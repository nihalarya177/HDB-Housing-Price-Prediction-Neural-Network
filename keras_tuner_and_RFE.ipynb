{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZ16K1uLTT7_"
   },
   "source": [
    "# Use [markdown](https://www.markdownguide.org/basic-syntax/) to label each (sub)question neatly.\n",
    "\n",
    "This notebook serves as your report. All your answers should be presented within it. \n",
    "\n",
    "You can submit multiple notebooks (e.g. 1 notebook per part / question).\n",
    "\n",
    "Before submission, remember to tidy up the notebook and retain only relevant parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2671,
     "status": "ok",
     "timestamp": 1661487448836,
     "user": {
      "displayName": "Yi Hao Chan",
      "userId": "12283099296861586040"
     },
     "user_tz": -480
    },
    "id": "dMfo-qGvShQe"
   },
   "outputs": [],
   "source": [
    "# Setting the seed here is sufficient. \n",
    "# If you don't plan to use these starter code, make sure you add this cell.\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "import os\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "\n",
    "import random \n",
    "random.seed(SEED)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 366,
     "status": "ok",
     "timestamp": 1661487450931,
     "user": {
      "displayName": "Yi Hao Chan",
      "userId": "12283099296861586040"
     },
     "user_tz": -480
    },
    "id": "mKSfgaY9S6J-"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Normalization, StringLookup, IntegerLookup\n",
    "import keras_tuner as kt\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "UACP3RoZS6Hv"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>full_address</th>\n",
       "      <th>nearest_stn</th>\n",
       "      <th>dist_to_nearest_stn</th>\n",
       "      <th>dist_to_dhoby</th>\n",
       "      <th>degree_centrality</th>\n",
       "      <th>eigenvector_centrality</th>\n",
       "      <th>flat_model_type</th>\n",
       "      <th>remaining_lease_years</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>resale_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>406 ANG MO KIO AVENUE 10</td>\n",
       "      <td>Ang Mo Kio</td>\n",
       "      <td>1.007264</td>\n",
       "      <td>7.006044</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>2 ROOM, Improved</td>\n",
       "      <td>61.333333</td>\n",
       "      <td>44.0</td>\n",
       "      <td>10 TO 12</td>\n",
       "      <td>232000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>108 ANG MO KIO AVENUE 4</td>\n",
       "      <td>Ang Mo Kio</td>\n",
       "      <td>1.271389</td>\n",
       "      <td>7.983837</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>3 ROOM, New Generation</td>\n",
       "      <td>60.583333</td>\n",
       "      <td>67.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>602 ANG MO KIO AVENUE 5</td>\n",
       "      <td>Yio Chu Kang</td>\n",
       "      <td>1.069743</td>\n",
       "      <td>9.090700</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>3 ROOM, New Generation</td>\n",
       "      <td>62.416667</td>\n",
       "      <td>67.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>262000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>465 ANG MO KIO AVENUE 10</td>\n",
       "      <td>Ang Mo Kio</td>\n",
       "      <td>0.946890</td>\n",
       "      <td>7.519889</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>3 ROOM, New Generation</td>\n",
       "      <td>62.083333</td>\n",
       "      <td>68.0</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>265000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>601 ANG MO KIO AVENUE 5</td>\n",
       "      <td>Yio Chu Kang</td>\n",
       "      <td>1.092551</td>\n",
       "      <td>9.130489</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>3 ROOM, New Generation</td>\n",
       "      <td>62.416667</td>\n",
       "      <td>67.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>265000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133407</th>\n",
       "      <td>6</td>\n",
       "      <td>2022</td>\n",
       "      <td>877 YISHUN STREET 81</td>\n",
       "      <td>Khatib</td>\n",
       "      <td>0.475885</td>\n",
       "      <td>12.738721</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>EXECUTIVE, Maisonette</td>\n",
       "      <td>64.583333</td>\n",
       "      <td>145.0</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>810000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133408</th>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>633 YISHUN STREET 61</td>\n",
       "      <td>Khatib</td>\n",
       "      <td>0.774113</td>\n",
       "      <td>13.229106</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>MULTI-GENERATION, Multi Generation</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>164.0</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>785000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133409</th>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>633 YISHUN STREET 61</td>\n",
       "      <td>Khatib</td>\n",
       "      <td>0.774113</td>\n",
       "      <td>13.229106</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>MULTI-GENERATION, Multi Generation</td>\n",
       "      <td>64.916667</td>\n",
       "      <td>171.0</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>842000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133410</th>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>632 YISHUN STREET 61</td>\n",
       "      <td>Khatib</td>\n",
       "      <td>0.700595</td>\n",
       "      <td>13.222912</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>MULTI-GENERATION, Multi Generation</td>\n",
       "      <td>64.750000</td>\n",
       "      <td>164.0</td>\n",
       "      <td>10 TO 12</td>\n",
       "      <td>845000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133411</th>\n",
       "      <td>5</td>\n",
       "      <td>2022</td>\n",
       "      <td>605 YISHUN STREET 61</td>\n",
       "      <td>Khatib</td>\n",
       "      <td>0.603845</td>\n",
       "      <td>13.592586</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>MULTI-GENERATION, Multi Generation</td>\n",
       "      <td>64.750000</td>\n",
       "      <td>163.0</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>862000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133412 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        month  year              full_address   nearest_stn  \\\n",
       "0           1  2017  406 ANG MO KIO AVENUE 10    Ang Mo Kio   \n",
       "1           1  2017   108 ANG MO KIO AVENUE 4    Ang Mo Kio   \n",
       "2           1  2017   602 ANG MO KIO AVENUE 5  Yio Chu Kang   \n",
       "3           1  2017  465 ANG MO KIO AVENUE 10    Ang Mo Kio   \n",
       "4           1  2017   601 ANG MO KIO AVENUE 5  Yio Chu Kang   \n",
       "...       ...   ...                       ...           ...   \n",
       "133407      6  2022      877 YISHUN STREET 81        Khatib   \n",
       "133408      1  2022      633 YISHUN STREET 61        Khatib   \n",
       "133409      2  2022      633 YISHUN STREET 61        Khatib   \n",
       "133410      2  2022      632 YISHUN STREET 61        Khatib   \n",
       "133411      5  2022      605 YISHUN STREET 61        Khatib   \n",
       "\n",
       "        dist_to_nearest_stn  dist_to_dhoby  degree_centrality  \\\n",
       "0                  1.007264       7.006044           0.016807   \n",
       "1                  1.271389       7.983837           0.016807   \n",
       "2                  1.069743       9.090700           0.016807   \n",
       "3                  0.946890       7.519889           0.016807   \n",
       "4                  1.092551       9.130489           0.016807   \n",
       "...                     ...            ...                ...   \n",
       "133407             0.475885      12.738721           0.016807   \n",
       "133408             0.774113      13.229106           0.016807   \n",
       "133409             0.774113      13.229106           0.016807   \n",
       "133410             0.700595      13.222912           0.016807   \n",
       "133411             0.603845      13.592586           0.016807   \n",
       "\n",
       "        eigenvector_centrality                     flat_model_type  \\\n",
       "0                     0.006243                    2 ROOM, Improved   \n",
       "1                     0.006243              3 ROOM, New Generation   \n",
       "2                     0.002459              3 ROOM, New Generation   \n",
       "3                     0.006243              3 ROOM, New Generation   \n",
       "4                     0.002459              3 ROOM, New Generation   \n",
       "...                        ...                                 ...   \n",
       "133407                0.000968               EXECUTIVE, Maisonette   \n",
       "133408                0.000968  MULTI-GENERATION, Multi Generation   \n",
       "133409                0.000968  MULTI-GENERATION, Multi Generation   \n",
       "133410                0.000968  MULTI-GENERATION, Multi Generation   \n",
       "133411                0.000968  MULTI-GENERATION, Multi Generation   \n",
       "\n",
       "        remaining_lease_years  floor_area_sqm storey_range  resale_price  \n",
       "0                   61.333333            44.0     10 TO 12      232000.0  \n",
       "1                   60.583333            67.0     01 TO 03      250000.0  \n",
       "2                   62.416667            67.0     01 TO 03      262000.0  \n",
       "3                   62.083333            68.0     04 TO 06      265000.0  \n",
       "4                   62.416667            67.0     01 TO 03      265000.0  \n",
       "...                       ...             ...          ...           ...  \n",
       "133407              64.583333           145.0     07 TO 09      810000.0  \n",
       "133408              65.000000           164.0     04 TO 06      785000.0  \n",
       "133409              64.916667           171.0     04 TO 06      842000.0  \n",
       "133410              64.750000           164.0     10 TO 12      845000.0  \n",
       "133411              64.750000           163.0     04 TO 06      862000.0  \n",
       "\n",
       "[133412 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import seaborn as sns\n",
    "df = pd.read_csv('hdb_price_prediction.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "eNWYYVX1S6Fo"
   },
   "outputs": [],
   "source": [
    "# The functions in this cell are adapted from https://keras.io/examples/structured_data/structured_data_classification_from_scratch/\n",
    "# It is the same link as the one mentioned in the question paper (Q1b)\n",
    "\n",
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(\"resale_price\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    return ds\n",
    "\n",
    "\n",
    "def encode_numerical_feature(feature, name, dataset):\n",
    "    # Create a Normalization layer for our feature\n",
    "    normalizer = Normalization()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the statistics of the data\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    # Normalize the input feature\n",
    "    encoded_feature = normalizer(feature)\n",
    "    return encoded_feature\n",
    "\n",
    "\n",
    "def encode_categorical_feature(feature, name, dataset, is_string):\n",
    "    lookup_class = StringLookup if is_string else IntegerLookup\n",
    "    # Create a lookup layer which will turn strings into integer indices\n",
    "    lookup = lookup_class(output_mode = \"int\") # NOTE: as mentioned in the question paper, this actually does one-hot encoding. You could replace 'binary' with 'one_hot' if you wish to.\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the set of possible string values and assign them a fixed integer index\n",
    "    lookup.adapt(feature_ds)\n",
    "\n",
    "    # Turn the string input into integer indices\n",
    "    encoded_feature = lookup(feature)\n",
    "    return encoded_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "imK7P_YkWqOb"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def r2(y_true, y_pred): \n",
    "    '''\n",
    "    # Obtained from https://jmlb.github.io/ml/2017/03/20/CoeffDetermination_CustomMetric4Keras/\n",
    "    # TODO: you have to find out how to use it in your code\n",
    "    '''\n",
    "    SS_res = K.sum(K.square( y_true - y_pred )) \n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Further split the data from year 2020 and before (i.e. those not in test set) by using data from year 2020 as validation set and the rest as the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "IW5w4If2S6Df"
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_dataframe = df[df.year<2020] # TODO\n",
    "val_dataframe = df[df.year==2020] # TODO\n",
    "test_dataframe = df[df.year>2020]\n",
    "\n",
    "train_ds = dataframe_to_dataset(train_dataframe)\n",
    "val_ds = dataframe_to_dataset(val_dataframe)\n",
    "test_ds = dataframe_to_dataset(test_dataframe)\n",
    "\n",
    "train_ds = train_ds.batch(256)\n",
    "val_ds = val_ds.batch(256)\n",
    "test_ds = test_ds.batch(256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) For each categorical variable, replace the one-hot ecncoding with the layer  tf.keras.layers.Embedding() and set output_dim=floor(num_categories//divisor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get output_dim value\n",
    "def output_dim(num_categories, divisor):\n",
    "    return (int(np.floor(num_categories//divisor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the number of categories in a column\n",
    "def num_categories(param):\n",
    "    return (int(len(np.unique(train_dataframe[param]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to perform embedding\n",
    "def embedding(param, divisor):\n",
    "    embedded = tf.keras.layers.Embedding((num_categories(param)+1), output_dim(num_categories(param), divisor))\n",
    "    return embedded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    divisor = hp.Int(\"divisor\", min_value=1, max_value=2, step=1)\n",
    "\n",
    "    # Categorcial Features encoded as Integers\n",
    "    month = keras.Input(shape=(1,), name=\"month\", dtype=\"int64\")\n",
    "\n",
    "    # Categorcial Features encoded as String\n",
    "    flat_model_type = keras.Input(shape=(1,), name=\"flat_model_type\", dtype=\"string\")\n",
    "    storey_range = keras.Input(shape=(1,), name=\"storey_range\", dtype=\"string\")\n",
    "\n",
    "    # Numerical Features\n",
    "    floor_area_sqm = keras.Input(shape=(1,), name=\"floor_area_sqm\")\n",
    "    remaining_lease_years = keras.Input(shape=(1,), name=\"remaining_lease_years\")\n",
    "    degree_centrality = keras.Input(shape=(1,), name=\"degree_centrality\")\n",
    "    eigenvector_centrality = keras.Input(shape=(1,), name=\"eigenvector_centrality\")\n",
    "    dist_to_nearest_stn = keras.Input(shape=(1,), name=\"dist_to_nearest_stn\")\n",
    "    dist_to_dhoby = keras.Input(shape=(1,), name=\"dist_to_dhoby\")\n",
    "\n",
    "    all_inputs = [\n",
    "        month,\n",
    "        storey_range,\n",
    "        flat_model_type,\n",
    "        floor_area_sqm,\n",
    "        remaining_lease_years,\n",
    "        degree_centrality,\n",
    "        eigenvector_centrality,\n",
    "        dist_to_nearest_stn,\n",
    "        dist_to_dhoby\n",
    "    ]\n",
    "\n",
    "    # Embedding implemented for all the categorical features after using \n",
    "    # lookup to get the input integer encoded -> embedded -> flattened\n",
    "\n",
    "    # Integer Categorical Features\n",
    "    month_encoded = encode_categorical_feature(month, \"month\", train_ds, False)\n",
    "    month_embedded = embedding('month', divisor)(month_encoded)\n",
    "    month_flattened = keras.layers.Flatten()(month_embedded)\n",
    "\n",
    "    # String Categorical Features\n",
    "    flat_model_type_encoded = encode_categorical_feature(flat_model_type, \"flat_model_type\", train_ds, True)\n",
    "    flat_model_type_embedded = embedding('flat_model_type', divisor)(flat_model_type_encoded)\n",
    "    flat_model_type_flattened = keras.layers.Flatten()(flat_model_type_embedded)\n",
    "\n",
    "    storey_range_encoded = encode_categorical_feature(storey_range, \"storey_range\", train_ds, True)\n",
    "    storey_range_embedded = embedding('storey_range', divisor)(storey_range_encoded)\n",
    "    storey_range_flattened = keras.layers.Flatten()(storey_range_embedded)\n",
    "\n",
    "    # Numerical Features\n",
    "    floor_area_sqm_encoded = encode_numerical_feature(floor_area_sqm, \"floor_area_sqm\", train_ds)\n",
    "    remaining_lease_years_encoded = encode_numerical_feature(remaining_lease_years, \"remaining_lease_years\", train_ds)\n",
    "    degree_centrality_encoded = encode_numerical_feature(degree_centrality, \"degree_centrality\", train_ds)\n",
    "    eigenvector_centrality_encoded = encode_numerical_feature(eigenvector_centrality, \"eigenvector_centrality\", train_ds)\n",
    "    dist_to_nearest_stn_encoded = encode_numerical_feature(dist_to_nearest_stn, \"dist_to_nearest_stn\", train_ds)\n",
    "    dist_to_dhoby_encoded = encode_numerical_feature(dist_to_dhoby, \"dist_to_dhoby\", train_ds)\n",
    "\n",
    "    all_features = layers.concatenate(\n",
    "        [\n",
    "            month_flattened,\n",
    "            storey_range_flattened,\n",
    "            flat_model_type_flattened,\n",
    "            floor_area_sqm_encoded,\n",
    "            remaining_lease_years_encoded,\n",
    "            degree_centrality_encoded,\n",
    "            eigenvector_centrality_encoded,\n",
    "            dist_to_nearest_stn_encoded,\n",
    "            dist_to_dhoby_encoded\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    units = hp.Int(\"units\", min_value=4, max_value=32, step=4)\n",
    "    \n",
    "    x = layers.Dense(units=units, activation='relu')(all_features)\n",
    "    output = layers.Dense(1, activation='linear')(x)\n",
    "    model = keras.Model(all_inputs, output)\n",
    "    \n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=2e-1, sampling=\"log\")\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss=tf.keras.losses.mean_squared_error, \n",
    "                  metrics=[r2, tf.keras.metrics.RootMeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Via a callback, introduce early stopping (based on val_loss, with patience of 10 epochs) to the model and use KerasTuner  (with the RandomSearch algorithm) to tune the model on the validation set, according to the following ranges:\n",
    "\n",
    "#### - Number of neurons: min=4, max=32, step=4\n",
    "#### - Learning rate: min=1e-4, max=2e-1, sampling=â€™logâ€™\n",
    "#### - Divisor: min=1, max=2, step=1\n",
    "\n",
    "#### Run 10 iterations of parameter search, each for 50 epochs and report best set of hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras tuner initialisation\n",
    "tuner = kt.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=kt.Objective('val_loss',direction='min'),\n",
    "    max_trials=10,\n",
    "    overwrite = True,\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping implementation to be used in callback\n",
    "es = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 01m 26s]\n",
      "val_loss: 9588917248.0\n",
      "\n",
      "Best val_loss So Far: 2737147136.0\n",
      "Total elapsed time: 00h 13m 48s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(train_ds, epochs=50, validation_data=val_ds, callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Using the best model configuration train a model on the non-test split (<=2020) for 50 epochs. Plot how train and test RMSE changes across epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data basedd on conditions given\n",
    "train_dataframe = df[df.year<=2020] # TODO\n",
    "test_dataframe = df[df.year>2020] # TODO\n",
    "\n",
    "train_ds = dataframe_to_dataset(train_dataframe)\n",
    "test_ds = dataframe_to_dataset(test_dataframe)\n",
    "\n",
    "train_ds = train_ds.batch(256)\n",
    "test_ds = test_ds.batch(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divisor': 1, 'units': 16, 'learning_rate': 0.1156985709194783}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters()\n",
    "best_hps[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the best hyperparamters for later use\n",
    "divisor = best_hps[0].values['divisor']\n",
    "units = best_hps[0].values['units']\n",
    "learning_rate = best_hps[0].values['learning_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the best_model based on the best hyperparameters\n",
    "model = build_model(best_hps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = '/tmp/checkpoint'\n",
    "# Initialising callback to save the model from the best epoch\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_root_mean_squared_error',\n",
    "    mode = 'min',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/NIHALARY001/CZ1016/base/lib/python3.8/site-packages/keras/engine/functional.py:637: UserWarning: Input dict contained keys ['year', 'full_address', 'nearest_stn'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341/342 [============================>.] - ETA: 0s - loss: 37260828672.0000 - r2: -0.5478 - root_mean_squared_error: 193030.6406INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n",
      "342/342 [==============================] - 5s 11ms/step - loss: 37238198272.0000 - r2: -0.5443 - root_mean_squared_error: 192972.0156 - val_loss: 14102861824.0000 - val_r2: 0.4853 - val_root_mean_squared_error: 118755.4688\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7405379072.0000 - r2: 0.6858 - root_mean_squared_error: 86054.5156 - val_loss: 14376395776.0000 - val_r2: 0.4738 - val_root_mean_squared_error: 119901.6094\n",
      "Epoch 3/50\n",
      "326/342 [===========================>..] - ETA: 0s - loss: 6462063616.0000 - r2: 0.7261 - root_mean_squared_error: 80386.9609INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n",
      "342/342 [==============================] - 4s 9ms/step - loss: 6444868096.0000 - r2: 0.7269 - root_mean_squared_error: 80279.9375 - val_loss: 12024166400.0000 - val_r2: 0.5598 - val_root_mean_squared_error: 109654.7578\n",
      "Epoch 4/50\n",
      "326/342 [===========================>..] - ETA: 0s - loss: 5618276864.0000 - r2: 0.7621 - root_mean_squared_error: 74955.1641INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n",
      "342/342 [==============================] - 4s 9ms/step - loss: 5607975936.0000 - r2: 0.7627 - root_mean_squared_error: 74886.4219 - val_loss: 11176627200.0000 - val_r2: 0.5906 - val_root_mean_squared_error: 105719.5703\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5024336896.0000 - r2: 0.7864 - root_mean_squared_error: 70882.5547 - val_loss: 12259880960.0000 - val_r2: 0.5504 - val_root_mean_squared_error: 110724.3438\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4626553344.0000 - r2: 0.8034 - root_mean_squared_error: 68018.7734 - val_loss: 11692448768.0000 - val_r2: 0.5713 - val_root_mean_squared_error: 108131.6250\n",
      "Epoch 7/50\n",
      "323/342 [===========================>..] - ETA: 0s - loss: 4326387712.0000 - r2: 0.8164 - root_mean_squared_error: 65775.2812INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n",
      "342/342 [==============================] - 4s 9ms/step - loss: 4319683072.0000 - r2: 0.8169 - root_mean_squared_error: 65724.2969 - val_loss: 10365959168.0000 - val_r2: 0.6198 - val_root_mean_squared_error: 101813.3516\n",
      "Epoch 8/50\n",
      "339/342 [============================>.] - ETA: 0s - loss: 4088308480.0000 - r2: 0.8265 - root_mean_squared_error: 63939.8828INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n",
      "342/342 [==============================] - 4s 9ms/step - loss: 4085975040.0000 - r2: 0.8264 - root_mean_squared_error: 63921.6328 - val_loss: 10087916544.0000 - val_r2: 0.6309 - val_root_mean_squared_error: 100438.6172\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3942956032.0000 - r2: 0.8324 - root_mean_squared_error: 62792.9609 - val_loss: 11370283008.0000 - val_r2: 0.5822 - val_root_mean_squared_error: 106631.5312\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3859162112.0000 - r2: 0.8360 - root_mean_squared_error: 62122.1562 - val_loss: 10239107072.0000 - val_r2: 0.6251 - val_root_mean_squared_error: 101188.4766\n",
      "Epoch 11/50\n",
      "326/342 [===========================>..] - ETA: 0s - loss: 3805865984.0000 - r2: 0.8385 - root_mean_squared_error: 61691.6992INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n",
      "342/342 [==============================] - 4s 9ms/step - loss: 3803782912.0000 - r2: 0.8383 - root_mean_squared_error: 61674.8164 - val_loss: 9989370880.0000 - val_r2: 0.6337 - val_root_mean_squared_error: 99946.8438\n",
      "Epoch 12/50\n",
      "325/342 [===========================>..] - ETA: 0s - loss: 3784088576.0000 - r2: 0.8391 - root_mean_squared_error: 61514.9453INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n",
      "342/342 [==============================] - 3s 8ms/step - loss: 3781221632.0000 - r2: 0.8393 - root_mean_squared_error: 61491.6406 - val_loss: 9227195392.0000 - val_r2: 0.6621 - val_root_mean_squared_error: 96058.2891\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3765298176.0000 - r2: 0.8403 - root_mean_squared_error: 61362.0273 - val_loss: 10505504768.0000 - val_r2: 0.6149 - val_root_mean_squared_error: 102496.3672\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3745966848.0000 - r2: 0.8409 - root_mean_squared_error: 61204.3047 - val_loss: 11217465344.0000 - val_r2: 0.5891 - val_root_mean_squared_error: 105912.5391\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3728847104.0000 - r2: 0.8416 - root_mean_squared_error: 61064.2852 - val_loss: 9316132864.0000 - val_r2: 0.6586 - val_root_mean_squared_error: 96520.1172\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3720103936.0000 - r2: 0.8418 - root_mean_squared_error: 60992.6562 - val_loss: 9386802176.0000 - val_r2: 0.6556 - val_root_mean_squared_error: 96885.5078\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3717903616.0000 - r2: 0.8417 - root_mean_squared_error: 60974.6133 - val_loss: 11510725632.0000 - val_r2: 0.5781 - val_root_mean_squared_error: 107288.0469\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3705741056.0000 - r2: 0.8427 - root_mean_squared_error: 60874.7969 - val_loss: 12162032640.0000 - val_r2: 0.5540 - val_root_mean_squared_error: 110281.6094\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3701286912.0000 - r2: 0.8426 - root_mean_squared_error: 60838.2031 - val_loss: 10859054080.0000 - val_r2: 0.6022 - val_root_mean_squared_error: 104206.7891\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3683399168.0000 - r2: 0.8436 - root_mean_squared_error: 60691.0156 - val_loss: 10147097600.0000 - val_r2: 0.6283 - val_root_mean_squared_error: 100732.8047\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3679243776.0000 - r2: 0.8439 - root_mean_squared_error: 60656.7695 - val_loss: 11877170176.0000 - val_r2: 0.5640 - val_root_mean_squared_error: 108982.4297\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3687543808.0000 - r2: 0.8433 - root_mean_squared_error: 60725.1484 - val_loss: 9992860672.0000 - val_r2: 0.6340 - val_root_mean_squared_error: 99964.2969\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3681039872.0000 - r2: 0.8431 - root_mean_squared_error: 60671.5742 - val_loss: 10085301248.0000 - val_r2: 0.6304 - val_root_mean_squared_error: 100425.6016\n",
      "Epoch 24/50\n",
      "327/342 [===========================>..] - ETA: 0s - loss: 3675761408.0000 - r2: 0.8436 - root_mean_squared_error: 60628.0586INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n",
      "342/342 [==============================] - 4s 9ms/step - loss: 3679764480.0000 - r2: 0.8436 - root_mean_squared_error: 60661.0625 - val_loss: 9156728832.0000 - val_r2: 0.6647 - val_root_mean_squared_error: 95690.7969\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3685038592.0000 - r2: 0.8434 - root_mean_squared_error: 60704.5195 - val_loss: 10409137152.0000 - val_r2: 0.6177 - val_root_mean_squared_error: 102025.1797\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3672856576.0000 - r2: 0.8439 - root_mean_squared_error: 60604.0977 - val_loss: 10445894656.0000 - val_r2: 0.6173 - val_root_mean_squared_error: 102205.1562\n",
      "Epoch 27/50\n",
      "333/342 [============================>.] - ETA: 0s - loss: 3596921600.0000 - r2: 0.8471 - root_mean_squared_error: 59974.3398INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n",
      "342/342 [==============================] - 3s 8ms/step - loss: 3595588352.0000 - r2: 0.8473 - root_mean_squared_error: 59963.2266 - val_loss: 8919508992.0000 - val_r2: 0.6730 - val_root_mean_squared_error: 94443.1484\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3392648448.0000 - r2: 0.8561 - root_mean_squared_error: 58246.4453 - val_loss: 9886151680.0000 - val_r2: 0.6376 - val_root_mean_squared_error: 99429.1328\n",
      "Epoch 29/50\n",
      "329/342 [===========================>..] - ETA: 0s - loss: 3217420800.0000 - r2: 0.8633 - root_mean_squared_error: 56722.3125INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n",
      "342/342 [==============================] - 4s 9ms/step - loss: 3207641856.0000 - r2: 0.8636 - root_mean_squared_error: 56636.0469 - val_loss: 8892270592.0000 - val_r2: 0.6739 - val_root_mean_squared_error: 94298.8359\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3043119872.0000 - r2: 0.8707 - root_mean_squared_error: 55164.4805 - val_loss: 10224931840.0000 - val_r2: 0.6244 - val_root_mean_squared_error: 101118.4062\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2943063040.0000 - r2: 0.8746 - root_mean_squared_error: 54250.0039 - val_loss: 9248561152.0000 - val_r2: 0.6600 - val_root_mean_squared_error: 96169.4375\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2850585088.0000 - r2: 0.8789 - root_mean_squared_error: 53390.8711 - val_loss: 9761924096.0000 - val_r2: 0.6415 - val_root_mean_squared_error: 98802.4531\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2779883776.0000 - r2: 0.8816 - root_mean_squared_error: 52724.6016 - val_loss: 9793419264.0000 - val_r2: 0.6410 - val_root_mean_squared_error: 98961.7031\n",
      "Epoch 34/50\n",
      "338/342 [============================>.] - ETA: 0s - loss: 2741656064.0000 - r2: 0.8831 - root_mean_squared_error: 52360.8242INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n",
      "342/342 [==============================] - 3s 8ms/step - loss: 2745316864.0000 - r2: 0.8830 - root_mean_squared_error: 52395.7695 - val_loss: 7982311424.0000 - val_r2: 0.7069 - val_root_mean_squared_error: 89343.7812\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2710063872.0000 - r2: 0.8845 - root_mean_squared_error: 52058.2734 - val_loss: 10419257344.0000 - val_r2: 0.6175 - val_root_mean_squared_error: 102074.7656\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2711064832.0000 - r2: 0.8848 - root_mean_squared_error: 52067.8867 - val_loss: 8559647232.0000 - val_r2: 0.6861 - val_root_mean_squared_error: 92518.3594\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2706155776.0000 - r2: 0.8849 - root_mean_squared_error: 52020.7227 - val_loss: 8456815616.0000 - val_r2: 0.6899 - val_root_mean_squared_error: 91960.9453\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2688660992.0000 - r2: 0.8853 - root_mean_squared_error: 51852.3008 - val_loss: 8673120256.0000 - val_r2: 0.6818 - val_root_mean_squared_error: 93129.5859\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2692934912.0000 - r2: 0.8853 - root_mean_squared_error: 51893.4961 - val_loss: 10503878656.0000 - val_r2: 0.6146 - val_root_mean_squared_error: 102488.4297\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2690168832.0000 - r2: 0.8855 - root_mean_squared_error: 51866.8359 - val_loss: 9233966080.0000 - val_r2: 0.6612 - val_root_mean_squared_error: 96093.5312\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2682328832.0000 - r2: 0.8858 - root_mean_squared_error: 51791.2031 - val_loss: 8952067072.0000 - val_r2: 0.6712 - val_root_mean_squared_error: 94615.3672\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2675337728.0000 - r2: 0.8864 - root_mean_squared_error: 51723.6680 - val_loss: 8465748992.0000 - val_r2: 0.6887 - val_root_mean_squared_error: 92009.5078\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2682752256.0000 - r2: 0.8854 - root_mean_squared_error: 51795.2930 - val_loss: 9531610112.0000 - val_r2: 0.6499 - val_root_mean_squared_error: 97629.9688\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2679641600.0000 - r2: 0.8859 - root_mean_squared_error: 51765.2539 - val_loss: 8128875008.0000 - val_r2: 0.7015 - val_root_mean_squared_error: 90160.2734\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2669246464.0000 - r2: 0.8863 - root_mean_squared_error: 51664.7500 - val_loss: 8718530560.0000 - val_r2: 0.6802 - val_root_mean_squared_error: 93373.0703\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2671404800.0000 - r2: 0.8862 - root_mean_squared_error: 51685.6328 - val_loss: 8631799808.0000 - val_r2: 0.6827 - val_root_mean_squared_error: 92907.4766\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2664516864.0000 - r2: 0.8866 - root_mean_squared_error: 51618.9570 - val_loss: 9240926208.0000 - val_r2: 0.6597 - val_root_mean_squared_error: 96129.7344\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2667780608.0000 - r2: 0.8864 - root_mean_squared_error: 51650.5625 - val_loss: 8456938496.0000 - val_r2: 0.6897 - val_root_mean_squared_error: 91961.6172\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2665502464.0000 - r2: 0.8868 - root_mean_squared_error: 51628.5039 - val_loss: 8331161088.0000 - val_r2: 0.6940 - val_root_mean_squared_error: 91275.1953\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2670139648.0000 - r2: 0.8862 - root_mean_squared_error: 51673.3945 - val_loss: 9118034944.0000 - val_r2: 0.6649 - val_root_mean_squared_error: 95488.3984\n"
     ]
    }
   ],
   "source": [
    "# Training the model with best hyperparameters along with the callback to retain the model from the best epoch\n",
    "history = model.fit(train_ds, epochs=50, validation_data=test_ds, \n",
    "                    callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'r2', 'root_mean_squared_error', 'val_loss', 'val_r2', 'val_root_mean_squared_error'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Root Mean Squared Error (RMSE)')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rmse = history.history[\"root_mean_squared_error\"]\n",
    "val_rmse = history.history[\"val_root_mean_squared_error\"]\n",
    "plt.plot(rmse[0:100])\n",
    "plt.plot(val_rmse[0:100])\n",
    "plt.legend(['train', 'test'], loc = 'upper right')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Root Mean Squared Error (RMSE)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Using the model from the best epoch, report the test R2 value and show the top 30 test samples with the largest errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_rmse = history.history[\"val_root_mean_squared_error\"]\n",
    "val_r2 = history.history[\"val_r2\"]\n",
    "\n",
    "best_epoch_rmse = sys.float_info.max\n",
    "best_epoch_r2 = sys.float_info.max\n",
    "\n",
    "for i in range(len(val_rmse)):\n",
    "    if val_rmse[i]<best_epoch_rmse:\n",
    "        best_epoch_rmse = val_rmse[i]\n",
    "        best_epoch_r2 = val_r2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R2 value for the best epoch :  0.7068911194801331\n"
     ]
    }
   ],
   "source": [
    "print('Test R2 value for the best epoch : ', best_epoch_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/NIHALARY001/CZ1016/base/lib/python3.8/site-packages/keras/engine/functional.py:637: UserWarning: Input dict contained keys ['year', 'full_address', 'nearest_stn'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(checkpoint_filepath)\n",
    "predict = model.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-6344145ba361>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_dataframe['predict'] = predict\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>full_address</th>\n",
       "      <th>nearest_stn</th>\n",
       "      <th>dist_to_nearest_stn</th>\n",
       "      <th>dist_to_dhoby</th>\n",
       "      <th>degree_centrality</th>\n",
       "      <th>eigenvector_centrality</th>\n",
       "      <th>flat_model_type</th>\n",
       "      <th>remaining_lease_years</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>resale_price</th>\n",
       "      <th>predict</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90171</th>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>20 JALAN KLINIK</td>\n",
       "      <td>Tiong Bahru</td>\n",
       "      <td>0.289046</td>\n",
       "      <td>2.229959</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>2 ROOM, Standard</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>48.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>210000.0</td>\n",
       "      <td>8.400191e+05</td>\n",
       "      <td>3.000091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94548</th>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "      <td>534 BEDOK NORTH STREET 3</td>\n",
       "      <td>Bedok North</td>\n",
       "      <td>0.791520</td>\n",
       "      <td>9.557626</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>2 ROOM, Improved</td>\n",
       "      <td>63.916667</td>\n",
       "      <td>45.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>246944.0</td>\n",
       "      <td>9.583636e+05</td>\n",
       "      <td>2.880894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109789</th>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>2 HOUGANG AVENUE 3</td>\n",
       "      <td>Hougang</td>\n",
       "      <td>0.917218</td>\n",
       "      <td>8.822781</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.001507</td>\n",
       "      <td>3 ROOM, Improved</td>\n",
       "      <td>52.833333</td>\n",
       "      <td>59.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1.039750e+06</td>\n",
       "      <td>2.850926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91210</th>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>85 COMMONWEALTH CLOSE</td>\n",
       "      <td>Commonwealth</td>\n",
       "      <td>0.212743</td>\n",
       "      <td>5.199732</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.005350</td>\n",
       "      <td>2 ROOM, Standard</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>46.0</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>218000.0</td>\n",
       "      <td>8.274156e+05</td>\n",
       "      <td>2.795485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91902</th>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>706 YISHUN AVENUE 5</td>\n",
       "      <td>Yishun</td>\n",
       "      <td>0.688427</td>\n",
       "      <td>14.463999</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>3 ROOM, New Generation</td>\n",
       "      <td>62.083333</td>\n",
       "      <td>68.0</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>255000.0</td>\n",
       "      <td>9.663935e+05</td>\n",
       "      <td>2.789778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103342</th>\n",
       "      <td>7</td>\n",
       "      <td>2021</td>\n",
       "      <td>194 KIM KEAT AVENUE</td>\n",
       "      <td>Potong Pasir</td>\n",
       "      <td>1.180073</td>\n",
       "      <td>3.773605</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.021715</td>\n",
       "      <td>3 ROOM, Improved</td>\n",
       "      <td>51.083333</td>\n",
       "      <td>66.0</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>256000.0</td>\n",
       "      <td>9.692913e+05</td>\n",
       "      <td>2.786294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93150</th>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "      <td>3 JALAN BATU</td>\n",
       "      <td>Mountbatten</td>\n",
       "      <td>0.366149</td>\n",
       "      <td>4.263915</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.016678</td>\n",
       "      <td>3 ROOM, Standard</td>\n",
       "      <td>46.916667</td>\n",
       "      <td>60.0</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>256000.0</td>\n",
       "      <td>9.656808e+05</td>\n",
       "      <td>2.772191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89559</th>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>51 LORONG 6 TOA PAYOH</td>\n",
       "      <td>Braddell</td>\n",
       "      <td>0.675356</td>\n",
       "      <td>4.334529</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.017995</td>\n",
       "      <td>3 ROOM, Standard</td>\n",
       "      <td>61.416667</td>\n",
       "      <td>63.0</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>262000.0</td>\n",
       "      <td>9.789821e+05</td>\n",
       "      <td>2.736573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99066</th>\n",
       "      <td>6</td>\n",
       "      <td>2021</td>\n",
       "      <td>20 JALAN KLINIK</td>\n",
       "      <td>Tiong Bahru</td>\n",
       "      <td>0.289046</td>\n",
       "      <td>2.229959</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>2 ROOM, Standard</td>\n",
       "      <td>48.666667</td>\n",
       "      <td>48.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>8.161058e+05</td>\n",
       "      <td>2.627137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118879</th>\n",
       "      <td>4</td>\n",
       "      <td>2022</td>\n",
       "      <td>20 JALAN KLINIK</td>\n",
       "      <td>Tiong Bahru</td>\n",
       "      <td>0.289046</td>\n",
       "      <td>2.229959</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>2 ROOM, Standard</td>\n",
       "      <td>47.833333</td>\n",
       "      <td>48.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>9.743311e+05</td>\n",
       "      <td>2.608634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95167</th>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "      <td>20 BALAM ROAD</td>\n",
       "      <td>MacPherson</td>\n",
       "      <td>0.522173</td>\n",
       "      <td>5.814082</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>3 ROOM, Standard</td>\n",
       "      <td>44.750000</td>\n",
       "      <td>60.3</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>228000.0</td>\n",
       "      <td>8.182322e+05</td>\n",
       "      <td>2.588738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89573</th>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>206 TOA PAYOH NORTH</td>\n",
       "      <td>Braddell</td>\n",
       "      <td>0.205879</td>\n",
       "      <td>4.771517</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.017995</td>\n",
       "      <td>3 ROOM, Improved</td>\n",
       "      <td>51.583333</td>\n",
       "      <td>59.0</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>245000.0</td>\n",
       "      <td>8.782944e+05</td>\n",
       "      <td>2.584875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94826</th>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "      <td>37 JALAN RUMAH TINGGI</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>0.723049</td>\n",
       "      <td>4.219591</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.008342</td>\n",
       "      <td>3 ROOM, Standard</td>\n",
       "      <td>47.333333</td>\n",
       "      <td>53.0</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>8.919108e+05</td>\n",
       "      <td>2.567643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111059</th>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>110 LORONG 1 TOA PAYOH</td>\n",
       "      <td>Braddell</td>\n",
       "      <td>0.136305</td>\n",
       "      <td>4.687060</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.017995</td>\n",
       "      <td>3 ROOM, Improved</td>\n",
       "      <td>44.750000</td>\n",
       "      <td>65.0</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>8.901542e+05</td>\n",
       "      <td>2.560617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88923</th>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>97 COMMONWEALTH CRESCENT</td>\n",
       "      <td>Commonwealth</td>\n",
       "      <td>0.541989</td>\n",
       "      <td>4.990753</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.005350</td>\n",
       "      <td>2 ROOM, Standard</td>\n",
       "      <td>48.500000</td>\n",
       "      <td>47.0</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>230000.0</td>\n",
       "      <td>8.127462e+05</td>\n",
       "      <td>2.533679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88155</th>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>40 CIRCUIT ROAD</td>\n",
       "      <td>Mattar</td>\n",
       "      <td>0.341167</td>\n",
       "      <td>5.497101</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.004897</td>\n",
       "      <td>2 ROOM, Standard</td>\n",
       "      <td>49.083333</td>\n",
       "      <td>45.0</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>198000.0</td>\n",
       "      <td>6.898937e+05</td>\n",
       "      <td>2.484312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101876</th>\n",
       "      <td>7</td>\n",
       "      <td>2021</td>\n",
       "      <td>30 BALAM ROAD</td>\n",
       "      <td>MacPherson</td>\n",
       "      <td>0.439622</td>\n",
       "      <td>5.707583</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>3 ROOM, Standard</td>\n",
       "      <td>51.083333</td>\n",
       "      <td>57.0</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>240000.0</td>\n",
       "      <td>8.342988e+05</td>\n",
       "      <td>2.476245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108947</th>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>219 ANG MO KIO AVENUE 1</td>\n",
       "      <td>Ang Mo Kio</td>\n",
       "      <td>1.090130</td>\n",
       "      <td>7.409995</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>3 ROOM, New Generation</td>\n",
       "      <td>54.833333</td>\n",
       "      <td>67.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>288000.0</td>\n",
       "      <td>1.000985e+06</td>\n",
       "      <td>2.475643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102827</th>\n",
       "      <td>7</td>\n",
       "      <td>2021</td>\n",
       "      <td>447A JALAN KAYU</td>\n",
       "      <td>Buangkok</td>\n",
       "      <td>2.531806</td>\n",
       "      <td>10.700616</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>2 ROOM, Model A</td>\n",
       "      <td>91.416667</td>\n",
       "      <td>47.0</td>\n",
       "      <td>13 TO 15</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>8.674394e+05</td>\n",
       "      <td>2.469758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88926</th>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>82 COMMONWEALTH CLOSE</td>\n",
       "      <td>Commonwealth</td>\n",
       "      <td>0.303557</td>\n",
       "      <td>5.083298</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.005350</td>\n",
       "      <td>3 ROOM, Standard</td>\n",
       "      <td>45.083333</td>\n",
       "      <td>60.0</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>232000.0</td>\n",
       "      <td>7.988816e+05</td>\n",
       "      <td>2.443455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96646</th>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "      <td>438 YISHUN AVENUE 11</td>\n",
       "      <td>Yishun</td>\n",
       "      <td>1.513531</td>\n",
       "      <td>13.546570</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>2 ROOM, Model A</td>\n",
       "      <td>78.500000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>216000.0</td>\n",
       "      <td>7.430639e+05</td>\n",
       "      <td>2.440111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132188</th>\n",
       "      <td>4</td>\n",
       "      <td>2022</td>\n",
       "      <td>451 YISHUN RING ROAD</td>\n",
       "      <td>Yishun</td>\n",
       "      <td>1.362785</td>\n",
       "      <td>13.588573</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>2 ROOM, Model A</td>\n",
       "      <td>89.333333</td>\n",
       "      <td>47.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>9.276572e+05</td>\n",
       "      <td>2.435768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104753</th>\n",
       "      <td>8</td>\n",
       "      <td>2021</td>\n",
       "      <td>209 BOON LAY PLACE</td>\n",
       "      <td>Lakeside</td>\n",
       "      <td>0.665480</td>\n",
       "      <td>15.443600</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>3 ROOM, Improved</td>\n",
       "      <td>53.833333</td>\n",
       "      <td>65.0</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>280000.0</td>\n",
       "      <td>9.587486e+05</td>\n",
       "      <td>2.424102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104514</th>\n",
       "      <td>8</td>\n",
       "      <td>2021</td>\n",
       "      <td>67 CIRCUIT ROAD</td>\n",
       "      <td>MacPherson</td>\n",
       "      <td>0.242097</td>\n",
       "      <td>5.539389</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>3 ROOM, Standard</td>\n",
       "      <td>46.500000</td>\n",
       "      <td>61.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>262000.0</td>\n",
       "      <td>8.875305e+05</td>\n",
       "      <td>2.387521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88516</th>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>6 BEACH ROAD</td>\n",
       "      <td>Lavender</td>\n",
       "      <td>0.420631</td>\n",
       "      <td>2.139762</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.118015</td>\n",
       "      <td>2 ROOM, Standard</td>\n",
       "      <td>57.750000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>230000.0</td>\n",
       "      <td>7.789937e+05</td>\n",
       "      <td>2.386929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118869</th>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>38 BEO CRESCENT</td>\n",
       "      <td>Tiong Bahru</td>\n",
       "      <td>0.224143</td>\n",
       "      <td>2.370832</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>2 ROOM, Standard</td>\n",
       "      <td>47.916667</td>\n",
       "      <td>51.0</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>8.444177e+05</td>\n",
       "      <td>2.377671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122110</th>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>703 HOUGANG AVENUE 2</td>\n",
       "      <td>Hougang</td>\n",
       "      <td>0.734095</td>\n",
       "      <td>8.800961</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.001507</td>\n",
       "      <td>3 ROOM, New Generation</td>\n",
       "      <td>63.500000</td>\n",
       "      <td>67.0</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>370000.0</td>\n",
       "      <td>1.248625e+06</td>\n",
       "      <td>2.374662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101433</th>\n",
       "      <td>7</td>\n",
       "      <td>2021</td>\n",
       "      <td>28 JALAN BUKIT MERAH</td>\n",
       "      <td>Redhill</td>\n",
       "      <td>0.863408</td>\n",
       "      <td>4.253836</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.019127</td>\n",
       "      <td>3 ROOM, Standard</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>13 TO 15</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>9.107642e+05</td>\n",
       "      <td>2.373201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92769</th>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "      <td>43 CIRCUIT ROAD</td>\n",
       "      <td>Mattar</td>\n",
       "      <td>0.253215</td>\n",
       "      <td>5.356046</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.004897</td>\n",
       "      <td>3 ROOM, Standard</td>\n",
       "      <td>48.916667</td>\n",
       "      <td>52.0</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>224000.0</td>\n",
       "      <td>7.535694e+05</td>\n",
       "      <td>2.364149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104080</th>\n",
       "      <td>8</td>\n",
       "      <td>2021</td>\n",
       "      <td>12 TAMAN HO SWEE</td>\n",
       "      <td>Tiong Bahru</td>\n",
       "      <td>0.662914</td>\n",
       "      <td>1.917586</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>3 ROOM, Standard</td>\n",
       "      <td>47.500000</td>\n",
       "      <td>54.0</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>258000.0</td>\n",
       "      <td>8.667066e+05</td>\n",
       "      <td>2.359328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        month  year              full_address   nearest_stn  \\\n",
       "90171       2  2021           20 JALAN KLINIK   Tiong Bahru   \n",
       "94548       4  2021  534 BEDOK NORTH STREET 3   Bedok North   \n",
       "109789     10  2021        2 HOUGANG AVENUE 3       Hougang   \n",
       "91210       2  2021     85 COMMONWEALTH CLOSE  Commonwealth   \n",
       "91902       2  2021       706 YISHUN AVENUE 5        Yishun   \n",
       "103342      7  2021       194 KIM KEAT AVENUE  Potong Pasir   \n",
       "93150       3  2021              3 JALAN BATU   Mountbatten   \n",
       "89559       1  2021     51 LORONG 6 TOA PAYOH      Braddell   \n",
       "99066       6  2021           20 JALAN KLINIK   Tiong Bahru   \n",
       "118879      4  2022           20 JALAN KLINIK   Tiong Bahru   \n",
       "95167       4  2021             20 BALAM ROAD    MacPherson   \n",
       "89573       1  2021       206 TOA PAYOH NORTH      Braddell   \n",
       "94826       4  2021     37 JALAN RUMAH TINGGI    Queenstown   \n",
       "111059     10  2021    110 LORONG 1 TOA PAYOH      Braddell   \n",
       "88923       1  2021  97 COMMONWEALTH CRESCENT  Commonwealth   \n",
       "88155       1  2021           40 CIRCUIT ROAD        Mattar   \n",
       "101876      7  2021             30 BALAM ROAD    MacPherson   \n",
       "108947     10  2021   219 ANG MO KIO AVENUE 1    Ang Mo Kio   \n",
       "102827      7  2021           447A JALAN KAYU      Buangkok   \n",
       "88926       1  2021     82 COMMONWEALTH CLOSE  Commonwealth   \n",
       "96646       4  2021      438 YISHUN AVENUE 11        Yishun   \n",
       "132188      4  2022      451 YISHUN RING ROAD        Yishun   \n",
       "104753      8  2021        209 BOON LAY PLACE      Lakeside   \n",
       "104514      8  2021           67 CIRCUIT ROAD    MacPherson   \n",
       "88516       1  2021              6 BEACH ROAD      Lavender   \n",
       "118869      3  2022           38 BEO CRESCENT   Tiong Bahru   \n",
       "122110      1  2022      703 HOUGANG AVENUE 2       Hougang   \n",
       "101433      7  2021      28 JALAN BUKIT MERAH       Redhill   \n",
       "92769       3  2021           43 CIRCUIT ROAD        Mattar   \n",
       "104080      8  2021          12 TAMAN HO SWEE   Tiong Bahru   \n",
       "\n",
       "        dist_to_nearest_stn  dist_to_dhoby  degree_centrality  \\\n",
       "90171              0.289046       2.229959           0.016807   \n",
       "94548              0.791520       9.557626           0.016807   \n",
       "109789             0.917218       8.822781           0.016807   \n",
       "91210              0.212743       5.199732           0.016807   \n",
       "91902              0.688427      14.463999           0.016807   \n",
       "103342             1.180073       3.773605           0.016807   \n",
       "93150              0.366149       4.263915           0.016807   \n",
       "89559              0.675356       4.334529           0.016807   \n",
       "99066              0.289046       2.229959           0.016807   \n",
       "118879             0.289046       2.229959           0.016807   \n",
       "95167              0.522173       5.814082           0.033613   \n",
       "89573              0.205879       4.771517           0.016807   \n",
       "94826              0.723049       4.219591           0.016807   \n",
       "111059             0.136305       4.687060           0.016807   \n",
       "88923              0.541989       4.990753           0.016807   \n",
       "88155              0.341167       5.497101           0.016807   \n",
       "101876             0.439622       5.707583           0.033613   \n",
       "108947             1.090130       7.409995           0.016807   \n",
       "102827             2.531806      10.700616           0.016807   \n",
       "88926              0.303557       5.083298           0.016807   \n",
       "96646              1.513531      13.546570           0.016807   \n",
       "132188             1.362785      13.588573           0.016807   \n",
       "104753             0.665480      15.443600           0.016807   \n",
       "104514             0.242097       5.539389           0.033613   \n",
       "88516              0.420631       2.139762           0.016807   \n",
       "118869             0.224143       2.370832           0.016807   \n",
       "122110             0.734095       8.800961           0.016807   \n",
       "101433             0.863408       4.253836           0.016807   \n",
       "92769              0.253215       5.356046           0.016807   \n",
       "104080             0.662914       1.917586           0.016807   \n",
       "\n",
       "        eigenvector_centrality         flat_model_type  remaining_lease_years  \\\n",
       "90171                 0.047782        2 ROOM, Standard              49.000000   \n",
       "94548                 0.000698        2 ROOM, Improved              63.916667   \n",
       "109789                0.001507        3 ROOM, Improved              52.833333   \n",
       "91210                 0.005350        2 ROOM, Standard              45.000000   \n",
       "91902                 0.000382  3 ROOM, New Generation              62.083333   \n",
       "103342                0.021715        3 ROOM, Improved              51.083333   \n",
       "93150                 0.016678        3 ROOM, Standard              46.916667   \n",
       "89559                 0.017995        3 ROOM, Standard              61.416667   \n",
       "99066                 0.047782        2 ROOM, Standard              48.666667   \n",
       "118879                0.047782        2 ROOM, Standard              47.833333   \n",
       "95167                 0.011178        3 ROOM, Standard              44.750000   \n",
       "89573                 0.017995        3 ROOM, Improved              51.583333   \n",
       "94826                 0.008342        3 ROOM, Standard              47.333333   \n",
       "111059                0.017995        3 ROOM, Improved              44.750000   \n",
       "88923                 0.005350        2 ROOM, Standard              48.500000   \n",
       "88155                 0.004897        2 ROOM, Standard              49.083333   \n",
       "101876                0.011178        3 ROOM, Standard              51.083333   \n",
       "108947                0.006243  3 ROOM, New Generation              54.833333   \n",
       "102827                0.000594         2 ROOM, Model A              91.416667   \n",
       "88926                 0.005350        3 ROOM, Standard              45.083333   \n",
       "96646                 0.000382         2 ROOM, Model A              78.500000   \n",
       "132188                0.000382         2 ROOM, Model A              89.333333   \n",
       "104753                0.000085        3 ROOM, Improved              53.833333   \n",
       "104514                0.011178        3 ROOM, Standard              46.500000   \n",
       "88516                 0.118015        2 ROOM, Standard              57.750000   \n",
       "118869                0.047782        2 ROOM, Standard              47.916667   \n",
       "122110                0.001507  3 ROOM, New Generation              63.500000   \n",
       "101433                0.019127        3 ROOM, Standard              45.000000   \n",
       "92769                 0.004897        3 ROOM, Standard              48.916667   \n",
       "104080                0.047782        3 ROOM, Standard              47.500000   \n",
       "\n",
       "        floor_area_sqm storey_range  resale_price       predict     error  \n",
       "90171             48.0     01 TO 03      210000.0  8.400191e+05  3.000091  \n",
       "94548             45.0     01 TO 03      246944.0  9.583636e+05  2.880894  \n",
       "109789            59.0     01 TO 03      270000.0  1.039750e+06  2.850926  \n",
       "91210             46.0     04 TO 06      218000.0  8.274156e+05  2.795485  \n",
       "91902             68.0     07 TO 09      255000.0  9.663935e+05  2.789778  \n",
       "103342            66.0     04 TO 06      256000.0  9.692913e+05  2.786294  \n",
       "93150             60.0     04 TO 06      256000.0  9.656808e+05  2.772191  \n",
       "89559             63.0     07 TO 09      262000.0  9.789821e+05  2.736573  \n",
       "99066             48.0     01 TO 03      225000.0  8.161058e+05  2.627137  \n",
       "118879            48.0     01 TO 03      270000.0  9.743311e+05  2.608634  \n",
       "95167             60.3     04 TO 06      228000.0  8.182322e+05  2.588738  \n",
       "89573             59.0     04 TO 06      245000.0  8.782944e+05  2.584875  \n",
       "94826             53.0     04 TO 06      250000.0  8.919108e+05  2.567643  \n",
       "111059            65.0     07 TO 09      250000.0  8.901542e+05  2.560617  \n",
       "88923             47.0     04 TO 06      230000.0  8.127462e+05  2.533679  \n",
       "88155             45.0     07 TO 09      198000.0  6.898937e+05  2.484312  \n",
       "101876            57.0     04 TO 06      240000.0  8.342988e+05  2.476245  \n",
       "108947            67.0     01 TO 03      288000.0  1.000985e+06  2.475643  \n",
       "102827            47.0     13 TO 15      250000.0  8.674394e+05  2.469758  \n",
       "88926             60.0     07 TO 09      232000.0  7.988816e+05  2.443455  \n",
       "96646             40.0     07 TO 09      216000.0  7.430639e+05  2.440111  \n",
       "132188            47.0     01 TO 03      270000.0  9.276572e+05  2.435768  \n",
       "104753            65.0     04 TO 06      280000.0  9.587486e+05  2.424102  \n",
       "104514            61.0     01 TO 03      262000.0  8.875305e+05  2.387521  \n",
       "88516             42.0     07 TO 09      230000.0  7.789937e+05  2.386929  \n",
       "118869            51.0     04 TO 06      250000.0  8.444177e+05  2.377671  \n",
       "122110            67.0     07 TO 09      370000.0  1.248625e+06  2.374662  \n",
       "101433            60.0     13 TO 15      270000.0  9.107642e+05  2.373201  \n",
       "92769             52.0     07 TO 09      224000.0  7.535694e+05  2.364149  \n",
       "104080            54.0     04 TO 06      258000.0  8.667066e+05  2.359328  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataframe['predict'] = predict\n",
    "test_dataframe = pd.DataFrame(test_dataframe)\n",
    "test_dataframe['error'] = abs(test_dataframe['predict']-test_dataframe['resale_price'])/test_dataframe['resale_price']\n",
    "test_dataframe = test_dataframe.sort_values(by='error', ascending=False)\n",
    "test_dataframe.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trends and Observations\n",
    "\n",
    "1. Almost all have same degree centrality of 0.016807\n",
    "2. Close to an MRT station with furthest one only being ~2.5 kms away\n",
    "3. Far away from Dhoby Ghaut station which could mean that there is not enough data for HDBs in less populated areas as there may not be many datapoints from these places.\n",
    "4. The resale prices of these HDB's were all between 200,000 - 300,000 which suggests that our model is not good at predicting the resale prices of HDB's with low resale prices. This may be because of the lack of data of HDB's with low resale prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/NIHALARY001/CZ1016/base/lib/python3.8/site-packages/keras/engine/functional.py:637: UserWarning: Input dict contained keys ['year', 'full_address', 'nearest_stn'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342/342 [==============================] - 3s 6ms/step - loss: 36873408512.0000 - r2: -0.5625 - root_mean_squared_error: 192024.5000 - val_loss: 13790502912.0000 - val_r2: 0.4961 - val_root_mean_squared_error: 117432.9688\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 7420629504.0000 - r2: 0.6854 - root_mean_squared_error: 86143.0781 - val_loss: 13599012864.0000 - val_r2: 0.5026 - val_root_mean_squared_error: 116614.8047\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 6460056576.0000 - r2: 0.7261 - root_mean_squared_error: 80374.4766 - val_loss: 12256728064.0000 - val_r2: 0.5514 - val_root_mean_squared_error: 110710.1094\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 5599859200.0000 - r2: 0.7622 - root_mean_squared_error: 74832.2031 - val_loss: 11513276416.0000 - val_r2: 0.5786 - val_root_mean_squared_error: 107299.9375\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 5023465472.0000 - r2: 0.7867 - root_mean_squared_error: 70876.4062 - val_loss: 11184133120.0000 - val_r2: 0.5905 - val_root_mean_squared_error: 105755.0625\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 4621513728.0000 - r2: 0.8039 - root_mean_squared_error: 67981.7188 - val_loss: 10682832896.0000 - val_r2: 0.6085 - val_root_mean_squared_error: 103357.7891\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 4305156096.0000 - r2: 0.8175 - root_mean_squared_error: 65613.6875 - val_loss: 10349703168.0000 - val_r2: 0.6207 - val_root_mean_squared_error: 101733.4922\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 4094211840.0000 - r2: 0.8261 - root_mean_squared_error: 63986.0273 - val_loss: 10974132224.0000 - val_r2: 0.5975 - val_root_mean_squared_error: 104757.4922\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 3s 5ms/step - loss: 3936550144.0000 - r2: 0.8329 - root_mean_squared_error: 62741.9336 - val_loss: 10148748288.0000 - val_r2: 0.6275 - val_root_mean_squared_error: 100740.9922\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 3s 7ms/step - loss: 3856859392.0000 - r2: 0.8359 - root_mean_squared_error: 62103.6172 - val_loss: 9957649408.0000 - val_r2: 0.6347 - val_root_mean_squared_error: 99788.0234\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3810638336.0000 - r2: 0.8381 - root_mean_squared_error: 61730.3672 - val_loss: 11962358784.0000 - val_r2: 0.5615 - val_root_mean_squared_error: 109372.5703\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3765925120.0000 - r2: 0.8400 - root_mean_squared_error: 61367.1328 - val_loss: 9770253312.0000 - val_r2: 0.6416 - val_root_mean_squared_error: 98844.5938\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 3s 5ms/step - loss: 3608944384.0000 - r2: 0.8466 - root_mean_squared_error: 60074.4922 - val_loss: 10131897344.0000 - val_r2: 0.6273 - val_root_mean_squared_error: 100657.3281\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3504436480.0000 - r2: 0.8512 - root_mean_squared_error: 59198.2812 - val_loss: 9914521600.0000 - val_r2: 0.6365 - val_root_mean_squared_error: 99571.6875\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3387534336.0000 - r2: 0.8560 - root_mean_squared_error: 58202.5273 - val_loss: 11220041728.0000 - val_r2: 0.5880 - val_root_mean_squared_error: 105924.6953\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3210041088.0000 - r2: 0.8638 - root_mean_squared_error: 56657.2227 - val_loss: 9481895936.0000 - val_r2: 0.6525 - val_root_mean_squared_error: 97375.0234\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 3s 5ms/step - loss: 3063334144.0000 - r2: 0.8698 - root_mean_squared_error: 55347.3945 - val_loss: 8151531008.0000 - val_r2: 0.7008 - val_root_mean_squared_error: 90285.8281\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 2948344064.0000 - r2: 0.8748 - root_mean_squared_error: 54298.6562 - val_loss: 10230589440.0000 - val_r2: 0.6249 - val_root_mean_squared_error: 101146.3750\n",
      "Epoch 19/50\n",
      "339/342 [============================>.] - ETA: 0s - loss: 2875414528.0000 - r2: 0.8778 - root_mean_squared_error: 53622.8906INFO:tensorflow:Assets written to: /tmp/checkpoint/assets\n",
      "342/342 [==============================] - 5s 11ms/step - loss: 2876965632.0000 - r2: 0.8776 - root_mean_squared_error: 53637.3516 - val_loss: 7400908800.0000 - val_r2: 0.7288 - val_root_mean_squared_error: 86028.5312\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 3s 5ms/step - loss: 2836640000.0000 - r2: 0.8793 - root_mean_squared_error: 53260.1172 - val_loss: 9899327488.0000 - val_r2: 0.6367 - val_root_mean_squared_error: 99495.3672\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2789169152.0000 - r2: 0.8816 - root_mean_squared_error: 52812.5859 - val_loss: 8554211328.0000 - val_r2: 0.6863 - val_root_mean_squared_error: 92488.9766\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2788468992.0000 - r2: 0.8813 - root_mean_squared_error: 52805.9570 - val_loss: 9156920320.0000 - val_r2: 0.6633 - val_root_mean_squared_error: 95691.7969\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 2771743488.0000 - r2: 0.8821 - root_mean_squared_error: 52647.3516 - val_loss: 9280731136.0000 - val_r2: 0.6588 - val_root_mean_squared_error: 96336.5547\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 2757399808.0000 - r2: 0.8828 - root_mean_squared_error: 52510.9492 - val_loss: 10659781632.0000 - val_r2: 0.6083 - val_root_mean_squared_error: 103246.2188\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2740482560.0000 - r2: 0.8833 - root_mean_squared_error: 52349.6172 - val_loss: 9464173568.0000 - val_r2: 0.6517 - val_root_mean_squared_error: 97283.9844\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2732790272.0000 - r2: 0.8837 - root_mean_squared_error: 52276.0977 - val_loss: 9018915840.0000 - val_r2: 0.6686 - val_root_mean_squared_error: 94967.9766\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2725588480.0000 - r2: 0.8839 - root_mean_squared_error: 52207.1680 - val_loss: 9967097856.0000 - val_r2: 0.6339 - val_root_mean_squared_error: 99835.3516\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 3s 5ms/step - loss: 2713318144.0000 - r2: 0.8844 - root_mean_squared_error: 52089.5195 - val_loss: 10546484224.0000 - val_r2: 0.6130 - val_root_mean_squared_error: 102696.0781\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 3s 5ms/step - loss: 2716391680.0000 - r2: 0.8846 - root_mean_squared_error: 52119.0156 - val_loss: 8705806336.0000 - val_r2: 0.6805 - val_root_mean_squared_error: 93304.9141\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 3s 5ms/step - loss: 2704596224.0000 - r2: 0.8849 - root_mean_squared_error: 52005.7344 - val_loss: 9218719744.0000 - val_r2: 0.6620 - val_root_mean_squared_error: 96014.1641\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 2692046592.0000 - r2: 0.8856 - root_mean_squared_error: 51884.9375 - val_loss: 9582489600.0000 - val_r2: 0.6484 - val_root_mean_squared_error: 97890.1953\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 2689922048.0000 - r2: 0.8855 - root_mean_squared_error: 51864.4570 - val_loss: 9242053632.0000 - val_r2: 0.6607 - val_root_mean_squared_error: 96135.6016\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 3s 5ms/step - loss: 2685517568.0000 - r2: 0.8854 - root_mean_squared_error: 51821.9805 - val_loss: 8976465920.0000 - val_r2: 0.6709 - val_root_mean_squared_error: 94744.2109\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 3s 7ms/step - loss: 2683294976.0000 - r2: 0.8858 - root_mean_squared_error: 51800.5312 - val_loss: 10017227776.0000 - val_r2: 0.6325 - val_root_mean_squared_error: 100086.1016\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 2679342336.0000 - r2: 0.8858 - root_mean_squared_error: 51762.3633 - val_loss: 9120899072.0000 - val_r2: 0.6647 - val_root_mean_squared_error: 95503.3984\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2686502912.0000 - r2: 0.8857 - root_mean_squared_error: 51831.4844 - val_loss: 9470771200.0000 - val_r2: 0.6525 - val_root_mean_squared_error: 97317.8906\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2658900992.0000 - r2: 0.8868 - root_mean_squared_error: 51564.5312 - val_loss: 8974875648.0000 - val_r2: 0.6704 - val_root_mean_squared_error: 94735.8203\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2661784064.0000 - r2: 0.8867 - root_mean_squared_error: 51592.4805 - val_loss: 8976696320.0000 - val_r2: 0.6702 - val_root_mean_squared_error: 94745.4297\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2660565248.0000 - r2: 0.8867 - root_mean_squared_error: 51580.6680 - val_loss: 8873702400.0000 - val_r2: 0.6742 - val_root_mean_squared_error: 94200.3281\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2657414144.0000 - r2: 0.8869 - root_mean_squared_error: 51550.1133 - val_loss: 9900743680.0000 - val_r2: 0.6366 - val_root_mean_squared_error: 99502.4844\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2659458560.0000 - r2: 0.8871 - root_mean_squared_error: 51569.9375 - val_loss: 9417638912.0000 - val_r2: 0.6545 - val_root_mean_squared_error: 97044.5234\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2645992448.0000 - r2: 0.8874 - root_mean_squared_error: 51439.2109 - val_loss: 9532956672.0000 - val_r2: 0.6502 - val_root_mean_squared_error: 97636.8594\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2639194624.0000 - r2: 0.8877 - root_mean_squared_error: 51373.0938 - val_loss: 9175216128.0000 - val_r2: 0.6628 - val_root_mean_squared_error: 95787.3516\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2628442368.0000 - r2: 0.8879 - root_mean_squared_error: 51268.3359 - val_loss: 8640059392.0000 - val_r2: 0.6825 - val_root_mean_squared_error: 92951.9219\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2621949184.0000 - r2: 0.8884 - root_mean_squared_error: 51204.9727 - val_loss: 9584707584.0000 - val_r2: 0.6479 - val_root_mean_squared_error: 97901.5234\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2625239040.0000 - r2: 0.8883 - root_mean_squared_error: 51237.0859 - val_loss: 7659194368.0000 - val_r2: 0.7192 - val_root_mean_squared_error: 87516.8203\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2624200960.0000 - r2: 0.8884 - root_mean_squared_error: 51226.9570 - val_loss: 7909769728.0000 - val_r2: 0.7093 - val_root_mean_squared_error: 88936.8828\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 2613584384.0000 - r2: 0.8888 - root_mean_squared_error: 51123.2266 - val_loss: 9700218880.0000 - val_r2: 0.6432 - val_root_mean_squared_error: 98489.6875\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2610586368.0000 - r2: 0.8886 - root_mean_squared_error: 51093.8984 - val_loss: 7871426560.0000 - val_r2: 0.7111 - val_root_mean_squared_error: 88721.0625\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2620409600.0000 - r2: 0.8885 - root_mean_squared_error: 51189.9375 - val_loss: 9177812992.0000 - val_r2: 0.6621 - val_root_mean_squared_error: 95800.9062\n"
     ]
    }
   ],
   "source": [
    "# Building and fitting the best model again to get rid of the model with best epoch weights\n",
    "model = build_model(best_hps[0])\n",
    "# Training the model with best hyperparameters along with the callback to retain the model from the best epoch\n",
    "history = model.fit(train_ds, epochs=50, validation_data=test_ds, \n",
    "                    callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Apply model from Q2d on the 'old test set'. On the 'new test set', split it into 2021 and 2022/ For all 3 test sets report the test R2 value obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>full_address</th>\n",
       "      <th>nearest_stn</th>\n",
       "      <th>dist_to_nearest_stn</th>\n",
       "      <th>dist_to_dhoby</th>\n",
       "      <th>degree_centrality</th>\n",
       "      <th>eigenvector_centrality</th>\n",
       "      <th>flat_model_type</th>\n",
       "      <th>remaining_lease_years</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>resale_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>406 ANG MO KIO AVENUE 10</td>\n",
       "      <td>Ang Mo Kio</td>\n",
       "      <td>1.007264</td>\n",
       "      <td>7.006044</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>2 ROOM, Improved</td>\n",
       "      <td>61.333333</td>\n",
       "      <td>44.0</td>\n",
       "      <td>10 TO 12</td>\n",
       "      <td>232000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>108 ANG MO KIO AVENUE 4</td>\n",
       "      <td>Ang Mo Kio</td>\n",
       "      <td>1.271389</td>\n",
       "      <td>7.983837</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>3 ROOM, New Generation</td>\n",
       "      <td>60.583333</td>\n",
       "      <td>67.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>602 ANG MO KIO AVENUE 5</td>\n",
       "      <td>Yio Chu Kang</td>\n",
       "      <td>1.069743</td>\n",
       "      <td>9.090700</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>3 ROOM, New Generation</td>\n",
       "      <td>62.416667</td>\n",
       "      <td>67.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>262000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>465 ANG MO KIO AVENUE 10</td>\n",
       "      <td>Ang Mo Kio</td>\n",
       "      <td>0.946890</td>\n",
       "      <td>7.519889</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>3 ROOM, New Generation</td>\n",
       "      <td>62.083333</td>\n",
       "      <td>68.0</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>265000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>601 ANG MO KIO AVENUE 5</td>\n",
       "      <td>Yio Chu Kang</td>\n",
       "      <td>1.092551</td>\n",
       "      <td>9.130489</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>3 ROOM, New Generation</td>\n",
       "      <td>62.416667</td>\n",
       "      <td>67.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>265000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104089</th>\n",
       "      <td>8</td>\n",
       "      <td>2021</td>\n",
       "      <td>710 YISHUN AVENUE 5</td>\n",
       "      <td>Yishun</td>\n",
       "      <td>0.826153</td>\n",
       "      <td>14.410089</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>4 ROOM, New Generation</td>\n",
       "      <td>61.750000</td>\n",
       "      <td>93.0</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>390000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104090</th>\n",
       "      <td>8</td>\n",
       "      <td>2021</td>\n",
       "      <td>117 YISHUN RING ROAD</td>\n",
       "      <td>Yishun</td>\n",
       "      <td>1.045337</td>\n",
       "      <td>15.215236</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>4 ROOM, Model A</td>\n",
       "      <td>60.916667</td>\n",
       "      <td>104.0</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>380000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104091</th>\n",
       "      <td>8</td>\n",
       "      <td>2021</td>\n",
       "      <td>453 YISHUN STREET 41</td>\n",
       "      <td>Khatib</td>\n",
       "      <td>1.424543</td>\n",
       "      <td>13.350952</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>4 ROOM, Model A</td>\n",
       "      <td>91.083333</td>\n",
       "      <td>93.0</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>433000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104092</th>\n",
       "      <td>8</td>\n",
       "      <td>2021</td>\n",
       "      <td>505D YISHUN STREET 51</td>\n",
       "      <td>Khatib</td>\n",
       "      <td>1.259536</td>\n",
       "      <td>13.232993</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>4 ROOM, Model A</td>\n",
       "      <td>93.666667</td>\n",
       "      <td>93.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>460000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104093</th>\n",
       "      <td>8</td>\n",
       "      <td>2021</td>\n",
       "      <td>161 YISHUN STREET 11</td>\n",
       "      <td>Yishun</td>\n",
       "      <td>0.405275</td>\n",
       "      <td>14.841775</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>62.916667</td>\n",
       "      <td>126.0</td>\n",
       "      <td>10 TO 12</td>\n",
       "      <td>550000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104094 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        month  year              full_address   nearest_stn  \\\n",
       "0           1  2017  406 ANG MO KIO AVENUE 10    Ang Mo Kio   \n",
       "1           1  2017   108 ANG MO KIO AVENUE 4    Ang Mo Kio   \n",
       "2           1  2017   602 ANG MO KIO AVENUE 5  Yio Chu Kang   \n",
       "3           1  2017  465 ANG MO KIO AVENUE 10    Ang Mo Kio   \n",
       "4           1  2017   601 ANG MO KIO AVENUE 5  Yio Chu Kang   \n",
       "...       ...   ...                       ...           ...   \n",
       "104089      8  2021       710 YISHUN AVENUE 5        Yishun   \n",
       "104090      8  2021      117 YISHUN RING ROAD        Yishun   \n",
       "104091      8  2021      453 YISHUN STREET 41        Khatib   \n",
       "104092      8  2021     505D YISHUN STREET 51        Khatib   \n",
       "104093      8  2021      161 YISHUN STREET 11        Yishun   \n",
       "\n",
       "        dist_to_nearest_stn  dist_to_dhoby  degree_centrality  \\\n",
       "0                  1.007264       7.006044           0.016807   \n",
       "1                  1.271389       7.983837           0.016807   \n",
       "2                  1.069743       9.090700           0.016807   \n",
       "3                  0.946890       7.519889           0.016807   \n",
       "4                  1.092551       9.130489           0.016807   \n",
       "...                     ...            ...                ...   \n",
       "104089             0.826153      14.410089           0.016807   \n",
       "104090             1.045337      15.215236           0.016807   \n",
       "104091             1.424543      13.350952           0.016807   \n",
       "104092             1.259536      13.232993           0.016807   \n",
       "104093             0.405275      14.841775           0.016807   \n",
       "\n",
       "        eigenvector_centrality         flat_model_type  remaining_lease_years  \\\n",
       "0                     0.006243        2 ROOM, Improved              61.333333   \n",
       "1                     0.006243  3 ROOM, New Generation              60.583333   \n",
       "2                     0.002459  3 ROOM, New Generation              62.416667   \n",
       "3                     0.006243  3 ROOM, New Generation              62.083333   \n",
       "4                     0.002459  3 ROOM, New Generation              62.416667   \n",
       "...                        ...                     ...                    ...   \n",
       "104089                0.000382  4 ROOM, New Generation              61.750000   \n",
       "104090                0.000382         4 ROOM, Model A              60.916667   \n",
       "104091                0.000968         4 ROOM, Model A              91.083333   \n",
       "104092                0.000968         4 ROOM, Model A              93.666667   \n",
       "104093                0.000382        5 ROOM, Improved              62.916667   \n",
       "\n",
       "        floor_area_sqm storey_range  resale_price  \n",
       "0                 44.0     10 TO 12      232000.0  \n",
       "1                 67.0     01 TO 03      250000.0  \n",
       "2                 67.0     01 TO 03      262000.0  \n",
       "3                 68.0     04 TO 06      265000.0  \n",
       "4                 67.0     01 TO 03      265000.0  \n",
       "...                ...          ...           ...  \n",
       "104089            93.0     07 TO 09      390000.0  \n",
       "104090           104.0     07 TO 09      380000.0  \n",
       "104091            93.0     04 TO 06      433000.0  \n",
       "104092            93.0     01 TO 03      460000.0  \n",
       "104093           126.0     10 TO 12      550000.0  \n",
       "\n",
       "[104094 rows x 13 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_df = pd.read_csv('hdb_price_prediction_old.csv')\n",
    "old_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "old_test_dataframe = old_df[old_df.year>2020] # TODO\n",
    "new_test_2021_dataframe = df[df.year==2021]\n",
    "new_test_2022_dataframe = df[df.year==2022]\n",
    "\n",
    "old_test_ds = dataframe_to_dataset(old_test_dataframe)\n",
    "new_test_2021_ds = dataframe_to_dataset(new_test_2021_dataframe)\n",
    "new_test_2022_ds = dataframe_to_dataset(new_test_2022_dataframe)\n",
    "\n",
    "old_test_ds = old_test_ds.batch(256)\n",
    "new_test_2021_ds = new_test_2021_ds.batch(256)\n",
    "new_test_2022_ds = new_test_2022_ds.batch(256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test R2 Value for Old Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 3ms/step - loss: 4892076032.0000 - r2: 0.8113 - root_mean_squared_error: 69943.3750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8112819194793701"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(old_test_ds)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test R2 Value for New Test Set (2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1s 3ms/step - loss: 6251382272.0000 - r2: 0.7607 - root_mean_squared_error: 79065.6797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7606648802757263"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(new_test_2021_ds)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test R2 Value for New Test Set (2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 3ms/step - loss: 14184182784.0000 - r2: 0.4989 - root_mean_squared_error: 119097.3672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4988911747932434"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(new_test_2022_ds)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Compare the extent to which model model degradation has impacted your model to that of the team's linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The team's linear regression model degraded more than our neural network model.\n",
    "\n",
    "When we compare the Test R2 Value for our models on the different test sets we see that our model performs better across the different test sets having ~0.5 better R2 value than that of the linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why this has occured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression models can only predict values from sample data based on a linear equation of the weighted values from the sample.\n",
    "\n",
    "Neural networks are capable of predicting complex data due to the nature with which they are composed of many non linear transformations. Further, having a large number of neurons makes our model more robust and resistant to change due to the nature of multiple neurons working cohesively to predict rather than just a single weighted estimation of the sample data.\n",
    "\n",
    "This would make our model less perceptible to the change in the sample data as compared to the linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) With appropriate plots, visualise the distributions of all the features and labels used by the model. Which variable(s) showed the largest covariate/label shift that might have led to the drop in model performance as seen in Q3b?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To help in our plotting\n",
    "plot_year = lambda x:((2022,2021)[x==2021], 2020)[x<=2020]\n",
    "df['plot_year'] = df['year'].apply(plot_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Legend\n",
    "\n",
    "- **2020 - Less than or equal to 2020**\n",
    "- **2021 - data from 2021**\n",
    "- **2022 - data from 2022**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='month', ylabel='Count'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=df, x='month', hue='plot_year', kde=True, palette=['tab:green', 'tab:orange', 'tab:red'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in our plot for months we can see that the distribution for the year is different in the year 2021 and evidently there is no values for 2022 in October-December period since the data is not available to us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='flat_model_type', ylabel='Count'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=df, x='flat_model_type', hue='plot_year', kde=True, palette=['tab:green', 'tab:orange', 'tab:red'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from this plot there is no evident shift but the distribution is different for our different categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.2.total\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.2.count\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='dist_to_dhoby', ylabel='Count'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=df, x='dist_to_dhoby', hue='plot_year', kde=True, palette=['tab:green', 'tab:orange', 'tab:red'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance to Dhoby has a slight covariate/label shift between the categories as seen from the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='floor_area_sqm', ylabel='Count'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=df, x='floor_area_sqm', hue='plot_year', kde=True, palette=['tab:green', 'tab:orange', 'tab:red'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance to Dhoby has different distributions for the different categories but no evident label/covariate shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='remaining_lease_years', ylabel='Count'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=df, x='remaining_lease_years', hue='plot_year', kde=True, palette=['tab:green', 'tab:orange', 'tab:red'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remaining Lease Years has a slight covariate/label shift between the categories as seen from the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='degree_centrality', ylabel='Count'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=df, x='degree_centrality', hue='plot_year', kde=True, palette=['tab:green', 'tab:orange', 'tab:red'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suggest a way to address the problem of model degradation.\n",
    "\n",
    "Remove the variables/features that are likely to have a covariate/label shift between the train and the test data.\n",
    "\n",
    "If there is a clear, visible covariate shift between our train and test data then we should remove that data since our model would not be able to predict the values correctly as there is a shift in the variance of data.\n",
    "\n",
    "A covariate shift indicates that the range/block of values is different and has been shifted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) The team passed you a script (â€˜RFE.pyâ€™) that recursively removes features from a neural network, so as to find the best feature subset. Run this piece of code with your model from Q2d and report the best feature subset obtained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data basedd on conditions given\n",
    "train_dataframe = df[df.year<=2020] # TODO\n",
    "test_dataframe = df[df.year>2020] # TODO\n",
    "\n",
    "train_ds = dataframe_to_dataset(train_dataframe)\n",
    "test_ds = dataframe_to_dataset(test_dataframe)\n",
    "\n",
    "train_ds = train_ds.batch(256)\n",
    "test_ds = test_ds.batch(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec [1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "ix 0 i 1\n",
      "updated temp_vec [0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "going through feature_mask [0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 12), dtype=tf.float32, name=None), name='flatten_9/Reshape:0', description=\"created by layer 'flatten_9'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 17), dtype=tf.float32, name=None), name='flatten_11/Reshape:0', description=\"created by layer 'flatten_11'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 43), dtype=tf.float32, name=None), name='flatten_10/Reshape:0', description=\"created by layer 'flatten_10'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_18/truediv:0', description=\"created by layer 'normalization_18'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_19/truediv:0', description=\"created by layer 'normalization_19'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_20/truediv:0', description=\"created by layer 'normalization_20'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_21/truediv:0', description=\"created by layer 'normalization_21'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_22/truediv:0', description=\"created by layer 'normalization_22'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_23/truediv:0', description=\"created by layer 'normalization_23'\")\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/NIHALARY001/CZ1016/base/lib/python3.8/site-packages/keras/engine/functional.py:637: UserWarning: Input dict contained keys ['year', 'full_address', 'nearest_stn', 'plot_year'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342/342 [==============================] - 3s 7ms/step - loss: 40502145024.0000 - r2: -0.7186 - root_mean_squared_error: 201251.4531 - val_loss: 14467784704.0000 - val_r2: 0.4707 - val_root_mean_squared_error: 120282.1016\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 7633795072.0000 - r2: 0.6764 - root_mean_squared_error: 87371.5938 - val_loss: 13255220224.0000 - val_r2: 0.5157 - val_root_mean_squared_error: 115131.3203\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 6796217856.0000 - r2: 0.7119 - root_mean_squared_error: 82439.1797 - val_loss: 12286391296.0000 - val_r2: 0.5506 - val_root_mean_squared_error: 110843.9922\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 5996252672.0000 - r2: 0.7456 - root_mean_squared_error: 77435.4766 - val_loss: 10781586432.0000 - val_r2: 0.6053 - val_root_mean_squared_error: 103834.4219\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 5343011328.0000 - r2: 0.7732 - root_mean_squared_error: 73095.9062 - val_loss: 11847855104.0000 - val_r2: 0.5663 - val_root_mean_squared_error: 108847.8516\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 4899577344.0000 - r2: 0.7916 - root_mean_squared_error: 69996.9844 - val_loss: 11265198080.0000 - val_r2: 0.5873 - val_root_mean_squared_error: 106137.6406\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 4576036352.0000 - r2: 0.8058 - root_mean_squared_error: 67646.4062 - val_loss: 10522146816.0000 - val_r2: 0.6151 - val_root_mean_squared_error: 102577.5156\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 4316023808.0000 - r2: 0.8168 - root_mean_squared_error: 65696.4531 - val_loss: 9935371264.0000 - val_r2: 0.6357 - val_root_mean_squared_error: 99676.3359\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 4109478656.0000 - r2: 0.8253 - root_mean_squared_error: 64105.2148 - val_loss: 10071559168.0000 - val_r2: 0.6313 - val_root_mean_squared_error: 100357.1562\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3971352832.0000 - r2: 0.8311 - root_mean_squared_error: 63018.6719 - val_loss: 10673225728.0000 - val_r2: 0.6089 - val_root_mean_squared_error: 103311.3047\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 3s 5ms/step - loss: 3881392128.0000 - r2: 0.8352 - root_mean_squared_error: 62300.8203 - val_loss: 9910566912.0000 - val_r2: 0.6367 - val_root_mean_squared_error: 99551.8281\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3824285184.0000 - r2: 0.8376 - root_mean_squared_error: 61840.8047 - val_loss: 10645193728.0000 - val_r2: 0.6099 - val_root_mean_squared_error: 103175.5469\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3786140160.0000 - r2: 0.8391 - root_mean_squared_error: 61531.6211 - val_loss: 10049191936.0000 - val_r2: 0.6318 - val_root_mean_squared_error: 100245.6562\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3776621056.0000 - r2: 0.8397 - root_mean_squared_error: 61454.2188 - val_loss: 10426478592.0000 - val_r2: 0.6180 - val_root_mean_squared_error: 102110.1328\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3754533632.0000 - r2: 0.8405 - root_mean_squared_error: 61274.2500 - val_loss: 9496577024.0000 - val_r2: 0.6518 - val_root_mean_squared_error: 97450.3828\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3744751104.0000 - r2: 0.8408 - root_mean_squared_error: 61194.3711 - val_loss: 10783881216.0000 - val_r2: 0.6049 - val_root_mean_squared_error: 103845.4688\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3732980224.0000 - r2: 0.8411 - root_mean_squared_error: 61098.1211 - val_loss: 9994461184.0000 - val_r2: 0.6340 - val_root_mean_squared_error: 99972.3047\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3717211648.0000 - r2: 0.8422 - root_mean_squared_error: 60968.9414 - val_loss: 10353815552.0000 - val_r2: 0.6208 - val_root_mean_squared_error: 101753.7031\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3721049856.0000 - r2: 0.8416 - root_mean_squared_error: 61000.4102 - val_loss: 8450651648.0000 - val_r2: 0.6906 - val_root_mean_squared_error: 91927.4297\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 3s 7ms/step - loss: 3709696512.0000 - r2: 0.8425 - root_mean_squared_error: 60907.2773 - val_loss: 11186938880.0000 - val_r2: 0.5893 - val_root_mean_squared_error: 105768.3281\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3705259264.0000 - r2: 0.8427 - root_mean_squared_error: 60870.8398 - val_loss: 10042629120.0000 - val_r2: 0.6319 - val_root_mean_squared_error: 100212.9219\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3696279808.0000 - r2: 0.8432 - root_mean_squared_error: 60797.0391 - val_loss: 10183143424.0000 - val_r2: 0.6271 - val_root_mean_squared_error: 100911.5625\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3703565568.0000 - r2: 0.8428 - root_mean_squared_error: 60856.9258 - val_loss: 10491545600.0000 - val_r2: 0.6158 - val_root_mean_squared_error: 102428.2500\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3692093696.0000 - r2: 0.8434 - root_mean_squared_error: 60762.6016 - val_loss: 11717138432.0000 - val_r2: 0.5702 - val_root_mean_squared_error: 108245.7344\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3693076736.0000 - r2: 0.8428 - root_mean_squared_error: 60770.6914 - val_loss: 12160889856.0000 - val_r2: 0.5539 - val_root_mean_squared_error: 110276.4219\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3688556032.0000 - r2: 0.8430 - root_mean_squared_error: 60733.4844 - val_loss: 8926233600.0000 - val_r2: 0.6728 - val_root_mean_squared_error: 94478.7500\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3684662528.0000 - r2: 0.8435 - root_mean_squared_error: 60701.4219 - val_loss: 11674845184.0000 - val_r2: 0.5714 - val_root_mean_squared_error: 108050.1953\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3679923712.0000 - r2: 0.8437 - root_mean_squared_error: 60662.3750 - val_loss: 10457298944.0000 - val_r2: 0.6164 - val_root_mean_squared_error: 102260.9375\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3680846592.0000 - r2: 0.8439 - root_mean_squared_error: 60669.9805 - val_loss: 10248978432.0000 - val_r2: 0.6245 - val_root_mean_squared_error: 101237.2422\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3676806144.0000 - r2: 0.8441 - root_mean_squared_error: 60636.6719 - val_loss: 10281883648.0000 - val_r2: 0.6231 - val_root_mean_squared_error: 101399.6250\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3665759744.0000 - r2: 0.8443 - root_mean_squared_error: 60545.5195 - val_loss: 9685567488.0000 - val_r2: 0.6448 - val_root_mean_squared_error: 98415.2812\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3671665664.0000 - r2: 0.8441 - root_mean_squared_error: 60594.2695 - val_loss: 10253383680.0000 - val_r2: 0.6236 - val_root_mean_squared_error: 101258.9922\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3671652864.0000 - r2: 0.8440 - root_mean_squared_error: 60594.1641 - val_loss: 10979608576.0000 - val_r2: 0.5969 - val_root_mean_squared_error: 104783.6250\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3677343488.0000 - r2: 0.8434 - root_mean_squared_error: 60641.1055 - val_loss: 9172515840.0000 - val_r2: 0.6634 - val_root_mean_squared_error: 95773.2500\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3665564672.0000 - r2: 0.8441 - root_mean_squared_error: 60543.9062 - val_loss: 9365945344.0000 - val_r2: 0.6562 - val_root_mean_squared_error: 96777.8125\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3671489792.0000 - r2: 0.8439 - root_mean_squared_error: 60592.8203 - val_loss: 9656759296.0000 - val_r2: 0.6457 - val_root_mean_squared_error: 98268.8125\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3675138560.0000 - r2: 0.8437 - root_mean_squared_error: 60622.9219 - val_loss: 11090725888.0000 - val_r2: 0.5932 - val_root_mean_squared_error: 105312.5156\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3671687936.0000 - r2: 0.8441 - root_mean_squared_error: 60594.4531 - val_loss: 9637836800.0000 - val_r2: 0.6473 - val_root_mean_squared_error: 98172.4844\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3679194880.0000 - r2: 0.8434 - root_mean_squared_error: 60656.3672 - val_loss: 10657610752.0000 - val_r2: 0.6090 - val_root_mean_squared_error: 103235.7031\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3683574272.0000 - r2: 0.8436 - root_mean_squared_error: 60692.4570 - val_loss: 9539677184.0000 - val_r2: 0.6506 - val_root_mean_squared_error: 97671.2734\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3663881984.0000 - r2: 0.8443 - root_mean_squared_error: 60530.0078 - val_loss: 8893986816.0000 - val_r2: 0.6739 - val_root_mean_squared_error: 94307.9375\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3678503680.0000 - r2: 0.8437 - root_mean_squared_error: 60650.6680 - val_loss: 11347581952.0000 - val_r2: 0.5837 - val_root_mean_squared_error: 106525.0312\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3662707968.0000 - r2: 0.8446 - root_mean_squared_error: 60520.3086 - val_loss: 9924539392.0000 - val_r2: 0.6355 - val_root_mean_squared_error: 99621.9844\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3676773376.0000 - r2: 0.8437 - root_mean_squared_error: 60636.4023 - val_loss: 10940656640.0000 - val_r2: 0.5991 - val_root_mean_squared_error: 104597.5938\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 3s 7ms/step - loss: 3662045440.0000 - r2: 0.8443 - root_mean_squared_error: 60514.8359 - val_loss: 11579786240.0000 - val_r2: 0.5746 - val_root_mean_squared_error: 107609.4141\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3661128448.0000 - r2: 0.8444 - root_mean_squared_error: 60507.2578 - val_loss: 10721792000.0000 - val_r2: 0.6072 - val_root_mean_squared_error: 103546.0859\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3375161856.0000 - r2: 0.8566 - root_mean_squared_error: 58096.1445 - val_loss: 9572118528.0000 - val_r2: 0.6484 - val_root_mean_squared_error: 97837.2031\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 3091441920.0000 - r2: 0.8684 - root_mean_squared_error: 55600.7383 - val_loss: 9753241600.0000 - val_r2: 0.6426 - val_root_mean_squared_error: 98758.5000\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 2944745472.0000 - r2: 0.8745 - root_mean_squared_error: 54265.5078 - val_loss: 9243959296.0000 - val_r2: 0.6610 - val_root_mean_squared_error: 96145.5078\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 2816534016.0000 - r2: 0.8802 - root_mean_squared_error: 53071.0273 - val_loss: 9275381760.0000 - val_r2: 0.6593 - val_root_mean_squared_error: 96308.7812\n",
      "new min loss: len 9, ix 0\n",
      "session cleared!\n",
      "\n",
      "ix 1 i 1\n",
      "updated temp_vec [1, 0, 1, 1, 1, 1, 1, 1, 1]\n",
      "going through feature_mask [1, 0, 1, 1, 1, 1, 1, 1, 1]\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 12), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 17), dtype=tf.float32, name=None), name='flatten_2/Reshape:0', description=\"created by layer 'flatten_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 43), dtype=tf.float32, name=None), name='flatten_1/Reshape:0', description=\"created by layer 'flatten_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization/truediv:0', description=\"created by layer 'normalization'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_1/truediv:0', description=\"created by layer 'normalization_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_2/truediv:0', description=\"created by layer 'normalization_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_3/truediv:0', description=\"created by layer 'normalization_3'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_4/truediv:0', description=\"created by layer 'normalization_4'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_5/truediv:0', description=\"created by layer 'normalization_5'\")\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 4s 7ms/step - loss: 38167080960.0000 - r2: -0.5945 - root_mean_squared_error: 195363.9688 - val_loss: 16472045568.0000 - val_r2: 0.3995 - val_root_mean_squared_error: 128343.4688\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 8622194688.0000 - r2: 0.6354 - root_mean_squared_error: 92855.7734 - val_loss: 15342069760.0000 - val_r2: 0.4401 - val_root_mean_squared_error: 123863.1094\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 7221303296.0000 - r2: 0.6945 - root_mean_squared_error: 84978.2500 - val_loss: 13967791104.0000 - val_r2: 0.4899 - val_root_mean_squared_error: 118185.4062\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 6141412352.0000 - r2: 0.7399 - root_mean_squared_error: 78367.1641 - val_loss: 11369612288.0000 - val_r2: 0.5844 - val_root_mean_squared_error: 106628.3828\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5488466944.0000 - r2: 0.7677 - root_mean_squared_error: 74084.1875 - val_loss: 12846174208.0000 - val_r2: 0.5301 - val_root_mean_squared_error: 113340.9609\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4959304704.0000 - r2: 0.7898 - root_mean_squared_error: 70422.3281 - val_loss: 10860362752.0000 - val_r2: 0.6024 - val_root_mean_squared_error: 104213.0625\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4594765824.0000 - r2: 0.8049 - root_mean_squared_error: 67784.7031 - val_loss: 10671598592.0000 - val_r2: 0.6090 - val_root_mean_squared_error: 103303.4297\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4305462784.0000 - r2: 0.8168 - root_mean_squared_error: 65616.0234 - val_loss: 10096568320.0000 - val_r2: 0.6304 - val_root_mean_squared_error: 100481.6797\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4088615424.0000 - r2: 0.8264 - root_mean_squared_error: 63942.2812 - val_loss: 10769849344.0000 - val_r2: 0.6055 - val_root_mean_squared_error: 103777.8828\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3899927040.0000 - r2: 0.8346 - root_mean_squared_error: 62449.3945 - val_loss: 10279864320.0000 - val_r2: 0.6231 - val_root_mean_squared_error: 101389.6641\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3705311488.0000 - r2: 0.8428 - root_mean_squared_error: 60871.2695 - val_loss: 11389900800.0000 - val_r2: 0.5825 - val_root_mean_squared_error: 106723.4766\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3568600320.0000 - r2: 0.8480 - root_mean_squared_error: 59737.7617 - val_loss: 9484432384.0000 - val_r2: 0.6521 - val_root_mean_squared_error: 97388.0469\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3448421376.0000 - r2: 0.8535 - root_mean_squared_error: 58723.2617 - val_loss: 10573956096.0000 - val_r2: 0.6123 - val_root_mean_squared_error: 102829.7422\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3399148032.0000 - r2: 0.8554 - root_mean_squared_error: 58302.2148 - val_loss: 10400595968.0000 - val_r2: 0.6178 - val_root_mean_squared_error: 101983.3125\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3358166528.0000 - r2: 0.8572 - root_mean_squared_error: 57949.6914 - val_loss: 9930300416.0000 - val_r2: 0.6354 - val_root_mean_squared_error: 99650.8906\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3320433664.0000 - r2: 0.8588 - root_mean_squared_error: 57623.2031 - val_loss: 10572296192.0000 - val_r2: 0.6125 - val_root_mean_squared_error: 102821.6719\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3294286080.0000 - r2: 0.8599 - root_mean_squared_error: 57395.8711 - val_loss: 9863570432.0000 - val_r2: 0.6380 - val_root_mean_squared_error: 99315.5078\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3264328960.0000 - r2: 0.8612 - root_mean_squared_error: 57134.3047 - val_loss: 10944329728.0000 - val_r2: 0.5989 - val_root_mean_squared_error: 104615.1484\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3236780544.0000 - r2: 0.8624 - root_mean_squared_error: 56892.7109 - val_loss: 11686296576.0000 - val_r2: 0.5711 - val_root_mean_squared_error: 108103.1719\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3217524992.0000 - r2: 0.8630 - root_mean_squared_error: 56723.2305 - val_loss: 10419842048.0000 - val_r2: 0.6183 - val_root_mean_squared_error: 102077.6250\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3190083584.0000 - r2: 0.8643 - root_mean_squared_error: 56480.8242 - val_loss: 12531163136.0000 - val_r2: 0.5397 - val_root_mean_squared_error: 111942.6797\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3176452352.0000 - r2: 0.8648 - root_mean_squared_error: 56360.0234 - val_loss: 9736755200.0000 - val_r2: 0.6433 - val_root_mean_squared_error: 98675.0000\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3159555328.0000 - r2: 0.8656 - root_mean_squared_error: 56209.9219 - val_loss: 9648437248.0000 - val_r2: 0.6459 - val_root_mean_squared_error: 98226.4609\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3149050624.0000 - r2: 0.8661 - root_mean_squared_error: 56116.4023 - val_loss: 13163295744.0000 - val_r2: 0.5163 - val_root_mean_squared_error: 114731.4062\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3132980224.0000 - r2: 0.8670 - root_mean_squared_error: 55973.0312 - val_loss: 9546546176.0000 - val_r2: 0.6497 - val_root_mean_squared_error: 97706.4297\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3117841408.0000 - r2: 0.8673 - root_mean_squared_error: 55837.6328 - val_loss: 10114139136.0000 - val_r2: 0.6288 - val_root_mean_squared_error: 100569.0781\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3095183872.0000 - r2: 0.8685 - root_mean_squared_error: 55634.3750 - val_loss: 9811908608.0000 - val_r2: 0.6399 - val_root_mean_squared_error: 99055.0781\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3085839872.0000 - r2: 0.8688 - root_mean_squared_error: 55550.3359 - val_loss: 11149708288.0000 - val_r2: 0.5913 - val_root_mean_squared_error: 105592.1797\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3052101376.0000 - r2: 0.8704 - root_mean_squared_error: 55245.8281 - val_loss: 8735852544.0000 - val_r2: 0.6793 - val_root_mean_squared_error: 93465.7812\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3042302208.0000 - r2: 0.8706 - root_mean_squared_error: 55157.0703 - val_loss: 9671615488.0000 - val_r2: 0.6452 - val_root_mean_squared_error: 98344.3750\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3018424576.0000 - r2: 0.8717 - root_mean_squared_error: 54940.1914 - val_loss: 9299892224.0000 - val_r2: 0.6590 - val_root_mean_squared_error: 96435.9453\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3006754304.0000 - r2: 0.8718 - root_mean_squared_error: 54833.8789 - val_loss: 10057359360.0000 - val_r2: 0.6316 - val_root_mean_squared_error: 100286.3828\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2970902272.0000 - r2: 0.8741 - root_mean_squared_error: 54505.9844 - val_loss: 8910199808.0000 - val_r2: 0.6725 - val_root_mean_squared_error: 94393.8516\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2953609984.0000 - r2: 0.8745 - root_mean_squared_error: 54347.1250 - val_loss: 10091710464.0000 - val_r2: 0.6292 - val_root_mean_squared_error: 100457.5078\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2932679168.0000 - r2: 0.8753 - root_mean_squared_error: 54154.2148 - val_loss: 8652764160.0000 - val_r2: 0.6828 - val_root_mean_squared_error: 93020.2344\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2931068160.0000 - r2: 0.8752 - root_mean_squared_error: 54139.3398 - val_loss: 10896999424.0000 - val_r2: 0.6003 - val_root_mean_squared_error: 104388.6953\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2902642688.0000 - r2: 0.8767 - root_mean_squared_error: 53876.1797 - val_loss: 10492698624.0000 - val_r2: 0.6144 - val_root_mean_squared_error: 102433.8750\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2905134336.0000 - r2: 0.8765 - root_mean_squared_error: 53899.2969 - val_loss: 9002090496.0000 - val_r2: 0.6692 - val_root_mean_squared_error: 94879.3438\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2888410368.0000 - r2: 0.8771 - root_mean_squared_error: 53743.9336 - val_loss: 9209684992.0000 - val_r2: 0.6620 - val_root_mean_squared_error: 95967.1016\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2889615616.0000 - r2: 0.8771 - root_mean_squared_error: 53755.1445 - val_loss: 9171511296.0000 - val_r2: 0.6641 - val_root_mean_squared_error: 95768.0078\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2890183168.0000 - r2: 0.8773 - root_mean_squared_error: 53760.4219 - val_loss: 8298803712.0000 - val_r2: 0.6958 - val_root_mean_squared_error: 91097.7734\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2869947904.0000 - r2: 0.8780 - root_mean_squared_error: 53571.8945 - val_loss: 10369817600.0000 - val_r2: 0.6194 - val_root_mean_squared_error: 101832.3047\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2865415424.0000 - r2: 0.8782 - root_mean_squared_error: 53529.5742 - val_loss: 9544711168.0000 - val_r2: 0.6490 - val_root_mean_squared_error: 97697.0391\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2857034752.0000 - r2: 0.8786 - root_mean_squared_error: 53451.2383 - val_loss: 8839203840.0000 - val_r2: 0.6755 - val_root_mean_squared_error: 94017.0391\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2859721984.0000 - r2: 0.8782 - root_mean_squared_error: 53476.3672 - val_loss: 8207024128.0000 - val_r2: 0.6990 - val_root_mean_squared_error: 90592.6250\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2849615872.0000 - r2: 0.8790 - root_mean_squared_error: 53381.7930 - val_loss: 9661553664.0000 - val_r2: 0.6455 - val_root_mean_squared_error: 98293.2031\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2847444224.0000 - r2: 0.8786 - root_mean_squared_error: 53361.4492 - val_loss: 9031346176.0000 - val_r2: 0.6690 - val_root_mean_squared_error: 95033.3984\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2839697664.0000 - r2: 0.8793 - root_mean_squared_error: 53288.8125 - val_loss: 9252024320.0000 - val_r2: 0.6601 - val_root_mean_squared_error: 96187.4453\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2837052160.0000 - r2: 0.8791 - root_mean_squared_error: 53263.9844 - val_loss: 8739449856.0000 - val_r2: 0.6789 - val_root_mean_squared_error: 93485.0234\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2836128512.0000 - r2: 0.8793 - root_mean_squared_error: 53255.3125 - val_loss: 9860250624.0000 - val_r2: 0.6379 - val_root_mean_squared_error: 99298.7969\n",
      "new min loss: len 9, ix 1\n",
      "session cleared!\n",
      "\n",
      "ix 2 i 1\n",
      "updated temp_vec [1, 1, 0, 1, 1, 1, 1, 1, 1]\n",
      "going through feature_mask [1, 1, 0, 1, 1, 1, 1, 1, 1]\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 12), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 17), dtype=tf.float32, name=None), name='flatten_2/Reshape:0', description=\"created by layer 'flatten_2'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 43), dtype=tf.float32, name=None), name='flatten_1/Reshape:0', description=\"created by layer 'flatten_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization/truediv:0', description=\"created by layer 'normalization'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_1/truediv:0', description=\"created by layer 'normalization_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_2/truediv:0', description=\"created by layer 'normalization_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_3/truediv:0', description=\"created by layer 'normalization_3'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_4/truediv:0', description=\"created by layer 'normalization_4'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_5/truediv:0', description=\"created by layer 'normalization_5'\")\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 3s 5ms/step - loss: 50491985920.0000 - r2: -1.1450 - root_mean_squared_error: 224704.2188 - val_loss: 27548438528.0000 - val_r2: -0.0059 - val_root_mean_squared_error: 165977.2188\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 16323340288.0000 - r2: 0.3085 - root_mean_squared_error: 127762.8281 - val_loss: 24152838144.0000 - val_r2: 0.1164 - val_root_mean_squared_error: 155411.8281\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 12922941440.0000 - r2: 0.4528 - root_mean_squared_error: 113679.1172 - val_loss: 19918428160.0000 - val_r2: 0.2716 - val_root_mean_squared_error: 141132.6562\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 8965850112.0000 - r2: 0.6203 - root_mean_squared_error: 94688.1719 - val_loss: 14480198656.0000 - val_r2: 0.4706 - val_root_mean_squared_error: 120333.6953\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6011614720.0000 - r2: 0.7453 - root_mean_squared_error: 77534.6016 - val_loss: 12478654464.0000 - val_r2: 0.5432 - val_root_mean_squared_error: 111707.8984\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4709059584.0000 - r2: 0.8005 - root_mean_squared_error: 68622.5859 - val_loss: 11001326592.0000 - val_r2: 0.5976 - val_root_mean_squared_error: 104887.2109\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4359740928.0000 - r2: 0.8148 - root_mean_squared_error: 66028.3359 - val_loss: 10697355264.0000 - val_r2: 0.6083 - val_root_mean_squared_error: 103428.0234\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4091912448.0000 - r2: 0.8265 - root_mean_squared_error: 63968.0586 - val_loss: 10006971392.0000 - val_r2: 0.6333 - val_root_mean_squared_error: 100034.8516\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3824699392.0000 - r2: 0.8376 - root_mean_squared_error: 61844.1523 - val_loss: 11531648000.0000 - val_r2: 0.5770 - val_root_mean_squared_error: 107385.5078\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3629229568.0000 - r2: 0.8458 - root_mean_squared_error: 60243.0859 - val_loss: 9249470464.0000 - val_r2: 0.6605 - val_root_mean_squared_error: 96174.1641\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3528783360.0000 - r2: 0.8505 - root_mean_squared_error: 59403.5625 - val_loss: 11916647424.0000 - val_r2: 0.5630 - val_root_mean_squared_error: 109163.3984\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3456871936.0000 - r2: 0.8532 - root_mean_squared_error: 58795.1680 - val_loss: 9204044800.0000 - val_r2: 0.6631 - val_root_mean_squared_error: 95937.7109\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3385084672.0000 - r2: 0.8560 - root_mean_squared_error: 58181.4805 - val_loss: 10667772928.0000 - val_r2: 0.6081 - val_root_mean_squared_error: 103284.9141\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3331168512.0000 - r2: 0.8583 - root_mean_squared_error: 57716.2773 - val_loss: 10177795072.0000 - val_r2: 0.6264 - val_root_mean_squared_error: 100885.0625\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3298376448.0000 - r2: 0.8598 - root_mean_squared_error: 57431.4922 - val_loss: 10458338304.0000 - val_r2: 0.6162 - val_root_mean_squared_error: 102266.0156\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3263295744.0000 - r2: 0.8612 - root_mean_squared_error: 57125.2617 - val_loss: 10718753792.0000 - val_r2: 0.6072 - val_root_mean_squared_error: 103531.4141\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3250731264.0000 - r2: 0.8620 - root_mean_squared_error: 57015.1836 - val_loss: 9498092544.0000 - val_r2: 0.6509 - val_root_mean_squared_error: 97458.1562\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3208212992.0000 - r2: 0.8636 - root_mean_squared_error: 56641.0898 - val_loss: 10742773760.0000 - val_r2: 0.6061 - val_root_mean_squared_error: 103647.3516\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3195148544.0000 - r2: 0.8639 - root_mean_squared_error: 56525.6445 - val_loss: 10209790976.0000 - val_r2: 0.6244 - val_root_mean_squared_error: 101043.5078\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3170767104.0000 - r2: 0.8652 - root_mean_squared_error: 56309.5664 - val_loss: 10437654528.0000 - val_r2: 0.6163 - val_root_mean_squared_error: 102164.8438\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3141563648.0000 - r2: 0.8660 - root_mean_squared_error: 56049.6523 - val_loss: 9486460928.0000 - val_r2: 0.6518 - val_root_mean_squared_error: 97398.4609\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3122745344.0000 - r2: 0.8668 - root_mean_squared_error: 55881.5312 - val_loss: 9073141760.0000 - val_r2: 0.6661 - val_root_mean_squared_error: 95253.0391\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3108178944.0000 - r2: 0.8678 - root_mean_squared_error: 55751.0430 - val_loss: 10075205632.0000 - val_r2: 0.6312 - val_root_mean_squared_error: 100375.3203\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3076337920.0000 - r2: 0.8689 - root_mean_squared_error: 55464.7461 - val_loss: 8866472960.0000 - val_r2: 0.6740 - val_root_mean_squared_error: 94161.9531\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3051668736.0000 - r2: 0.8703 - root_mean_squared_error: 55241.9102 - val_loss: 9707361280.0000 - val_r2: 0.6438 - val_root_mean_squared_error: 98525.9453\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3020380928.0000 - r2: 0.8715 - root_mean_squared_error: 54957.9922 - val_loss: 9064683520.0000 - val_r2: 0.6676 - val_root_mean_squared_error: 95208.6328\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2990659584.0000 - r2: 0.8727 - root_mean_squared_error: 54686.9219 - val_loss: 9748921344.0000 - val_r2: 0.6425 - val_root_mean_squared_error: 98736.6250\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2976560640.0000 - r2: 0.8730 - root_mean_squared_error: 54557.8633 - val_loss: 10291527680.0000 - val_r2: 0.6228 - val_root_mean_squared_error: 101447.1641\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2963188992.0000 - r2: 0.8739 - root_mean_squared_error: 54435.1797 - val_loss: 11451926528.0000 - val_r2: 0.5794 - val_root_mean_squared_error: 107013.6719\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2954975232.0000 - r2: 0.8740 - root_mean_squared_error: 54359.6836 - val_loss: 9517869056.0000 - val_r2: 0.6505 - val_root_mean_squared_error: 97559.5703\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2932446976.0000 - r2: 0.8752 - root_mean_squared_error: 54152.0742 - val_loss: 9272159232.0000 - val_r2: 0.6592 - val_root_mean_squared_error: 96292.0547\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2923295232.0000 - r2: 0.8755 - root_mean_squared_error: 54067.5078 - val_loss: 10233943040.0000 - val_r2: 0.6245 - val_root_mean_squared_error: 101162.9531\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2919896832.0000 - r2: 0.8757 - root_mean_squared_error: 54036.0703 - val_loss: 9339862016.0000 - val_r2: 0.6578 - val_root_mean_squared_error: 96642.9609\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2907254272.0000 - r2: 0.8762 - root_mean_squared_error: 53918.9609 - val_loss: 8771070976.0000 - val_r2: 0.6785 - val_root_mean_squared_error: 93653.9922\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2897943808.0000 - r2: 0.8769 - root_mean_squared_error: 53832.5547 - val_loss: 9633424384.0000 - val_r2: 0.6464 - val_root_mean_squared_error: 98150.0078\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2892830208.0000 - r2: 0.8770 - root_mean_squared_error: 53785.0352 - val_loss: 10376032256.0000 - val_r2: 0.6185 - val_root_mean_squared_error: 101862.8125\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2870072320.0000 - r2: 0.8780 - root_mean_squared_error: 53573.0547 - val_loss: 9972458496.0000 - val_r2: 0.6331 - val_root_mean_squared_error: 99862.1953\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2866268672.0000 - r2: 0.8780 - root_mean_squared_error: 53537.5430 - val_loss: 9674379264.0000 - val_r2: 0.6447 - val_root_mean_squared_error: 98358.4219\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2854162688.0000 - r2: 0.8783 - root_mean_squared_error: 53424.3633 - val_loss: 9563686912.0000 - val_r2: 0.6492 - val_root_mean_squared_error: 97794.1016\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2846163456.0000 - r2: 0.8791 - root_mean_squared_error: 53349.4453 - val_loss: 9145607168.0000 - val_r2: 0.6640 - val_root_mean_squared_error: 95632.6641\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2837168384.0000 - r2: 0.8793 - root_mean_squared_error: 53265.0781 - val_loss: 7777756672.0000 - val_r2: 0.7140 - val_root_mean_squared_error: 88191.5938\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2821761536.0000 - r2: 0.8800 - root_mean_squared_error: 53120.2539 - val_loss: 9439195136.0000 - val_r2: 0.6539 - val_root_mean_squared_error: 97155.5234\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2813257728.0000 - r2: 0.8804 - root_mean_squared_error: 53040.1523 - val_loss: 8115811328.0000 - val_r2: 0.7015 - val_root_mean_squared_error: 90087.7969\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2799896832.0000 - r2: 0.8808 - root_mean_squared_error: 52914.0508 - val_loss: 8371118592.0000 - val_r2: 0.6929 - val_root_mean_squared_error: 91493.8203\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2807567104.0000 - r2: 0.8806 - root_mean_squared_error: 52986.4805 - val_loss: 9504395264.0000 - val_r2: 0.6510 - val_root_mean_squared_error: 97490.4844\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2792112896.0000 - r2: 0.8811 - root_mean_squared_error: 52840.4492 - val_loss: 8650498048.0000 - val_r2: 0.6822 - val_root_mean_squared_error: 93008.0547\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2790375424.0000 - r2: 0.8812 - root_mean_squared_error: 52824.0039 - val_loss: 8100221440.0000 - val_r2: 0.7028 - val_root_mean_squared_error: 90001.2266\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2784158976.0000 - r2: 0.8815 - root_mean_squared_error: 52765.1289 - val_loss: 9869726720.0000 - val_r2: 0.6380 - val_root_mean_squared_error: 99346.5000\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2778175744.0000 - r2: 0.8819 - root_mean_squared_error: 52708.4023 - val_loss: 10024181760.0000 - val_r2: 0.6324 - val_root_mean_squared_error: 100120.8359\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2783279616.0000 - r2: 0.8814 - root_mean_squared_error: 52756.7969 - val_loss: 9019781120.0000 - val_r2: 0.6697 - val_root_mean_squared_error: 94972.5312\n",
      "new min loss: len 9, ix 2\n",
      "session cleared!\n",
      "\n",
      "ix 3 i 1\n",
      "updated temp_vec [1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "going through feature_mask [1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 12), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 17), dtype=tf.float32, name=None), name='flatten_2/Reshape:0', description=\"created by layer 'flatten_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 43), dtype=tf.float32, name=None), name='flatten_1/Reshape:0', description=\"created by layer 'flatten_1'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization/truediv:0', description=\"created by layer 'normalization'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_1/truediv:0', description=\"created by layer 'normalization_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_2/truediv:0', description=\"created by layer 'normalization_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_3/truediv:0', description=\"created by layer 'normalization_3'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_4/truediv:0', description=\"created by layer 'normalization_4'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_5/truediv:0', description=\"created by layer 'normalization_5'\")\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 3s 5ms/step - loss: 38331555840.0000 - r2: -0.6469 - root_mean_squared_error: 195784.4688 - val_loss: 14550808576.0000 - val_r2: 0.4683 - val_root_mean_squared_error: 120626.7344\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7614723584.0000 - r2: 0.6774 - root_mean_squared_error: 87262.3828 - val_loss: 12710843392.0000 - val_r2: 0.5362 - val_root_mean_squared_error: 112742.3750\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6750285824.0000 - r2: 0.7140 - root_mean_squared_error: 82160.1250 - val_loss: 11837596672.0000 - val_r2: 0.5676 - val_root_mean_squared_error: 108800.7188\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5926704640.0000 - r2: 0.7481 - root_mean_squared_error: 76985.0938 - val_loss: 11360596992.0000 - val_r2: 0.5842 - val_root_mean_squared_error: 106586.1016\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5297635840.0000 - r2: 0.7753 - root_mean_squared_error: 72784.8594 - val_loss: 10851663872.0000 - val_r2: 0.6026 - val_root_mean_squared_error: 104171.3203\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4893066240.0000 - r2: 0.7921 - root_mean_squared_error: 69950.4531 - val_loss: 11190402048.0000 - val_r2: 0.5904 - val_root_mean_squared_error: 105784.6953\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4612487168.0000 - r2: 0.8043 - root_mean_squared_error: 67915.2969 - val_loss: 10865842176.0000 - val_r2: 0.6017 - val_root_mean_squared_error: 104239.3516\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4394323456.0000 - r2: 0.8136 - root_mean_squared_error: 66289.6953 - val_loss: 10063705088.0000 - val_r2: 0.6313 - val_root_mean_squared_error: 100318.0234\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4245640704.0000 - r2: 0.8195 - root_mean_squared_error: 65158.5820 - val_loss: 11424224256.0000 - val_r2: 0.5811 - val_root_mean_squared_error: 106884.1641\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4150579200.0000 - r2: 0.8238 - root_mean_squared_error: 64424.9883 - val_loss: 10833833984.0000 - val_r2: 0.6029 - val_root_mean_squared_error: 104085.7031\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4097689344.0000 - r2: 0.8261 - root_mean_squared_error: 64013.1953 - val_loss: 9199376384.0000 - val_r2: 0.6636 - val_root_mean_squared_error: 95913.3828\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4072769024.0000 - r2: 0.8271 - root_mean_squared_error: 63818.2500 - val_loss: 9294541824.0000 - val_r2: 0.6589 - val_root_mean_squared_error: 96408.2031\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4066906880.0000 - r2: 0.8272 - root_mean_squared_error: 63772.3047 - val_loss: 10174268416.0000 - val_r2: 0.6272 - val_root_mean_squared_error: 100867.5781\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4072244992.0000 - r2: 0.8268 - root_mean_squared_error: 63814.1445 - val_loss: 11388529664.0000 - val_r2: 0.5821 - val_root_mean_squared_error: 106717.0547\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4068102144.0000 - r2: 0.8273 - root_mean_squared_error: 63781.6758 - val_loss: 10543471616.0000 - val_r2: 0.6134 - val_root_mean_squared_error: 102681.4062\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4055223040.0000 - r2: 0.8275 - root_mean_squared_error: 63680.6328 - val_loss: 10419658752.0000 - val_r2: 0.6180 - val_root_mean_squared_error: 102076.7266\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4059302912.0000 - r2: 0.8275 - root_mean_squared_error: 63712.6602 - val_loss: 9895490560.0000 - val_r2: 0.6371 - val_root_mean_squared_error: 99476.0781\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4055089408.0000 - r2: 0.8272 - root_mean_squared_error: 63679.5820 - val_loss: 9280031744.0000 - val_r2: 0.6599 - val_root_mean_squared_error: 96332.9219\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4057115136.0000 - r2: 0.8281 - root_mean_squared_error: 63695.4883 - val_loss: 9230202880.0000 - val_r2: 0.6617 - val_root_mean_squared_error: 96073.9453\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4054716160.0000 - r2: 0.8278 - root_mean_squared_error: 63676.6523 - val_loss: 9205294080.0000 - val_r2: 0.6628 - val_root_mean_squared_error: 95944.2266\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4070553600.0000 - r2: 0.8269 - root_mean_squared_error: 63800.8906 - val_loss: 9044563968.0000 - val_r2: 0.6686 - val_root_mean_squared_error: 95102.9141\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4060763648.0000 - r2: 0.8274 - root_mean_squared_error: 63724.1211 - val_loss: 10814446592.0000 - val_r2: 0.6034 - val_root_mean_squared_error: 103992.5312\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4060207360.0000 - r2: 0.8273 - root_mean_squared_error: 63719.7578 - val_loss: 10138424320.0000 - val_r2: 0.6284 - val_root_mean_squared_error: 100689.7422\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4059779328.0000 - r2: 0.8274 - root_mean_squared_error: 63716.3984 - val_loss: 10913885184.0000 - val_r2: 0.5994 - val_root_mean_squared_error: 104469.5391\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4023553024.0000 - r2: 0.8285 - root_mean_squared_error: 63431.4844 - val_loss: 8683452416.0000 - val_r2: 0.6820 - val_root_mean_squared_error: 93185.0469\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3824903424.0000 - r2: 0.8375 - root_mean_squared_error: 61845.8047 - val_loss: 10760976384.0000 - val_r2: 0.6058 - val_root_mean_squared_error: 103735.1250\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3705964032.0000 - r2: 0.8426 - root_mean_squared_error: 60876.6289 - val_loss: 9604730880.0000 - val_r2: 0.6485 - val_root_mean_squared_error: 98003.7266\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3557806080.0000 - r2: 0.8486 - root_mean_squared_error: 59647.3477 - val_loss: 10517592064.0000 - val_r2: 0.6148 - val_root_mean_squared_error: 102555.3125\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3460721152.0000 - r2: 0.8530 - root_mean_squared_error: 58827.8945 - val_loss: 9435005952.0000 - val_r2: 0.6531 - val_root_mean_squared_error: 97133.9609\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3361276928.0000 - r2: 0.8568 - root_mean_squared_error: 57976.5195 - val_loss: 8892213248.0000 - val_r2: 0.6733 - val_root_mean_squared_error: 94298.5312\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3295499520.0000 - r2: 0.8598 - root_mean_squared_error: 57406.4414 - val_loss: 9325810688.0000 - val_r2: 0.6581 - val_root_mean_squared_error: 96570.2344\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3234785536.0000 - r2: 0.8623 - root_mean_squared_error: 56875.1758 - val_loss: 8898105344.0000 - val_r2: 0.6729 - val_root_mean_squared_error: 94329.7656\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3200376064.0000 - r2: 0.8637 - root_mean_squared_error: 56571.8672 - val_loss: 10097179648.0000 - val_r2: 0.6301 - val_root_mean_squared_error: 100484.7266\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3185723648.0000 - r2: 0.8640 - root_mean_squared_error: 56442.2148 - val_loss: 10096093184.0000 - val_r2: 0.6298 - val_root_mean_squared_error: 100479.3203\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3170407424.0000 - r2: 0.8653 - root_mean_squared_error: 56306.3711 - val_loss: 9430923264.0000 - val_r2: 0.6538 - val_root_mean_squared_error: 97112.9375\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3167963904.0000 - r2: 0.8651 - root_mean_squared_error: 56284.6680 - val_loss: 10426872832.0000 - val_r2: 0.6180 - val_root_mean_squared_error: 102112.0625\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3168945920.0000 - r2: 0.8648 - root_mean_squared_error: 56293.3906 - val_loss: 8436121600.0000 - val_r2: 0.6907 - val_root_mean_squared_error: 91848.3594\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3162583296.0000 - r2: 0.8655 - root_mean_squared_error: 56236.8516 - val_loss: 9661573120.0000 - val_r2: 0.6454 - val_root_mean_squared_error: 98293.3047\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3159450112.0000 - r2: 0.8654 - root_mean_squared_error: 56208.9844 - val_loss: 9956987904.0000 - val_r2: 0.6347 - val_root_mean_squared_error: 99784.7109\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3166804992.0000 - r2: 0.8651 - root_mean_squared_error: 56274.3711 - val_loss: 10384223232.0000 - val_r2: 0.6183 - val_root_mean_squared_error: 101903.0078\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3150322688.0000 - r2: 0.8659 - root_mean_squared_error: 56127.7344 - val_loss: 9647765504.0000 - val_r2: 0.6464 - val_root_mean_squared_error: 98223.0391\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3148213248.0000 - r2: 0.8661 - root_mean_squared_error: 56108.9414 - val_loss: 9829551104.0000 - val_r2: 0.6393 - val_root_mean_squared_error: 99144.0938\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3152889344.0000 - r2: 0.8658 - root_mean_squared_error: 56150.5938 - val_loss: 8741271552.0000 - val_r2: 0.6794 - val_root_mean_squared_error: 93494.7656\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3156128512.0000 - r2: 0.8656 - root_mean_squared_error: 56179.4297 - val_loss: 8887694336.0000 - val_r2: 0.6746 - val_root_mean_squared_error: 94274.5703\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3151768320.0000 - r2: 0.8658 - root_mean_squared_error: 56140.6133 - val_loss: 8319836672.0000 - val_r2: 0.6946 - val_root_mean_squared_error: 91213.1406\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3151574784.0000 - r2: 0.8660 - root_mean_squared_error: 56138.8867 - val_loss: 9175108608.0000 - val_r2: 0.6636 - val_root_mean_squared_error: 95786.7891\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3150062848.0000 - r2: 0.8659 - root_mean_squared_error: 56125.4219 - val_loss: 9171566592.0000 - val_r2: 0.6636 - val_root_mean_squared_error: 95768.2969\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3149795584.0000 - r2: 0.8659 - root_mean_squared_error: 56123.0391 - val_loss: 9766552576.0000 - val_r2: 0.6417 - val_root_mean_squared_error: 98825.8672\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3158838528.0000 - r2: 0.8656 - root_mean_squared_error: 56203.5469 - val_loss: 8959754240.0000 - val_r2: 0.6707 - val_root_mean_squared_error: 94655.9766\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3144412160.0000 - r2: 0.8662 - root_mean_squared_error: 56075.0586 - val_loss: 9563598848.0000 - val_r2: 0.6483 - val_root_mean_squared_error: 97793.6562\n",
      "session cleared!\n",
      "\n",
      "ix 4 i 1\n",
      "updated temp_vec [1, 1, 1, 1, 0, 1, 1, 1, 1]\n",
      "going through feature_mask [1, 1, 1, 1, 0, 1, 1, 1, 1]\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 12), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 17), dtype=tf.float32, name=None), name='flatten_2/Reshape:0', description=\"created by layer 'flatten_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 43), dtype=tf.float32, name=None), name='flatten_1/Reshape:0', description=\"created by layer 'flatten_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization/truediv:0', description=\"created by layer 'normalization'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_1/truediv:0', description=\"created by layer 'normalization_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_2/truediv:0', description=\"created by layer 'normalization_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_3/truediv:0', description=\"created by layer 'normalization_3'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_4/truediv:0', description=\"created by layer 'normalization_4'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_5/truediv:0', description=\"created by layer 'normalization_5'\")\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 3s 5ms/step - loss: 36245192704.0000 - r2: -0.5297 - root_mean_squared_error: 190381.7031 - val_loss: 14166220800.0000 - val_r2: 0.4820 - val_root_mean_squared_error: 119021.9375\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7401013760.0000 - r2: 0.6866 - root_mean_squared_error: 86029.1484 - val_loss: 12314097664.0000 - val_r2: 0.5503 - val_root_mean_squared_error: 110968.9062\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6457685504.0000 - r2: 0.7263 - root_mean_squared_error: 80359.7266 - val_loss: 13025137664.0000 - val_r2: 0.5229 - val_root_mean_squared_error: 114127.7266\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5701258752.0000 - r2: 0.7578 - root_mean_squared_error: 75506.6797 - val_loss: 11347919872.0000 - val_r2: 0.5849 - val_root_mean_squared_error: 106526.6172\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5246927872.0000 - r2: 0.7774 - root_mean_squared_error: 72435.6797 - val_loss: 11424552960.0000 - val_r2: 0.5815 - val_root_mean_squared_error: 106885.7031\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4941330944.0000 - r2: 0.7904 - root_mean_squared_error: 70294.6016 - val_loss: 10562281472.0000 - val_r2: 0.6131 - val_root_mean_squared_error: 102772.9609\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4731266560.0000 - r2: 0.7985 - root_mean_squared_error: 68784.2031 - val_loss: 10033739776.0000 - val_r2: 0.6320 - val_root_mean_squared_error: 100168.5547\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4567626752.0000 - r2: 0.8062 - root_mean_squared_error: 67584.2188 - val_loss: 11657563136.0000 - val_r2: 0.5727 - val_root_mean_squared_error: 107970.1953\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4473741824.0000 - r2: 0.8100 - root_mean_squared_error: 66886.0391 - val_loss: 9916408832.0000 - val_r2: 0.6371 - val_root_mean_squared_error: 99581.1641\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4417457152.0000 - r2: 0.8126 - root_mean_squared_error: 66463.9531 - val_loss: 11438628864.0000 - val_r2: 0.5807 - val_root_mean_squared_error: 106951.5234\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4399339008.0000 - r2: 0.8132 - root_mean_squared_error: 66327.5156 - val_loss: 11408293888.0000 - val_r2: 0.5823 - val_root_mean_squared_error: 106809.6172\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4397029888.0000 - r2: 0.8132 - root_mean_squared_error: 66310.1016 - val_loss: 10185847808.0000 - val_r2: 0.6268 - val_root_mean_squared_error: 100924.9609\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4401224192.0000 - r2: 0.8129 - root_mean_squared_error: 66341.7266 - val_loss: 10681591808.0000 - val_r2: 0.6087 - val_root_mean_squared_error: 103351.7891\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4390982656.0000 - r2: 0.8134 - root_mean_squared_error: 66264.4922 - val_loss: 10662732800.0000 - val_r2: 0.6083 - val_root_mean_squared_error: 103260.5078\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4382253056.0000 - r2: 0.8136 - root_mean_squared_error: 66198.5859 - val_loss: 10791516160.0000 - val_r2: 0.6039 - val_root_mean_squared_error: 103882.2188\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4389683712.0000 - r2: 0.8130 - root_mean_squared_error: 66254.6875 - val_loss: 9862074368.0000 - val_r2: 0.6382 - val_root_mean_squared_error: 99307.9766\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4399777792.0000 - r2: 0.8131 - root_mean_squared_error: 66330.8203 - val_loss: 10932773888.0000 - val_r2: 0.5993 - val_root_mean_squared_error: 104559.9062\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4380961792.0000 - r2: 0.8138 - root_mean_squared_error: 66188.8359 - val_loss: 10018973696.0000 - val_r2: 0.6329 - val_root_mean_squared_error: 100094.8203\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4370014720.0000 - r2: 0.8138 - root_mean_squared_error: 66106.0859 - val_loss: 11033509888.0000 - val_r2: 0.5956 - val_root_mean_squared_error: 105040.5156\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4377329664.0000 - r2: 0.8139 - root_mean_squared_error: 66161.3906 - val_loss: 11714338816.0000 - val_r2: 0.5696 - val_root_mean_squared_error: 108232.7969\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4385882112.0000 - r2: 0.8135 - root_mean_squared_error: 66225.9922 - val_loss: 10004702208.0000 - val_r2: 0.6334 - val_root_mean_squared_error: 100023.5078\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4361219584.0000 - r2: 0.8145 - root_mean_squared_error: 66039.5312 - val_loss: 10749024256.0000 - val_r2: 0.6058 - val_root_mean_squared_error: 103677.5000\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4205755648.0000 - r2: 0.8214 - root_mean_squared_error: 64851.7969 - val_loss: 8340463616.0000 - val_r2: 0.6944 - val_root_mean_squared_error: 91326.1406\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4100203008.0000 - r2: 0.8258 - root_mean_squared_error: 64032.8281 - val_loss: 11478244352.0000 - val_r2: 0.5789 - val_root_mean_squared_error: 107136.5703\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3930770432.0000 - r2: 0.8329 - root_mean_squared_error: 62695.8555 - val_loss: 9441364992.0000 - val_r2: 0.6542 - val_root_mean_squared_error: 97166.6875\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3818653696.0000 - r2: 0.8376 - root_mean_squared_error: 61795.2578 - val_loss: 9974817792.0000 - val_r2: 0.6336 - val_root_mean_squared_error: 99874.0078\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3715067904.0000 - r2: 0.8420 - root_mean_squared_error: 60951.3555 - val_loss: 11070835712.0000 - val_r2: 0.5934 - val_root_mean_squared_error: 105218.0391\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3647089152.0000 - r2: 0.8450 - root_mean_squared_error: 60391.1328 - val_loss: 9998092288.0000 - val_r2: 0.6334 - val_root_mean_squared_error: 99990.4609\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3610895104.0000 - r2: 0.8464 - root_mean_squared_error: 60090.7227 - val_loss: 9698561024.0000 - val_r2: 0.6438 - val_root_mean_squared_error: 98481.2734\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3594800640.0000 - r2: 0.8470 - root_mean_squared_error: 59956.6562 - val_loss: 9769075712.0000 - val_r2: 0.6411 - val_root_mean_squared_error: 98838.6328\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3571940864.0000 - r2: 0.8481 - root_mean_squared_error: 59765.7148 - val_loss: 9540463616.0000 - val_r2: 0.6494 - val_root_mean_squared_error: 97675.2969\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3546433024.0000 - r2: 0.8491 - root_mean_squared_error: 59551.9336 - val_loss: 8290722304.0000 - val_r2: 0.6955 - val_root_mean_squared_error: 91053.4062\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3575867392.0000 - r2: 0.8477 - root_mean_squared_error: 59798.5586 - val_loss: 9904289792.0000 - val_r2: 0.6369 - val_root_mean_squared_error: 99520.2969\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3546627072.0000 - r2: 0.8491 - root_mean_squared_error: 59553.5664 - val_loss: 10297997312.0000 - val_r2: 0.6222 - val_root_mean_squared_error: 101479.0469\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3539024384.0000 - r2: 0.8494 - root_mean_squared_error: 59489.6992 - val_loss: 10032183296.0000 - val_r2: 0.6322 - val_root_mean_squared_error: 100160.7891\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3543682048.0000 - r2: 0.8492 - root_mean_squared_error: 59528.8320 - val_loss: 10463632384.0000 - val_r2: 0.6164 - val_root_mean_squared_error: 102291.8984\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3540339456.0000 - r2: 0.8497 - root_mean_squared_error: 59500.7500 - val_loss: 8803619840.0000 - val_r2: 0.6761 - val_root_mean_squared_error: 93827.6094\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3542208256.0000 - r2: 0.8492 - root_mean_squared_error: 59516.4531 - val_loss: 9241835520.0000 - val_r2: 0.6605 - val_root_mean_squared_error: 96134.4688\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3529689600.0000 - r2: 0.8497 - root_mean_squared_error: 59411.1914 - val_loss: 10486923264.0000 - val_r2: 0.6157 - val_root_mean_squared_error: 102405.6797\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3548167936.0000 - r2: 0.8490 - root_mean_squared_error: 59566.5000 - val_loss: 9540256768.0000 - val_r2: 0.6498 - val_root_mean_squared_error: 97674.2344\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3546291456.0000 - r2: 0.8490 - root_mean_squared_error: 59550.7461 - val_loss: 12930440192.0000 - val_r2: 0.5252 - val_root_mean_squared_error: 113712.0938\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3538684416.0000 - r2: 0.8495 - root_mean_squared_error: 59486.8438 - val_loss: 9113583616.0000 - val_r2: 0.6655 - val_root_mean_squared_error: 95465.0938\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3555172608.0000 - r2: 0.8488 - root_mean_squared_error: 59625.2695 - val_loss: 10692803584.0000 - val_r2: 0.6078 - val_root_mean_squared_error: 103406.0156\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3540897792.0000 - r2: 0.8494 - root_mean_squared_error: 59505.4453 - val_loss: 10757320704.0000 - val_r2: 0.6061 - val_root_mean_squared_error: 103717.5078\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3523970304.0000 - r2: 0.8498 - root_mean_squared_error: 59363.0391 - val_loss: 10277036032.0000 - val_r2: 0.6221 - val_root_mean_squared_error: 101375.7188\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3530278912.0000 - r2: 0.8496 - root_mean_squared_error: 59416.1484 - val_loss: 10679465984.0000 - val_r2: 0.6075 - val_root_mean_squared_error: 103341.5000\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3541569792.0000 - r2: 0.8495 - root_mean_squared_error: 59511.0898 - val_loss: 10187698176.0000 - val_r2: 0.6258 - val_root_mean_squared_error: 100934.1250\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3534972928.0000 - r2: 0.8496 - root_mean_squared_error: 59455.6367 - val_loss: 9458554880.0000 - val_r2: 0.6526 - val_root_mean_squared_error: 97255.1016\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3530892032.0000 - r2: 0.8497 - root_mean_squared_error: 59421.3086 - val_loss: 10925179904.0000 - val_r2: 0.5993 - val_root_mean_squared_error: 104523.5859\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3532221696.0000 - r2: 0.8499 - root_mean_squared_error: 59432.4961 - val_loss: 9485340672.0000 - val_r2: 0.6524 - val_root_mean_squared_error: 97392.7109\n",
      "session cleared!\n",
      "\n",
      "ix 5 i 1\n",
      "updated temp_vec [1, 1, 1, 1, 1, 0, 1, 1, 1]\n",
      "going through feature_mask [1, 1, 1, 1, 1, 0, 1, 1, 1]\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 12), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 17), dtype=tf.float32, name=None), name='flatten_2/Reshape:0', description=\"created by layer 'flatten_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 43), dtype=tf.float32, name=None), name='flatten_1/Reshape:0', description=\"created by layer 'flatten_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization/truediv:0', description=\"created by layer 'normalization'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_1/truediv:0', description=\"created by layer 'normalization_1'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_2/truediv:0', description=\"created by layer 'normalization_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_3/truediv:0', description=\"created by layer 'normalization_3'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_4/truediv:0', description=\"created by layer 'normalization_4'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_5/truediv:0', description=\"created by layer 'normalization_5'\")\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 3s 5ms/step - loss: 38981541888.0000 - r2: -0.6323 - root_mean_squared_error: 197437.4375 - val_loss: 14605530112.0000 - val_r2: 0.4664 - val_root_mean_squared_error: 120853.3438\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7793356800.0000 - r2: 0.6699 - root_mean_squared_error: 88279.9922 - val_loss: 14166639616.0000 - val_r2: 0.4818 - val_root_mean_squared_error: 119023.6953\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7002921472.0000 - r2: 0.7032 - root_mean_squared_error: 83683.4609 - val_loss: 13228237824.0000 - val_r2: 0.5161 - val_root_mean_squared_error: 115014.0781\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6195193344.0000 - r2: 0.7373 - root_mean_squared_error: 78709.5469 - val_loss: 11354041344.0000 - val_r2: 0.5849 - val_root_mean_squared_error: 106555.3438\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5481686528.0000 - r2: 0.7669 - root_mean_squared_error: 74038.4141 - val_loss: 11870397440.0000 - val_r2: 0.5653 - val_root_mean_squared_error: 108951.3516\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4982801408.0000 - r2: 0.7886 - root_mean_squared_error: 70588.9609 - val_loss: 11581123584.0000 - val_r2: 0.5748 - val_root_mean_squared_error: 107615.6250\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4638848000.0000 - r2: 0.8032 - root_mean_squared_error: 68109.0859 - val_loss: 11882565632.0000 - val_r2: 0.5650 - val_root_mean_squared_error: 109007.1797\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4366706176.0000 - r2: 0.8147 - root_mean_squared_error: 66081.0547 - val_loss: 10887104512.0000 - val_r2: 0.6013 - val_root_mean_squared_error: 104341.2891\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4175384832.0000 - r2: 0.8229 - root_mean_squared_error: 64617.2188 - val_loss: 11063052288.0000 - val_r2: 0.5948 - val_root_mean_squared_error: 105181.0469\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4043085568.0000 - r2: 0.8282 - root_mean_squared_error: 63585.2617 - val_loss: 9080282112.0000 - val_r2: 0.6669 - val_root_mean_squared_error: 95290.5156\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3984289536.0000 - r2: 0.8307 - root_mean_squared_error: 63121.2305 - val_loss: 8858947584.0000 - val_r2: 0.6753 - val_root_mean_squared_error: 94121.9844\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3936646144.0000 - r2: 0.8329 - root_mean_squared_error: 62742.6992 - val_loss: 9562228736.0000 - val_r2: 0.6499 - val_root_mean_squared_error: 97786.6484\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3894337024.0000 - r2: 0.8343 - root_mean_squared_error: 62404.6250 - val_loss: 10757745664.0000 - val_r2: 0.6057 - val_root_mean_squared_error: 103719.5547\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3879709952.0000 - r2: 0.8348 - root_mean_squared_error: 62287.3164 - val_loss: 10734696448.0000 - val_r2: 0.6062 - val_root_mean_squared_error: 103608.3828\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3858492416.0000 - r2: 0.8360 - root_mean_squared_error: 62116.7656 - val_loss: 10543054848.0000 - val_r2: 0.6136 - val_root_mean_squared_error: 102679.3750\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3849428736.0000 - r2: 0.8363 - root_mean_squared_error: 62043.7656 - val_loss: 9922507776.0000 - val_r2: 0.6365 - val_root_mean_squared_error: 99611.7891\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3842398464.0000 - r2: 0.8368 - root_mean_squared_error: 61987.0820 - val_loss: 11538957312.0000 - val_r2: 0.5767 - val_root_mean_squared_error: 107419.5391\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3836802816.0000 - r2: 0.8369 - root_mean_squared_error: 61941.9297 - val_loss: 11236353024.0000 - val_r2: 0.5870 - val_root_mean_squared_error: 106001.6641\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3827496448.0000 - r2: 0.8372 - root_mean_squared_error: 61866.7656 - val_loss: 9813497856.0000 - val_r2: 0.6406 - val_root_mean_squared_error: 99063.1016\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3827402752.0000 - r2: 0.8372 - root_mean_squared_error: 61866.0078 - val_loss: 9956556800.0000 - val_r2: 0.6349 - val_root_mean_squared_error: 99782.5469\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3827567616.0000 - r2: 0.8372 - root_mean_squared_error: 61867.3398 - val_loss: 11366319104.0000 - val_r2: 0.5836 - val_root_mean_squared_error: 106612.9375\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3808011008.0000 - r2: 0.8381 - root_mean_squared_error: 61709.0820 - val_loss: 8352712704.0000 - val_r2: 0.6939 - val_root_mean_squared_error: 91393.1797\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3742541312.0000 - r2: 0.8408 - root_mean_squared_error: 61176.3125 - val_loss: 10265213952.0000 - val_r2: 0.6239 - val_root_mean_squared_error: 101317.3906\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3525017344.0000 - r2: 0.8501 - root_mean_squared_error: 59371.8555 - val_loss: 10697535488.0000 - val_r2: 0.6075 - val_root_mean_squared_error: 103428.8906\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3236828928.0000 - r2: 0.8624 - root_mean_squared_error: 56893.1367 - val_loss: 9903717376.0000 - val_r2: 0.6359 - val_root_mean_squared_error: 99517.4219\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3064026368.0000 - r2: 0.8694 - root_mean_squared_error: 55353.6484 - val_loss: 10586422272.0000 - val_r2: 0.6110 - val_root_mean_squared_error: 102890.3438\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2995606016.0000 - r2: 0.8723 - root_mean_squared_error: 54732.1289 - val_loss: 8886715392.0000 - val_r2: 0.6737 - val_root_mean_squared_error: 94269.3750\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2935664384.0000 - r2: 0.8747 - root_mean_squared_error: 54181.7734 - val_loss: 9491916800.0000 - val_r2: 0.6514 - val_root_mean_squared_error: 97426.4688\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2893374720.0000 - r2: 0.8768 - root_mean_squared_error: 53790.0977 - val_loss: 11382458368.0000 - val_r2: 0.5833 - val_root_mean_squared_error: 106688.6016\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2878571264.0000 - r2: 0.8772 - root_mean_squared_error: 53652.3164 - val_loss: 8632540160.0000 - val_r2: 0.6831 - val_root_mean_squared_error: 92911.4609\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2857800448.0000 - r2: 0.8784 - root_mean_squared_error: 53458.3984 - val_loss: 10862001152.0000 - val_r2: 0.6002 - val_root_mean_squared_error: 104220.9219\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2833501952.0000 - r2: 0.8793 - root_mean_squared_error: 53230.6484 - val_loss: 9616311296.0000 - val_r2: 0.6470 - val_root_mean_squared_error: 98062.7891\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2836157952.0000 - r2: 0.8791 - root_mean_squared_error: 53255.5898 - val_loss: 9053979648.0000 - val_r2: 0.6674 - val_root_mean_squared_error: 95152.3984\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2816661760.0000 - r2: 0.8803 - root_mean_squared_error: 53072.2305 - val_loss: 10371212288.0000 - val_r2: 0.6191 - val_root_mean_squared_error: 101839.1484\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2802520320.0000 - r2: 0.8806 - root_mean_squared_error: 52938.8359 - val_loss: 9486992384.0000 - val_r2: 0.6517 - val_root_mean_squared_error: 97401.1953\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2812453632.0000 - r2: 0.8801 - root_mean_squared_error: 53032.5703 - val_loss: 9863689216.0000 - val_r2: 0.6386 - val_root_mean_squared_error: 99316.1094\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2795347200.0000 - r2: 0.8813 - root_mean_squared_error: 52871.0430 - val_loss: 9674450944.0000 - val_r2: 0.6447 - val_root_mean_squared_error: 98358.7891\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2802359552.0000 - r2: 0.8807 - root_mean_squared_error: 52937.3164 - val_loss: 8643947520.0000 - val_r2: 0.6829 - val_root_mean_squared_error: 92972.8359\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2793753344.0000 - r2: 0.8809 - root_mean_squared_error: 52855.9688 - val_loss: 9827127296.0000 - val_r2: 0.6389 - val_root_mean_squared_error: 99131.8672\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2793901568.0000 - r2: 0.8811 - root_mean_squared_error: 52857.3711 - val_loss: 8237317120.0000 - val_r2: 0.6977 - val_root_mean_squared_error: 90759.6641\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2791053568.0000 - r2: 0.8810 - root_mean_squared_error: 52830.4219 - val_loss: 9699426304.0000 - val_r2: 0.6438 - val_root_mean_squared_error: 98485.6641\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2785544192.0000 - r2: 0.8815 - root_mean_squared_error: 52778.2539 - val_loss: 8043795968.0000 - val_r2: 0.7045 - val_root_mean_squared_error: 89687.2109\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2777034496.0000 - r2: 0.8819 - root_mean_squared_error: 52697.5742 - val_loss: 8292729344.0000 - val_r2: 0.6951 - val_root_mean_squared_error: 91064.4219\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2783250176.0000 - r2: 0.8816 - root_mean_squared_error: 52756.5195 - val_loss: 9849257984.0000 - val_r2: 0.6384 - val_root_mean_squared_error: 99243.4297\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2779164928.0000 - r2: 0.8817 - root_mean_squared_error: 52717.7852 - val_loss: 7753868800.0000 - val_r2: 0.7154 - val_root_mean_squared_error: 88056.0547\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2773684480.0000 - r2: 0.8818 - root_mean_squared_error: 52665.7812 - val_loss: 9583307776.0000 - val_r2: 0.6474 - val_root_mean_squared_error: 97894.3672\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2771153920.0000 - r2: 0.8820 - root_mean_squared_error: 52641.7500 - val_loss: 8811993088.0000 - val_r2: 0.6763 - val_root_mean_squared_error: 93872.2188\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2758422784.0000 - r2: 0.8828 - root_mean_squared_error: 52520.6875 - val_loss: 7780231680.0000 - val_r2: 0.7143 - val_root_mean_squared_error: 88205.6250\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2767286784.0000 - r2: 0.8823 - root_mean_squared_error: 52605.0078 - val_loss: 9197666304.0000 - val_r2: 0.6626 - val_root_mean_squared_error: 95904.4609\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2762160128.0000 - r2: 0.8824 - root_mean_squared_error: 52556.2578 - val_loss: 8934473728.0000 - val_r2: 0.6721 - val_root_mean_squared_error: 94522.3438\n",
      "new min loss: len 9, ix 5\n",
      "session cleared!\n",
      "\n",
      "ix 6 i 1\n",
      "updated temp_vec [1, 1, 1, 1, 1, 1, 0, 1, 1]\n",
      "going through feature_mask [1, 1, 1, 1, 1, 1, 0, 1, 1]\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 12), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 17), dtype=tf.float32, name=None), name='flatten_2/Reshape:0', description=\"created by layer 'flatten_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 43), dtype=tf.float32, name=None), name='flatten_1/Reshape:0', description=\"created by layer 'flatten_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization/truediv:0', description=\"created by layer 'normalization'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_1/truediv:0', description=\"created by layer 'normalization_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_2/truediv:0', description=\"created by layer 'normalization_2'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_3/truediv:0', description=\"created by layer 'normalization_3'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_4/truediv:0', description=\"created by layer 'normalization_4'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_5/truediv:0', description=\"created by layer 'normalization_5'\")\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 3s 5ms/step - loss: 38624260096.0000 - r2: -0.6119 - root_mean_squared_error: 196530.5625 - val_loss: 13930376192.0000 - val_r2: 0.4909 - val_root_mean_squared_error: 118027.0156\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7818323456.0000 - r2: 0.6682 - root_mean_squared_error: 88421.2812 - val_loss: 13318362112.0000 - val_r2: 0.5129 - val_root_mean_squared_error: 115405.2109\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7041464320.0000 - r2: 0.7013 - root_mean_squared_error: 83913.4297 - val_loss: 13082112000.0000 - val_r2: 0.5207 - val_root_mean_squared_error: 114377.0625\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6201190400.0000 - r2: 0.7370 - root_mean_squared_error: 78747.6406 - val_loss: 11186074624.0000 - val_r2: 0.5909 - val_root_mean_squared_error: 105764.2422\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5390047744.0000 - r2: 0.7713 - root_mean_squared_error: 73416.9453 - val_loss: 10572883968.0000 - val_r2: 0.6125 - val_root_mean_squared_error: 102824.5312\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4758733312.0000 - r2: 0.7982 - root_mean_squared_error: 68983.5703 - val_loss: 11101894656.0000 - val_r2: 0.5935 - val_root_mean_squared_error: 105365.5312\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4331259392.0000 - r2: 0.8161 - root_mean_squared_error: 65812.3047 - val_loss: 10969848832.0000 - val_r2: 0.5987 - val_root_mean_squared_error: 104737.0469\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4057939456.0000 - r2: 0.8276 - root_mean_squared_error: 63701.9570 - val_loss: 11304725504.0000 - val_r2: 0.5851 - val_root_mean_squared_error: 106323.6797\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3928981248.0000 - r2: 0.8332 - root_mean_squared_error: 62681.5859 - val_loss: 10772941824.0000 - val_r2: 0.6055 - val_root_mean_squared_error: 103792.7812\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3867244544.0000 - r2: 0.8355 - root_mean_squared_error: 62187.1719 - val_loss: 9597299712.0000 - val_r2: 0.6487 - val_root_mean_squared_error: 97965.8125\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3822429696.0000 - r2: 0.8378 - root_mean_squared_error: 61825.8008 - val_loss: 10169393152.0000 - val_r2: 0.6278 - val_root_mean_squared_error: 100843.4062\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3808315392.0000 - r2: 0.8381 - root_mean_squared_error: 61711.5508 - val_loss: 11323868160.0000 - val_r2: 0.5849 - val_root_mean_squared_error: 106413.6641\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3787632128.0000 - r2: 0.8391 - root_mean_squared_error: 61543.7422 - val_loss: 10212886528.0000 - val_r2: 0.6256 - val_root_mean_squared_error: 101058.8281\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3772983808.0000 - r2: 0.8396 - root_mean_squared_error: 61424.6172 - val_loss: 11740275712.0000 - val_r2: 0.5698 - val_root_mean_squared_error: 108352.5547\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3759294720.0000 - r2: 0.8404 - root_mean_squared_error: 61313.0859 - val_loss: 11044364288.0000 - val_r2: 0.5957 - val_root_mean_squared_error: 105092.1719\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3744091648.0000 - r2: 0.8410 - root_mean_squared_error: 61188.9844 - val_loss: 10987826176.0000 - val_r2: 0.5975 - val_root_mean_squared_error: 104822.8359\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3553113344.0000 - r2: 0.8492 - root_mean_squared_error: 59607.9961 - val_loss: 9463525376.0000 - val_r2: 0.6530 - val_root_mean_squared_error: 97280.6562\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3440544000.0000 - r2: 0.8539 - root_mean_squared_error: 58656.1523 - val_loss: 10297602048.0000 - val_r2: 0.6226 - val_root_mean_squared_error: 101477.1016\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3268433664.0000 - r2: 0.8610 - root_mean_squared_error: 57170.2148 - val_loss: 8613922816.0000 - val_r2: 0.6843 - val_root_mean_squared_error: 92811.2188\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3117226496.0000 - r2: 0.8675 - root_mean_squared_error: 55832.1289 - val_loss: 10633639936.0000 - val_r2: 0.6103 - val_root_mean_squared_error: 103119.5391\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3001863424.0000 - r2: 0.8722 - root_mean_squared_error: 54789.2656 - val_loss: 8939704320.0000 - val_r2: 0.6716 - val_root_mean_squared_error: 94550.0078\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2933403392.0000 - r2: 0.8754 - root_mean_squared_error: 54160.9023 - val_loss: 9703570432.0000 - val_r2: 0.6437 - val_root_mean_squared_error: 98506.7031\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2869169408.0000 - r2: 0.8778 - root_mean_squared_error: 53564.6289 - val_loss: 8455770112.0000 - val_r2: 0.6891 - val_root_mean_squared_error: 91955.2578\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2804753664.0000 - r2: 0.8806 - root_mean_squared_error: 52959.9258 - val_loss: 9386210304.0000 - val_r2: 0.6559 - val_root_mean_squared_error: 96882.4531\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2800941824.0000 - r2: 0.8807 - root_mean_squared_error: 52923.9258 - val_loss: 10450733056.0000 - val_r2: 0.6161 - val_root_mean_squared_error: 102228.8281\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2779826944.0000 - r2: 0.8815 - root_mean_squared_error: 52724.0625 - val_loss: 9671034880.0000 - val_r2: 0.6447 - val_root_mean_squared_error: 98341.4219\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2770930176.0000 - r2: 0.8821 - root_mean_squared_error: 52639.6250 - val_loss: 9111878656.0000 - val_r2: 0.6658 - val_root_mean_squared_error: 95456.1641\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2765280000.0000 - r2: 0.8824 - root_mean_squared_error: 52585.9297 - val_loss: 7790351872.0000 - val_r2: 0.7143 - val_root_mean_squared_error: 88262.9688\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2760302336.0000 - r2: 0.8826 - root_mean_squared_error: 52538.5781 - val_loss: 10640031744.0000 - val_r2: 0.6084 - val_root_mean_squared_error: 103150.5312\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2748965632.0000 - r2: 0.8831 - root_mean_squared_error: 52430.5781 - val_loss: 9570887680.0000 - val_r2: 0.6487 - val_root_mean_squared_error: 97830.9141\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2755095296.0000 - r2: 0.8827 - root_mean_squared_error: 52489.0000 - val_loss: 8941014016.0000 - val_r2: 0.6719 - val_root_mean_squared_error: 94556.9375\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2741138432.0000 - r2: 0.8830 - root_mean_squared_error: 52355.8828 - val_loss: 9878512640.0000 - val_r2: 0.6369 - val_root_mean_squared_error: 99390.7031\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2744690432.0000 - r2: 0.8834 - root_mean_squared_error: 52389.7930 - val_loss: 10633532416.0000 - val_r2: 0.6095 - val_root_mean_squared_error: 103119.0234\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2738986496.0000 - r2: 0.8832 - root_mean_squared_error: 52335.3281 - val_loss: 8803689472.0000 - val_r2: 0.6768 - val_root_mean_squared_error: 93827.9766\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2728258560.0000 - r2: 0.8838 - root_mean_squared_error: 52232.7344 - val_loss: 9181270016.0000 - val_r2: 0.6624 - val_root_mean_squared_error: 95818.9453\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2735241472.0000 - r2: 0.8836 - root_mean_squared_error: 52299.5352 - val_loss: 9088346112.0000 - val_r2: 0.6663 - val_root_mean_squared_error: 95332.8203\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2721189632.0000 - r2: 0.8841 - root_mean_squared_error: 52165.0234 - val_loss: 9031439360.0000 - val_r2: 0.6681 - val_root_mean_squared_error: 95033.8828\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2710082304.0000 - r2: 0.8843 - root_mean_squared_error: 52058.4492 - val_loss: 9847677952.0000 - val_r2: 0.6390 - val_root_mean_squared_error: 99235.4688\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2718467072.0000 - r2: 0.8843 - root_mean_squared_error: 52138.9219 - val_loss: 9479120896.0000 - val_r2: 0.6521 - val_root_mean_squared_error: 97360.7734\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2716071424.0000 - r2: 0.8842 - root_mean_squared_error: 52115.9414 - val_loss: 10332758016.0000 - val_r2: 0.6204 - val_root_mean_squared_error: 101650.1719\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2716450304.0000 - r2: 0.8844 - root_mean_squared_error: 52119.5781 - val_loss: 8821627904.0000 - val_r2: 0.6761 - val_root_mean_squared_error: 93923.5234\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2705002496.0000 - r2: 0.8848 - root_mean_squared_error: 52009.6367 - val_loss: 9298299904.0000 - val_r2: 0.6585 - val_root_mean_squared_error: 96427.6953\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2705101824.0000 - r2: 0.8850 - root_mean_squared_error: 52010.5938 - val_loss: 9090294784.0000 - val_r2: 0.6657 - val_root_mean_squared_error: 95343.0391\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2706024448.0000 - r2: 0.8847 - root_mean_squared_error: 52019.4609 - val_loss: 9050907648.0000 - val_r2: 0.6677 - val_root_mean_squared_error: 95136.2578\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2697679872.0000 - r2: 0.8853 - root_mean_squared_error: 51939.1953 - val_loss: 9356274688.0000 - val_r2: 0.6566 - val_root_mean_squared_error: 96727.8359\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2708531968.0000 - r2: 0.8845 - root_mean_squared_error: 52043.5586 - val_loss: 9951063040.0000 - val_r2: 0.6348 - val_root_mean_squared_error: 99755.0156\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2701230592.0000 - r2: 0.8849 - root_mean_squared_error: 51973.3633 - val_loss: 10261766144.0000 - val_r2: 0.6229 - val_root_mean_squared_error: 101300.3750\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2696294400.0000 - r2: 0.8852 - root_mean_squared_error: 51925.8555 - val_loss: 8632251392.0000 - val_r2: 0.6828 - val_root_mean_squared_error: 92909.9062\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2688486656.0000 - r2: 0.8855 - root_mean_squared_error: 51850.6172 - val_loss: 9996618752.0000 - val_r2: 0.6328 - val_root_mean_squared_error: 99983.0938\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2691688448.0000 - r2: 0.8854 - root_mean_squared_error: 51881.4844 - val_loss: 9116718080.0000 - val_r2: 0.6651 - val_root_mean_squared_error: 95481.5078\n",
      "session cleared!\n",
      "\n",
      "ix 7 i 1\n",
      "updated temp_vec [1, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "going through feature_mask [1, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 12), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 17), dtype=tf.float32, name=None), name='flatten_2/Reshape:0', description=\"created by layer 'flatten_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 43), dtype=tf.float32, name=None), name='flatten_1/Reshape:0', description=\"created by layer 'flatten_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization/truediv:0', description=\"created by layer 'normalization'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_1/truediv:0', description=\"created by layer 'normalization_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_2/truediv:0', description=\"created by layer 'normalization_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_3/truediv:0', description=\"created by layer 'normalization_3'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_4/truediv:0', description=\"created by layer 'normalization_4'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_5/truediv:0', description=\"created by layer 'normalization_5'\")\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 4s 6ms/step - loss: 37620658176.0000 - r2: -0.5911 - root_mean_squared_error: 193960.4531 - val_loss: 15886461952.0000 - val_r2: 0.4195 - val_root_mean_squared_error: 126041.5078\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7837296640.0000 - r2: 0.6681 - root_mean_squared_error: 88528.5078 - val_loss: 13315367936.0000 - val_r2: 0.5125 - val_root_mean_squared_error: 115392.2344\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7125529088.0000 - r2: 0.6980 - root_mean_squared_error: 84412.8516 - val_loss: 13880911872.0000 - val_r2: 0.4926 - val_root_mean_squared_error: 117817.2812\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6447263744.0000 - r2: 0.7264 - root_mean_squared_error: 80294.8516 - val_loss: 11645917184.0000 - val_r2: 0.5742 - val_root_mean_squared_error: 107916.2500\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5861982208.0000 - r2: 0.7511 - root_mean_squared_error: 76563.5859 - val_loss: 13286249472.0000 - val_r2: 0.5126 - val_root_mean_squared_error: 115265.9922\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5426782720.0000 - r2: 0.7697 - root_mean_squared_error: 73666.7031 - val_loss: 11433647104.0000 - val_r2: 0.5814 - val_root_mean_squared_error: 106928.2344\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5088707584.0000 - r2: 0.7837 - root_mean_squared_error: 71335.1797 - val_loss: 9157781504.0000 - val_r2: 0.6650 - val_root_mean_squared_error: 95696.2969\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4832642560.0000 - r2: 0.7951 - root_mean_squared_error: 69517.2109 - val_loss: 9894073344.0000 - val_r2: 0.6376 - val_root_mean_squared_error: 99468.9531\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4653210624.0000 - r2: 0.8021 - root_mean_squared_error: 68214.4453 - val_loss: 10763119616.0000 - val_r2: 0.6058 - val_root_mean_squared_error: 103745.4531\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4538035200.0000 - r2: 0.8072 - root_mean_squared_error: 67364.9375 - val_loss: 11674497024.0000 - val_r2: 0.5716 - val_root_mean_squared_error: 108048.5859\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4463027712.0000 - r2: 0.8107 - root_mean_squared_error: 66805.8984 - val_loss: 12018083840.0000 - val_r2: 0.5595 - val_root_mean_squared_error: 109627.0234\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4415808512.0000 - r2: 0.8122 - root_mean_squared_error: 66451.5469 - val_loss: 10920276992.0000 - val_r2: 0.5996 - val_root_mean_squared_error: 104500.1328\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4408144384.0000 - r2: 0.8130 - root_mean_squared_error: 66393.8594 - val_loss: 9646154752.0000 - val_r2: 0.6471 - val_root_mean_squared_error: 98214.8359\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4387525120.0000 - r2: 0.8136 - root_mean_squared_error: 66238.3984 - val_loss: 10311905280.0000 - val_r2: 0.6216 - val_root_mean_squared_error: 101547.5547\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4373723648.0000 - r2: 0.8140 - root_mean_squared_error: 66134.1328 - val_loss: 10029317120.0000 - val_r2: 0.6325 - val_root_mean_squared_error: 100146.4766\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4364534272.0000 - r2: 0.8144 - root_mean_squared_error: 66064.6250 - val_loss: 12371980288.0000 - val_r2: 0.5460 - val_root_mean_squared_error: 111229.4062\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4359385088.0000 - r2: 0.8146 - root_mean_squared_error: 66025.6406 - val_loss: 11351119872.0000 - val_r2: 0.5835 - val_root_mean_squared_error: 106541.6328\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4343940096.0000 - r2: 0.8153 - root_mean_squared_error: 65908.5703 - val_loss: 9557182464.0000 - val_r2: 0.6497 - val_root_mean_squared_error: 97760.8438\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4343549952.0000 - r2: 0.8150 - root_mean_squared_error: 65905.6172 - val_loss: 10316138496.0000 - val_r2: 0.6218 - val_root_mean_squared_error: 101568.3906\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4333318656.0000 - r2: 0.8156 - root_mean_squared_error: 65827.9453 - val_loss: 9084957696.0000 - val_r2: 0.6676 - val_root_mean_squared_error: 95315.0469\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4340229632.0000 - r2: 0.8157 - root_mean_squared_error: 65880.4219 - val_loss: 10600763392.0000 - val_r2: 0.6114 - val_root_mean_squared_error: 102960.0078\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4325394944.0000 - r2: 0.8160 - root_mean_squared_error: 65767.7344 - val_loss: 9997043712.0000 - val_r2: 0.6336 - val_root_mean_squared_error: 99985.2188\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4323295744.0000 - r2: 0.8159 - root_mean_squared_error: 65751.7734 - val_loss: 11561821184.0000 - val_r2: 0.5762 - val_root_mean_squared_error: 107525.9062\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4318531072.0000 - r2: 0.8167 - root_mean_squared_error: 65715.5312 - val_loss: 8956439552.0000 - val_r2: 0.6710 - val_root_mean_squared_error: 94638.4688\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4333899776.0000 - r2: 0.8159 - root_mean_squared_error: 65832.3594 - val_loss: 9831041024.0000 - val_r2: 0.6399 - val_root_mean_squared_error: 99151.6094\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4303203840.0000 - r2: 0.8170 - root_mean_squared_error: 65598.8125 - val_loss: 11211502592.0000 - val_r2: 0.5894 - val_root_mean_squared_error: 105884.3828\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4158516736.0000 - r2: 0.8233 - root_mean_squared_error: 64486.5625 - val_loss: 12739236864.0000 - val_r2: 0.5330 - val_root_mean_squared_error: 112868.2266\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4032189184.0000 - r2: 0.8288 - root_mean_squared_error: 63499.5195 - val_loss: 10807252992.0000 - val_r2: 0.6036 - val_root_mean_squared_error: 103957.9375\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3896243712.0000 - r2: 0.8342 - root_mean_squared_error: 62419.8984 - val_loss: 10121963520.0000 - val_r2: 0.6293 - val_root_mean_squared_error: 100607.9688\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3777115648.0000 - r2: 0.8388 - root_mean_squared_error: 61458.2422 - val_loss: 9669137408.0000 - val_r2: 0.6449 - val_root_mean_squared_error: 98331.7734\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3677363712.0000 - r2: 0.8436 - root_mean_squared_error: 60641.2695 - val_loss: 9797922816.0000 - val_r2: 0.6400 - val_root_mean_squared_error: 98984.4609\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3605275648.0000 - r2: 0.8465 - root_mean_squared_error: 60043.9492 - val_loss: 9167639552.0000 - val_r2: 0.6634 - val_root_mean_squared_error: 95747.7891\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3557505280.0000 - r2: 0.8486 - root_mean_squared_error: 59644.8242 - val_loss: 10333111296.0000 - val_r2: 0.6203 - val_root_mean_squared_error: 101651.9141\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3520331520.0000 - r2: 0.8500 - root_mean_squared_error: 59332.3828 - val_loss: 10402418688.0000 - val_r2: 0.6177 - val_root_mean_squared_error: 101992.2500\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3488756224.0000 - r2: 0.8514 - root_mean_squared_error: 59065.6953 - val_loss: 10700826624.0000 - val_r2: 0.6071 - val_root_mean_squared_error: 103444.7969\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3467276544.0000 - r2: 0.8522 - root_mean_squared_error: 58883.5859 - val_loss: 8586632704.0000 - val_r2: 0.6856 - val_root_mean_squared_error: 92664.0859\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3455531264.0000 - r2: 0.8530 - root_mean_squared_error: 58783.7656 - val_loss: 9334913024.0000 - val_r2: 0.6577 - val_root_mean_squared_error: 96617.3516\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3468402944.0000 - r2: 0.8524 - root_mean_squared_error: 58893.1484 - val_loss: 9722812416.0000 - val_r2: 0.6423 - val_root_mean_squared_error: 98604.3203\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3454378752.0000 - r2: 0.8530 - root_mean_squared_error: 58773.9648 - val_loss: 10913263616.0000 - val_r2: 0.5993 - val_root_mean_squared_error: 104466.5703\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3455599616.0000 - r2: 0.8525 - root_mean_squared_error: 58784.3477 - val_loss: 9293592576.0000 - val_r2: 0.6587 - val_root_mean_squared_error: 96403.2812\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3441831424.0000 - r2: 0.8535 - root_mean_squared_error: 58667.1250 - val_loss: 9727384576.0000 - val_r2: 0.6435 - val_root_mean_squared_error: 98627.5078\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3426737920.0000 - r2: 0.8541 - root_mean_squared_error: 58538.3477 - val_loss: 10801213440.0000 - val_r2: 0.6038 - val_root_mean_squared_error: 103928.8828\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3420235520.0000 - r2: 0.8545 - root_mean_squared_error: 58482.7812 - val_loss: 9396191232.0000 - val_r2: 0.6554 - val_root_mean_squared_error: 96933.9531\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3429054464.0000 - r2: 0.8541 - root_mean_squared_error: 58558.1289 - val_loss: 8386395648.0000 - val_r2: 0.6930 - val_root_mean_squared_error: 91577.2656\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3423597056.0000 - r2: 0.8542 - root_mean_squared_error: 58511.5117 - val_loss: 9306303488.0000 - val_r2: 0.6580 - val_root_mean_squared_error: 96469.1875\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3431885568.0000 - r2: 0.8539 - root_mean_squared_error: 58582.2969 - val_loss: 9490138112.0000 - val_r2: 0.6516 - val_root_mean_squared_error: 97417.3438\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3419893248.0000 - r2: 0.8546 - root_mean_squared_error: 58479.8516 - val_loss: 10300180480.0000 - val_r2: 0.6217 - val_root_mean_squared_error: 101489.8047\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3430255616.0000 - r2: 0.8539 - root_mean_squared_error: 58568.3828 - val_loss: 8609628160.0000 - val_r2: 0.6844 - val_root_mean_squared_error: 92788.0781\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3428708352.0000 - r2: 0.8537 - root_mean_squared_error: 58555.1719 - val_loss: 9403040768.0000 - val_r2: 0.6545 - val_root_mean_squared_error: 96969.2812\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3432558080.0000 - r2: 0.8536 - root_mean_squared_error: 58588.0352 - val_loss: 9377462272.0000 - val_r2: 0.6555 - val_root_mean_squared_error: 96837.2969\n",
      "session cleared!\n",
      "\n",
      "ix 8 i 1\n",
      "updated temp_vec [1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "going through feature_mask [1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 12), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 17), dtype=tf.float32, name=None), name='flatten_2/Reshape:0', description=\"created by layer 'flatten_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 43), dtype=tf.float32, name=None), name='flatten_1/Reshape:0', description=\"created by layer 'flatten_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization/truediv:0', description=\"created by layer 'normalization'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_1/truediv:0', description=\"created by layer 'normalization_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_2/truediv:0', description=\"created by layer 'normalization_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_3/truediv:0', description=\"created by layer 'normalization_3'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_4/truediv:0', description=\"created by layer 'normalization_4'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_5/truediv:0', description=\"created by layer 'normalization_5'\")\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 3s 5ms/step - loss: 37310496768.0000 - r2: -0.6053 - root_mean_squared_error: 193159.2500 - val_loss: 14921077760.0000 - val_r2: 0.4540 - val_root_mean_squared_error: 122151.8672\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 8101321728.0000 - r2: 0.6562 - root_mean_squared_error: 90007.3438 - val_loss: 13097382912.0000 - val_r2: 0.5214 - val_root_mean_squared_error: 114443.7969\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7591518720.0000 - r2: 0.6780 - root_mean_squared_error: 87129.3203 - val_loss: 13614393344.0000 - val_r2: 0.5024 - val_root_mean_squared_error: 116680.7344\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7186730496.0000 - r2: 0.6948 - root_mean_squared_error: 84774.5859 - val_loss: 12816846848.0000 - val_r2: 0.5315 - val_root_mean_squared_error: 113211.5156\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6894304768.0000 - r2: 0.7072 - root_mean_squared_error: 83031.9531 - val_loss: 13395082240.0000 - val_r2: 0.5103 - val_root_mean_squared_error: 115737.1250\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6748637696.0000 - r2: 0.7128 - root_mean_squared_error: 82150.0938 - val_loss: 13932837888.0000 - val_r2: 0.4893 - val_root_mean_squared_error: 118037.4453\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6678546432.0000 - r2: 0.7165 - root_mean_squared_error: 81722.3750 - val_loss: 13376985088.0000 - val_r2: 0.5104 - val_root_mean_squared_error: 115658.9141\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6660803072.0000 - r2: 0.7169 - root_mean_squared_error: 81613.7422 - val_loss: 13494455296.0000 - val_r2: 0.5055 - val_root_mean_squared_error: 116165.6406\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6637625856.0000 - r2: 0.7185 - root_mean_squared_error: 81471.6250 - val_loss: 12235545600.0000 - val_r2: 0.5516 - val_root_mean_squared_error: 110614.3984\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6599847424.0000 - r2: 0.7197 - root_mean_squared_error: 81239.4453 - val_loss: 14280796160.0000 - val_r2: 0.4777 - val_root_mean_squared_error: 119502.2891\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6586017280.0000 - r2: 0.7198 - root_mean_squared_error: 81154.2812 - val_loss: 13654569984.0000 - val_r2: 0.5003 - val_root_mean_squared_error: 116852.7734\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6570037760.0000 - r2: 0.7213 - root_mean_squared_error: 81055.7656 - val_loss: 13147039744.0000 - val_r2: 0.5179 - val_root_mean_squared_error: 114660.5391\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6558747136.0000 - r2: 0.7218 - root_mean_squared_error: 80986.0938 - val_loss: 13132436480.0000 - val_r2: 0.5192 - val_root_mean_squared_error: 114596.8438\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6564253184.0000 - r2: 0.7201 - root_mean_squared_error: 81020.0781 - val_loss: 11814786048.0000 - val_r2: 0.5665 - val_root_mean_squared_error: 108695.8438\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6528073216.0000 - r2: 0.7227 - root_mean_squared_error: 80796.4922 - val_loss: 13364152320.0000 - val_r2: 0.5099 - val_root_mean_squared_error: 115603.4297\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6516436480.0000 - r2: 0.7234 - root_mean_squared_error: 80724.4453 - val_loss: 14108139520.0000 - val_r2: 0.4834 - val_root_mean_squared_error: 118777.6875\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6512605184.0000 - r2: 0.7235 - root_mean_squared_error: 80700.7109 - val_loss: 12879322112.0000 - val_r2: 0.5277 - val_root_mean_squared_error: 113487.1016\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6489549312.0000 - r2: 0.7243 - root_mean_squared_error: 80557.7422 - val_loss: 12813312000.0000 - val_r2: 0.5305 - val_root_mean_squared_error: 113195.8984\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6489767936.0000 - r2: 0.7246 - root_mean_squared_error: 80559.0938 - val_loss: 11959398400.0000 - val_r2: 0.5628 - val_root_mean_squared_error: 109359.0312\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6476705280.0000 - r2: 0.7246 - root_mean_squared_error: 80477.9766 - val_loss: 11615621120.0000 - val_r2: 0.5740 - val_root_mean_squared_error: 107775.7891\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6474700288.0000 - r2: 0.7250 - root_mean_squared_error: 80465.5234 - val_loss: 13757963264.0000 - val_r2: 0.4963 - val_root_mean_squared_error: 117294.3438\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6469990912.0000 - r2: 0.7248 - root_mean_squared_error: 80436.2500 - val_loss: 13805435904.0000 - val_r2: 0.4948 - val_root_mean_squared_error: 117496.5391\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6457310720.0000 - r2: 0.7254 - root_mean_squared_error: 80357.3906 - val_loss: 12875828224.0000 - val_r2: 0.5288 - val_root_mean_squared_error: 113471.7031\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6448516608.0000 - r2: 0.7256 - root_mean_squared_error: 80302.6562 - val_loss: 14735533056.0000 - val_r2: 0.4595 - val_root_mean_squared_error: 121390.0078\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6446556672.0000 - r2: 0.7261 - root_mean_squared_error: 80290.4531 - val_loss: 12459802624.0000 - val_r2: 0.5436 - val_root_mean_squared_error: 111623.4844\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6429940224.0000 - r2: 0.7266 - root_mean_squared_error: 80186.9062 - val_loss: 14113860608.0000 - val_r2: 0.4830 - val_root_mean_squared_error: 118801.7734\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6461094912.0000 - r2: 0.7253 - root_mean_squared_error: 80380.9375 - val_loss: 13441609728.0000 - val_r2: 0.5075 - val_root_mean_squared_error: 115937.9531\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6426064384.0000 - r2: 0.7270 - root_mean_squared_error: 80162.7344 - val_loss: 13876694016.0000 - val_r2: 0.4910 - val_root_mean_squared_error: 117799.3828\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6433445888.0000 - r2: 0.7267 - root_mean_squared_error: 80208.7656 - val_loss: 12374538240.0000 - val_r2: 0.5467 - val_root_mean_squared_error: 111240.8984\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6431768576.0000 - r2: 0.7271 - root_mean_squared_error: 80198.3047 - val_loss: 13915794432.0000 - val_r2: 0.4893 - val_root_mean_squared_error: 117965.2266\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6424546304.0000 - r2: 0.7273 - root_mean_squared_error: 80153.2656 - val_loss: 13193556992.0000 - val_r2: 0.5163 - val_root_mean_squared_error: 114863.2109\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6417980416.0000 - r2: 0.7271 - root_mean_squared_error: 80112.2969 - val_loss: 13133966336.0000 - val_r2: 0.5192 - val_root_mean_squared_error: 114603.5156\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6399916032.0000 - r2: 0.7281 - root_mean_squared_error: 79999.4766 - val_loss: 12738573312.0000 - val_r2: 0.5345 - val_root_mean_squared_error: 112865.2891\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6418341888.0000 - r2: 0.7270 - root_mean_squared_error: 80114.5547 - val_loss: 13376951296.0000 - val_r2: 0.5098 - val_root_mean_squared_error: 115658.7734\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6431910400.0000 - r2: 0.7266 - root_mean_squared_error: 80199.1953 - val_loss: 12128489472.0000 - val_r2: 0.5560 - val_root_mean_squared_error: 110129.4219\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6407392256.0000 - r2: 0.7284 - root_mean_squared_error: 80046.1875 - val_loss: 12574387200.0000 - val_r2: 0.5396 - val_root_mean_squared_error: 112135.5781\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6409579520.0000 - r2: 0.7277 - root_mean_squared_error: 80059.8516 - val_loss: 12317536256.0000 - val_r2: 0.5485 - val_root_mean_squared_error: 110984.3984\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6412180480.0000 - r2: 0.7272 - root_mean_squared_error: 80076.0938 - val_loss: 13239236608.0000 - val_r2: 0.5154 - val_root_mean_squared_error: 115061.8828\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6418385920.0000 - r2: 0.7277 - root_mean_squared_error: 80114.8281 - val_loss: 13858475008.0000 - val_r2: 0.4928 - val_root_mean_squared_error: 117722.0234\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6409646592.0000 - r2: 0.7283 - root_mean_squared_error: 80060.2656 - val_loss: 13339075584.0000 - val_r2: 0.5120 - val_root_mean_squared_error: 115494.9141\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6407912960.0000 - r2: 0.7282 - root_mean_squared_error: 80049.4375 - val_loss: 14168363008.0000 - val_r2: 0.4806 - val_root_mean_squared_error: 119030.9297\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6408432128.0000 - r2: 0.7277 - root_mean_squared_error: 80052.6797 - val_loss: 13399450624.0000 - val_r2: 0.5093 - val_root_mean_squared_error: 115755.9922\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6415275008.0000 - r2: 0.7276 - root_mean_squared_error: 80095.4141 - val_loss: 13139325952.0000 - val_r2: 0.5189 - val_root_mean_squared_error: 114626.8984\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6408431616.0000 - r2: 0.7279 - root_mean_squared_error: 80052.6797 - val_loss: 12712922112.0000 - val_r2: 0.5347 - val_root_mean_squared_error: 112751.5938\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6415702016.0000 - r2: 0.7278 - root_mean_squared_error: 80098.0781 - val_loss: 13117418496.0000 - val_r2: 0.5201 - val_root_mean_squared_error: 114531.2969\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6413865984.0000 - r2: 0.7280 - root_mean_squared_error: 80086.6172 - val_loss: 14226703360.0000 - val_r2: 0.4801 - val_root_mean_squared_error: 119275.7422\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6414790656.0000 - r2: 0.7276 - root_mean_squared_error: 80092.3906 - val_loss: 11850858496.0000 - val_r2: 0.5666 - val_root_mean_squared_error: 108861.6484\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6417420800.0000 - r2: 0.7273 - root_mean_squared_error: 80108.8047 - val_loss: 13080803328.0000 - val_r2: 0.5207 - val_root_mean_squared_error: 114371.3359\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6404208640.0000 - r2: 0.7280 - root_mean_squared_error: 80026.2969 - val_loss: 13037643776.0000 - val_r2: 0.5220 - val_root_mean_squared_error: 114182.5000\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6429112320.0000 - r2: 0.7270 - root_mean_squared_error: 80181.7422 - val_loss: 12289321984.0000 - val_r2: 0.5499 - val_root_mean_squared_error: 110857.2109\n",
      "session cleared!\n",
      "\n",
      "1160.0324339866638 seconds elapsed\n",
      "\n",
      "vec [1, 1, 1, 1, 1, 0, 1, 1, 1]\n",
      "ix 0 i 1\n",
      "updated temp_vec [0, 1, 1, 1, 1, 0, 1, 1, 1]\n",
      "going through feature_mask [0, 1, 1, 1, 1, 0, 1, 1, 1]\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 12), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 17), dtype=tf.float32, name=None), name='flatten_2/Reshape:0', description=\"created by layer 'flatten_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 43), dtype=tf.float32, name=None), name='flatten_1/Reshape:0', description=\"created by layer 'flatten_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization/truediv:0', description=\"created by layer 'normalization'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_1/truediv:0', description=\"created by layer 'normalization_1'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_2/truediv:0', description=\"created by layer 'normalization_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_3/truediv:0', description=\"created by layer 'normalization_3'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_4/truediv:0', description=\"created by layer 'normalization_4'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_5/truediv:0', description=\"created by layer 'normalization_5'\")\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 3s 5ms/step - loss: 37857259520.0000 - r2: -0.6213 - root_mean_squared_error: 194569.4219 - val_loss: 14167877632.0000 - val_r2: 0.4830 - val_root_mean_squared_error: 119028.8906\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7552795136.0000 - r2: 0.6798 - root_mean_squared_error: 86906.8203 - val_loss: 13271340032.0000 - val_r2: 0.5139 - val_root_mean_squared_error: 115201.3047\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6655346688.0000 - r2: 0.7179 - root_mean_squared_error: 81580.3047 - val_loss: 12618569728.0000 - val_r2: 0.5381 - val_root_mean_squared_error: 112332.4062\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5804503040.0000 - r2: 0.7538 - root_mean_squared_error: 76187.2891 - val_loss: 11091836928.0000 - val_r2: 0.5947 - val_root_mean_squared_error: 105317.7891\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5162408448.0000 - r2: 0.7813 - root_mean_squared_error: 71849.8984 - val_loss: 10709426176.0000 - val_r2: 0.6072 - val_root_mean_squared_error: 103486.3594\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4739226624.0000 - r2: 0.7992 - root_mean_squared_error: 68842.0391 - val_loss: 11809644544.0000 - val_r2: 0.5677 - val_root_mean_squared_error: 108672.1875\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4432331776.0000 - r2: 0.8120 - root_mean_squared_error: 66575.7578 - val_loss: 10868622336.0000 - val_r2: 0.6017 - val_root_mean_squared_error: 104252.6875\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4204704000.0000 - r2: 0.8214 - root_mean_squared_error: 64843.6875 - val_loss: 11040514048.0000 - val_r2: 0.5952 - val_root_mean_squared_error: 105073.8516\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4071765504.0000 - r2: 0.8270 - root_mean_squared_error: 63810.3867 - val_loss: 10105115648.0000 - val_r2: 0.6300 - val_root_mean_squared_error: 100524.2031\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3984102144.0000 - r2: 0.8311 - root_mean_squared_error: 63119.7461 - val_loss: 9723227136.0000 - val_r2: 0.6433 - val_root_mean_squared_error: 98606.4219\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3944024576.0000 - r2: 0.8322 - root_mean_squared_error: 62801.4688 - val_loss: 9791745024.0000 - val_r2: 0.6406 - val_root_mean_squared_error: 98953.2500\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3906971392.0000 - r2: 0.8338 - root_mean_squared_error: 62505.7695 - val_loss: 9776577536.0000 - val_r2: 0.6419 - val_root_mean_squared_error: 98876.5781\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3881944064.0000 - r2: 0.8346 - root_mean_squared_error: 62305.2500 - val_loss: 10703192064.0000 - val_r2: 0.6082 - val_root_mean_squared_error: 103456.2344\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3868051712.0000 - r2: 0.8352 - root_mean_squared_error: 62193.6641 - val_loss: 10866770944.0000 - val_r2: 0.6019 - val_root_mean_squared_error: 104243.8047\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3855099648.0000 - r2: 0.8364 - root_mean_squared_error: 62089.4492 - val_loss: 9625156608.0000 - val_r2: 0.6471 - val_root_mean_squared_error: 98107.8828\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3851041024.0000 - r2: 0.8364 - root_mean_squared_error: 62056.7578 - val_loss: 8578006016.0000 - val_r2: 0.6854 - val_root_mean_squared_error: 92617.5234\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3826002176.0000 - r2: 0.8376 - root_mean_squared_error: 61854.6875 - val_loss: 11256374272.0000 - val_r2: 0.5869 - val_root_mean_squared_error: 106096.0625\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3837799680.0000 - r2: 0.8372 - root_mean_squared_error: 61949.9766 - val_loss: 10519939072.0000 - val_r2: 0.6142 - val_root_mean_squared_error: 102566.7578\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3823230720.0000 - r2: 0.8374 - root_mean_squared_error: 61832.2773 - val_loss: 9099718656.0000 - val_r2: 0.6666 - val_root_mean_squared_error: 95392.4453\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3754638848.0000 - r2: 0.8406 - root_mean_squared_error: 61275.1094 - val_loss: 9741666304.0000 - val_r2: 0.6427 - val_root_mean_squared_error: 98699.8828\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3589226240.0000 - r2: 0.8474 - root_mean_squared_error: 59910.1523 - val_loss: 10469681152.0000 - val_r2: 0.6155 - val_root_mean_squared_error: 102321.4609\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3420420608.0000 - r2: 0.8546 - root_mean_squared_error: 58484.3633 - val_loss: 10695710720.0000 - val_r2: 0.6076 - val_root_mean_squared_error: 103420.0703\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3239422208.0000 - r2: 0.8619 - root_mean_squared_error: 56915.9219 - val_loss: 8644435968.0000 - val_r2: 0.6826 - val_root_mean_squared_error: 92975.4609\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3103261952.0000 - r2: 0.8679 - root_mean_squared_error: 55706.9297 - val_loss: 8738878464.0000 - val_r2: 0.6791 - val_root_mean_squared_error: 93481.9688\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3015261696.0000 - r2: 0.8717 - root_mean_squared_error: 54911.3984 - val_loss: 8952608768.0000 - val_r2: 0.6718 - val_root_mean_squared_error: 94618.2266\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2950742272.0000 - r2: 0.8744 - root_mean_squared_error: 54320.7344 - val_loss: 9760452608.0000 - val_r2: 0.6429 - val_root_mean_squared_error: 98795.0000\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2928738816.0000 - r2: 0.8751 - root_mean_squared_error: 54117.8242 - val_loss: 9957527552.0000 - val_r2: 0.6344 - val_root_mean_squared_error: 99787.4141\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2914759936.0000 - r2: 0.8759 - root_mean_squared_error: 53988.5156 - val_loss: 9225703424.0000 - val_r2: 0.6609 - val_root_mean_squared_error: 96050.5234\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2899037952.0000 - r2: 0.8767 - root_mean_squared_error: 53842.7148 - val_loss: 9131159552.0000 - val_r2: 0.6645 - val_root_mean_squared_error: 95557.1016\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2873192192.0000 - r2: 0.8777 - root_mean_squared_error: 53602.1641 - val_loss: 8482988544.0000 - val_r2: 0.6885 - val_root_mean_squared_error: 92103.1406\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2875031296.0000 - r2: 0.8776 - root_mean_squared_error: 53619.3164 - val_loss: 9470645248.0000 - val_r2: 0.6528 - val_root_mean_squared_error: 97317.2422\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2869633536.0000 - r2: 0.8781 - root_mean_squared_error: 53568.9609 - val_loss: 10728706048.0000 - val_r2: 0.6065 - val_root_mean_squared_error: 103579.4688\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2844451072.0000 - r2: 0.8791 - root_mean_squared_error: 53333.3945 - val_loss: 8640843776.0000 - val_r2: 0.6828 - val_root_mean_squared_error: 92956.1406\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2854326272.0000 - r2: 0.8783 - root_mean_squared_error: 53425.8945 - val_loss: 10397039616.0000 - val_r2: 0.6180 - val_root_mean_squared_error: 101965.8750\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2827961856.0000 - r2: 0.8796 - root_mean_squared_error: 53178.5859 - val_loss: 9365881856.0000 - val_r2: 0.6559 - val_root_mean_squared_error: 96777.4844\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2836529152.0000 - r2: 0.8793 - root_mean_squared_error: 53259.0742 - val_loss: 8137633280.0000 - val_r2: 0.7008 - val_root_mean_squared_error: 90208.8281\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2832706816.0000 - r2: 0.8796 - root_mean_squared_error: 53223.1797 - val_loss: 7971602432.0000 - val_r2: 0.7077 - val_root_mean_squared_error: 89283.8281\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2827082240.0000 - r2: 0.8795 - root_mean_squared_error: 53170.3125 - val_loss: 8556467712.0000 - val_r2: 0.6858 - val_root_mean_squared_error: 92501.1797\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2825408768.0000 - r2: 0.8796 - root_mean_squared_error: 53154.5742 - val_loss: 9428462592.0000 - val_r2: 0.6539 - val_root_mean_squared_error: 97100.2734\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2819998976.0000 - r2: 0.8799 - root_mean_squared_error: 53103.6641 - val_loss: 8915548160.0000 - val_r2: 0.6730 - val_root_mean_squared_error: 94422.1797\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2811226368.0000 - r2: 0.8803 - root_mean_squared_error: 53021.0000 - val_loss: 9324480512.0000 - val_r2: 0.6580 - val_root_mean_squared_error: 96563.3516\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2818610944.0000 - r2: 0.8800 - root_mean_squared_error: 53090.5938 - val_loss: 8402131456.0000 - val_r2: 0.6918 - val_root_mean_squared_error: 91663.1406\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2814007296.0000 - r2: 0.8801 - root_mean_squared_error: 53047.2188 - val_loss: 8880854016.0000 - val_r2: 0.6734 - val_root_mean_squared_error: 94238.2812\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2817136640.0000 - r2: 0.8800 - root_mean_squared_error: 53076.7070 - val_loss: 8385132544.0000 - val_r2: 0.6917 - val_root_mean_squared_error: 91570.3672\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2810868736.0000 - r2: 0.8803 - root_mean_squared_error: 53017.6250 - val_loss: 9310891008.0000 - val_r2: 0.6576 - val_root_mean_squared_error: 96492.9609\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2801261312.0000 - r2: 0.8809 - root_mean_squared_error: 52926.9414 - val_loss: 8733074432.0000 - val_r2: 0.6799 - val_root_mean_squared_error: 93450.9219\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2823941632.0000 - r2: 0.8797 - root_mean_squared_error: 53140.7734 - val_loss: 9311699968.0000 - val_r2: 0.6575 - val_root_mean_squared_error: 96497.1484\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2805649408.0000 - r2: 0.8804 - root_mean_squared_error: 52968.3828 - val_loss: 8517422080.0000 - val_r2: 0.6867 - val_root_mean_squared_error: 92289.8828\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2789507328.0000 - r2: 0.8813 - root_mean_squared_error: 52815.7852 - val_loss: 9244548096.0000 - val_r2: 0.6607 - val_root_mean_squared_error: 96148.5703\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2784145408.0000 - r2: 0.8814 - root_mean_squared_error: 52765.0000 - val_loss: 8399119360.0000 - val_r2: 0.6918 - val_root_mean_squared_error: 91646.7109\n",
      "session cleared!\n",
      "\n",
      "ix 1 i 1\n",
      "updated temp_vec [1, 0, 1, 1, 1, 0, 1, 1, 1]\n",
      "going through feature_mask [1, 0, 1, 1, 1, 0, 1, 1, 1]\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 12), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 17), dtype=tf.float32, name=None), name='flatten_2/Reshape:0', description=\"created by layer 'flatten_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 43), dtype=tf.float32, name=None), name='flatten_1/Reshape:0', description=\"created by layer 'flatten_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization/truediv:0', description=\"created by layer 'normalization'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_1/truediv:0', description=\"created by layer 'normalization_1'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_2/truediv:0', description=\"created by layer 'normalization_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_3/truediv:0', description=\"created by layer 'normalization_3'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_4/truediv:0', description=\"created by layer 'normalization_4'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_5/truediv:0', description=\"created by layer 'normalization_5'\")\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 40527892480.0000 - r2: -0.6994 - root_mean_squared_error: 201315.4062 - val_loss: 16624133120.0000 - val_r2: 0.3934 - val_root_mean_squared_error: 128934.6094\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 9255768064.0000 - r2: 0.6081 - root_mean_squared_error: 96206.9062 - val_loss: 15594773504.0000 - val_r2: 0.4303 - val_root_mean_squared_error: 124879.0391\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 8143728640.0000 - r2: 0.6552 - root_mean_squared_error: 90242.6094 - val_loss: 14780280832.0000 - val_r2: 0.4604 - val_root_mean_squared_error: 121574.1797\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6996044800.0000 - r2: 0.7035 - root_mean_squared_error: 83642.3594 - val_loss: 13683344384.0000 - val_r2: 0.5003 - val_root_mean_squared_error: 116975.8281\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6122361344.0000 - r2: 0.7413 - root_mean_squared_error: 78245.5234 - val_loss: 12426534912.0000 - val_r2: 0.5459 - val_root_mean_squared_error: 111474.3672\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5566875136.0000 - r2: 0.7641 - root_mean_squared_error: 74611.4922 - val_loss: 13154125824.0000 - val_r2: 0.5187 - val_root_mean_squared_error: 114691.4375\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5186251264.0000 - r2: 0.7800 - root_mean_squared_error: 72015.6328 - val_loss: 12256166912.0000 - val_r2: 0.5521 - val_root_mean_squared_error: 110707.5703\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4920937984.0000 - r2: 0.7908 - root_mean_squared_error: 70149.3984 - val_loss: 11785321472.0000 - val_r2: 0.5682 - val_root_mean_squared_error: 108560.2188\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4758582784.0000 - r2: 0.7982 - root_mean_squared_error: 68982.4844 - val_loss: 11346977792.0000 - val_r2: 0.5853 - val_root_mean_squared_error: 106522.1953\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4643198976.0000 - r2: 0.8033 - root_mean_squared_error: 68141.0234 - val_loss: 11185783808.0000 - val_r2: 0.5908 - val_root_mean_squared_error: 105762.8672\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4595008000.0000 - r2: 0.8050 - root_mean_squared_error: 67786.4922 - val_loss: 12254818304.0000 - val_r2: 0.5512 - val_root_mean_squared_error: 110701.4844\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4546817024.0000 - r2: 0.8072 - root_mean_squared_error: 67430.0938 - val_loss: 12569579520.0000 - val_r2: 0.5394 - val_root_mean_squared_error: 112114.1328\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4522314240.0000 - r2: 0.8078 - root_mean_squared_error: 67248.1562 - val_loss: 12416929792.0000 - val_r2: 0.5445 - val_root_mean_squared_error: 111431.2812\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4514107392.0000 - r2: 0.8085 - root_mean_squared_error: 67187.1094 - val_loss: 12031508480.0000 - val_r2: 0.5599 - val_root_mean_squared_error: 109688.2344\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4495040512.0000 - r2: 0.8092 - root_mean_squared_error: 67045.0625 - val_loss: 10903667712.0000 - val_r2: 0.6009 - val_root_mean_squared_error: 104420.6250\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4495819776.0000 - r2: 0.8094 - root_mean_squared_error: 67050.8750 - val_loss: 11417322496.0000 - val_r2: 0.5825 - val_root_mean_squared_error: 106851.8750\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4473291264.0000 - r2: 0.8100 - root_mean_squared_error: 66882.6641 - val_loss: 12333874176.0000 - val_r2: 0.5483 - val_root_mean_squared_error: 111057.9766\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4473223680.0000 - r2: 0.8103 - root_mean_squared_error: 66882.1641 - val_loss: 10442329088.0000 - val_r2: 0.6183 - val_root_mean_squared_error: 102187.7188\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4476099584.0000 - r2: 0.8091 - root_mean_squared_error: 66903.6562 - val_loss: 11217277952.0000 - val_r2: 0.5890 - val_root_mean_squared_error: 105911.6484\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4413742592.0000 - r2: 0.8126 - root_mean_squared_error: 66436.0000 - val_loss: 11729480704.0000 - val_r2: 0.5706 - val_root_mean_squared_error: 108302.7266\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4179464704.0000 - r2: 0.8224 - root_mean_squared_error: 64648.7812 - val_loss: 10355244032.0000 - val_r2: 0.6206 - val_root_mean_squared_error: 101760.7188\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4039190784.0000 - r2: 0.8284 - root_mean_squared_error: 63554.6289 - val_loss: 12351778816.0000 - val_r2: 0.5471 - val_root_mean_squared_error: 111138.5547\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3838621184.0000 - r2: 0.8366 - root_mean_squared_error: 61956.6055 - val_loss: 10811312128.0000 - val_r2: 0.6037 - val_root_mean_squared_error: 103977.4609\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3701930240.0000 - r2: 0.8425 - root_mean_squared_error: 60843.4883 - val_loss: 10742649856.0000 - val_r2: 0.6059 - val_root_mean_squared_error: 103646.7578\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3590403840.0000 - r2: 0.8473 - root_mean_squared_error: 59919.9805 - val_loss: 9334409216.0000 - val_r2: 0.6580 - val_root_mean_squared_error: 96614.7500\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3477407488.0000 - r2: 0.8525 - root_mean_squared_error: 58969.5469 - val_loss: 9469151232.0000 - val_r2: 0.6529 - val_root_mean_squared_error: 97309.5625\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3446220288.0000 - r2: 0.8536 - root_mean_squared_error: 58704.5156 - val_loss: 10307408896.0000 - val_r2: 0.6222 - val_root_mean_squared_error: 101525.4062\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3419717888.0000 - r2: 0.8545 - root_mean_squared_error: 58478.3555 - val_loss: 10496034816.0000 - val_r2: 0.6156 - val_root_mean_squared_error: 102450.1562\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3405371904.0000 - r2: 0.8554 - root_mean_squared_error: 58355.5664 - val_loss: 8628605952.0000 - val_r2: 0.6839 - val_root_mean_squared_error: 92890.2891\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3404560128.0000 - r2: 0.8552 - root_mean_squared_error: 58348.6094 - val_loss: 10854432768.0000 - val_r2: 0.6007 - val_root_mean_squared_error: 104184.6094\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3395290368.0000 - r2: 0.8558 - root_mean_squared_error: 58269.1211 - val_loss: 8979535872.0000 - val_r2: 0.6710 - val_root_mean_squared_error: 94760.4141\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3394764544.0000 - r2: 0.8556 - root_mean_squared_error: 58264.6094 - val_loss: 8979657728.0000 - val_r2: 0.6702 - val_root_mean_squared_error: 94761.0547\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3400069376.0000 - r2: 0.8552 - root_mean_squared_error: 58310.1133 - val_loss: 10048688128.0000 - val_r2: 0.6313 - val_root_mean_squared_error: 100243.1484\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3376026368.0000 - r2: 0.8566 - root_mean_squared_error: 58103.5820 - val_loss: 10401821696.0000 - val_r2: 0.6181 - val_root_mean_squared_error: 101989.3203\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3381677568.0000 - r2: 0.8564 - root_mean_squared_error: 58152.1914 - val_loss: 9324765184.0000 - val_r2: 0.6578 - val_root_mean_squared_error: 96564.8203\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3367680256.0000 - r2: 0.8570 - root_mean_squared_error: 58031.7188 - val_loss: 9371638784.0000 - val_r2: 0.6563 - val_root_mean_squared_error: 96807.2266\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3358336512.0000 - r2: 0.8571 - root_mean_squared_error: 57951.1562 - val_loss: 9860109312.0000 - val_r2: 0.6377 - val_root_mean_squared_error: 99298.0859\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3367112960.0000 - r2: 0.8568 - root_mean_squared_error: 58026.8281 - val_loss: 9796368384.0000 - val_r2: 0.6411 - val_root_mean_squared_error: 98976.6016\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3352838656.0000 - r2: 0.8573 - root_mean_squared_error: 57903.7031 - val_loss: 8430142464.0000 - val_r2: 0.6909 - val_root_mean_squared_error: 91815.8047\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3347154688.0000 - r2: 0.8577 - root_mean_squared_error: 57854.5977 - val_loss: 9562866688.0000 - val_r2: 0.6488 - val_root_mean_squared_error: 97789.9141\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3335331584.0000 - r2: 0.8582 - root_mean_squared_error: 57752.3281 - val_loss: 10162406400.0000 - val_r2: 0.6269 - val_root_mean_squared_error: 100808.7578\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3332416000.0000 - r2: 0.8582 - root_mean_squared_error: 57727.0820 - val_loss: 9866020864.0000 - val_r2: 0.6385 - val_root_mean_squared_error: 99327.8438\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3329135872.0000 - r2: 0.8584 - root_mean_squared_error: 57698.6641 - val_loss: 11549181952.0000 - val_r2: 0.5765 - val_root_mean_squared_error: 107467.1172\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3320204032.0000 - r2: 0.8587 - root_mean_squared_error: 57621.2109 - val_loss: 9170297856.0000 - val_r2: 0.6636 - val_root_mean_squared_error: 95761.6719\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3323458304.0000 - r2: 0.8588 - root_mean_squared_error: 57649.4414 - val_loss: 9124625408.0000 - val_r2: 0.6656 - val_root_mean_squared_error: 95522.9062\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3315313920.0000 - r2: 0.8591 - root_mean_squared_error: 57578.7617 - val_loss: 9872033792.0000 - val_r2: 0.6379 - val_root_mean_squared_error: 99358.1094\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3312200704.0000 - r2: 0.8590 - root_mean_squared_error: 57551.7227 - val_loss: 9458311168.0000 - val_r2: 0.6536 - val_root_mean_squared_error: 97253.8516\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3312683776.0000 - r2: 0.8590 - root_mean_squared_error: 57555.9180 - val_loss: 8563454976.0000 - val_r2: 0.6862 - val_root_mean_squared_error: 92538.9375\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3303466752.0000 - r2: 0.8596 - root_mean_squared_error: 57475.7930 - val_loss: 10865308672.0000 - val_r2: 0.6018 - val_root_mean_squared_error: 104236.7891\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3295124736.0000 - r2: 0.8599 - root_mean_squared_error: 57403.1758 - val_loss: 9072693248.0000 - val_r2: 0.6671 - val_root_mean_squared_error: 95250.6875\n",
      "session cleared!\n",
      "\n",
      "ix 2 i 1\n",
      "updated temp_vec [1, 1, 0, 1, 1, 0, 1, 1, 1]\n",
      "going through feature_mask [1, 1, 0, 1, 1, 0, 1, 1, 1]\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 12), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 17), dtype=tf.float32, name=None), name='flatten_2/Reshape:0', description=\"created by layer 'flatten_2'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 43), dtype=tf.float32, name=None), name='flatten_1/Reshape:0', description=\"created by layer 'flatten_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization/truediv:0', description=\"created by layer 'normalization'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_1/truediv:0', description=\"created by layer 'normalization_1'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_2/truediv:0', description=\"created by layer 'normalization_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_3/truediv:0', description=\"created by layer 'normalization_3'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_4/truediv:0', description=\"created by layer 'normalization_4'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_5/truediv:0', description=\"created by layer 'normalization_5'\")\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 3s 5ms/step - loss: 51124244480.0000 - r2: -1.1506 - root_mean_squared_error: 226106.7031 - val_loss: 27865368576.0000 - val_r2: -0.0190 - val_root_mean_squared_error: 166929.2344\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 16754325504.0000 - r2: 0.2908 - root_mean_squared_error: 129438.5000 - val_loss: 24005294080.0000 - val_r2: 0.1236 - val_root_mean_squared_error: 154936.4219\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 13612122112.0000 - r2: 0.4237 - root_mean_squared_error: 116671.0000 - val_loss: 21704830976.0000 - val_r2: 0.2066 - val_root_mean_squared_error: 147325.5938\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 9771189248.0000 - r2: 0.5866 - root_mean_squared_error: 98849.3281 - val_loss: 16517894144.0000 - val_r2: 0.3968 - val_root_mean_squared_error: 128521.9609\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6618773504.0000 - r2: 0.7199 - root_mean_squared_error: 81355.8438 - val_loss: 12837987328.0000 - val_r2: 0.5307 - val_root_mean_squared_error: 113304.8438\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5074068992.0000 - r2: 0.7848 - root_mean_squared_error: 71232.5000 - val_loss: 11970656256.0000 - val_r2: 0.5627 - val_root_mean_squared_error: 109410.4922\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4588992512.0000 - r2: 0.8056 - root_mean_squared_error: 67742.1016 - val_loss: 10793057280.0000 - val_r2: 0.6055 - val_root_mean_squared_error: 103889.6406\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4509165056.0000 - r2: 0.8087 - root_mean_squared_error: 67150.3203 - val_loss: 10164982784.0000 - val_r2: 0.6274 - val_root_mean_squared_error: 100821.5391\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4502710272.0000 - r2: 0.8091 - root_mean_squared_error: 67102.2344 - val_loss: 10572571648.0000 - val_r2: 0.6134 - val_root_mean_squared_error: 102823.0078\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4501151232.0000 - r2: 0.8091 - root_mean_squared_error: 67090.6172 - val_loss: 12008769536.0000 - val_r2: 0.5598 - val_root_mean_squared_error: 109584.5312\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4493655552.0000 - r2: 0.8090 - root_mean_squared_error: 67034.7344 - val_loss: 10816330752.0000 - val_r2: 0.6041 - val_root_mean_squared_error: 104001.5938\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4494143488.0000 - r2: 0.8093 - root_mean_squared_error: 67038.3750 - val_loss: 10404410368.0000 - val_r2: 0.6193 - val_root_mean_squared_error: 102002.0078\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4387937792.0000 - r2: 0.8138 - root_mean_squared_error: 66241.5078 - val_loss: 9960695808.0000 - val_r2: 0.6341 - val_root_mean_squared_error: 99803.2891\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4114594048.0000 - r2: 0.8249 - root_mean_squared_error: 64145.1016 - val_loss: 10569666560.0000 - val_r2: 0.6128 - val_root_mean_squared_error: 102808.8828\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3898080256.0000 - r2: 0.8348 - root_mean_squared_error: 62434.6094 - val_loss: 10352121856.0000 - val_r2: 0.6205 - val_root_mean_squared_error: 101745.3750\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3708592640.0000 - r2: 0.8424 - root_mean_squared_error: 60898.2148 - val_loss: 10742617088.0000 - val_r2: 0.6063 - val_root_mean_squared_error: 103646.5938\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3590037248.0000 - r2: 0.8474 - root_mean_squared_error: 59916.9180 - val_loss: 11393364992.0000 - val_r2: 0.5821 - val_root_mean_squared_error: 106739.7031\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3523325952.0000 - r2: 0.8504 - root_mean_squared_error: 59357.6094 - val_loss: 10722186240.0000 - val_r2: 0.6067 - val_root_mean_squared_error: 103547.9922\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3489607168.0000 - r2: 0.8514 - root_mean_squared_error: 59072.8984 - val_loss: 10240885760.0000 - val_r2: 0.6246 - val_root_mean_squared_error: 101197.2578\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3468683264.0000 - r2: 0.8528 - root_mean_squared_error: 58895.5273 - val_loss: 10449199104.0000 - val_r2: 0.6164 - val_root_mean_squared_error: 102221.3203\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3442442496.0000 - r2: 0.8540 - root_mean_squared_error: 58672.3320 - val_loss: 9523865600.0000 - val_r2: 0.6506 - val_root_mean_squared_error: 97590.2969\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3425929472.0000 - r2: 0.8543 - root_mean_squared_error: 58531.4414 - val_loss: 9951551488.0000 - val_r2: 0.6344 - val_root_mean_squared_error: 99757.4609\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3411997184.0000 - r2: 0.8551 - root_mean_squared_error: 58412.3047 - val_loss: 10610095104.0000 - val_r2: 0.6100 - val_root_mean_squared_error: 103005.3125\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3393724416.0000 - r2: 0.8558 - root_mean_squared_error: 58255.6797 - val_loss: 9770875904.0000 - val_r2: 0.6416 - val_root_mean_squared_error: 98847.7422\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3375572480.0000 - r2: 0.8561 - root_mean_squared_error: 58099.6758 - val_loss: 9465116672.0000 - val_r2: 0.6530 - val_root_mean_squared_error: 97288.8281\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3337966592.0000 - r2: 0.8580 - root_mean_squared_error: 57775.1367 - val_loss: 9698809856.0000 - val_r2: 0.6442 - val_root_mean_squared_error: 98482.5391\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3313315584.0000 - r2: 0.8591 - root_mean_squared_error: 57561.4062 - val_loss: 11210096640.0000 - val_r2: 0.5884 - val_root_mean_squared_error: 105877.7422\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3267478784.0000 - r2: 0.8611 - root_mean_squared_error: 57161.8633 - val_loss: 8990635008.0000 - val_r2: 0.6703 - val_root_mean_squared_error: 94818.9609\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3243715328.0000 - r2: 0.8622 - root_mean_squared_error: 56953.6250 - val_loss: 8837458944.0000 - val_r2: 0.6759 - val_root_mean_squared_error: 94007.7578\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3207240960.0000 - r2: 0.8638 - root_mean_squared_error: 56632.5078 - val_loss: 9830225920.0000 - val_r2: 0.6391 - val_root_mean_squared_error: 99147.4922\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3179515392.0000 - r2: 0.8649 - root_mean_squared_error: 56387.1914 - val_loss: 9381706752.0000 - val_r2: 0.6558 - val_root_mean_squared_error: 96859.2109\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3148918528.0000 - r2: 0.8661 - root_mean_squared_error: 56115.2266 - val_loss: 10511755264.0000 - val_r2: 0.6143 - val_root_mean_squared_error: 102526.8516\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3133092864.0000 - r2: 0.8666 - root_mean_squared_error: 55974.0391 - val_loss: 10019229696.0000 - val_r2: 0.6323 - val_root_mean_squared_error: 100096.1016\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3126096640.0000 - r2: 0.8670 - root_mean_squared_error: 55911.5078 - val_loss: 9524771840.0000 - val_r2: 0.6504 - val_root_mean_squared_error: 97594.9375\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3090451712.0000 - r2: 0.8688 - root_mean_squared_error: 55591.8320 - val_loss: 9451220992.0000 - val_r2: 0.6533 - val_root_mean_squared_error: 97217.3906\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3090094848.0000 - r2: 0.8685 - root_mean_squared_error: 55588.6211 - val_loss: 8738764800.0000 - val_r2: 0.6801 - val_root_mean_squared_error: 93481.3594\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3072372480.0000 - r2: 0.8694 - root_mean_squared_error: 55428.9844 - val_loss: 9061257216.0000 - val_r2: 0.6675 - val_root_mean_squared_error: 95190.6328\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3071397376.0000 - r2: 0.8689 - root_mean_squared_error: 55420.1875 - val_loss: 9514900480.0000 - val_r2: 0.6498 - val_root_mean_squared_error: 97544.3516\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3060094976.0000 - r2: 0.8695 - root_mean_squared_error: 55318.1250 - val_loss: 9199161344.0000 - val_r2: 0.6626 - val_root_mean_squared_error: 95912.2578\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3061095424.0000 - r2: 0.8695 - root_mean_squared_error: 55327.1680 - val_loss: 9245604864.0000 - val_r2: 0.6606 - val_root_mean_squared_error: 96154.0703\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3052878080.0000 - r2: 0.8701 - root_mean_squared_error: 55252.8555 - val_loss: 10007197696.0000 - val_r2: 0.6324 - val_root_mean_squared_error: 100035.9844\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3045803520.0000 - r2: 0.8706 - root_mean_squared_error: 55188.8008 - val_loss: 9473726464.0000 - val_r2: 0.6520 - val_root_mean_squared_error: 97333.0703\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3042016000.0000 - r2: 0.8707 - root_mean_squared_error: 55154.4727 - val_loss: 9520032768.0000 - val_r2: 0.6514 - val_root_mean_squared_error: 97570.6562\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3043891200.0000 - r2: 0.8705 - root_mean_squared_error: 55171.4727 - val_loss: 9036831744.0000 - val_r2: 0.6679 - val_root_mean_squared_error: 95062.2500\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3041385984.0000 - r2: 0.8705 - root_mean_squared_error: 55148.7617 - val_loss: 9108633600.0000 - val_r2: 0.6656 - val_root_mean_squared_error: 95439.1641\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3044056320.0000 - r2: 0.8705 - root_mean_squared_error: 55172.9688 - val_loss: 8866935808.0000 - val_r2: 0.6750 - val_root_mean_squared_error: 94164.4062\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3029756160.0000 - r2: 0.8712 - root_mean_squared_error: 55043.2227 - val_loss: 9630260224.0000 - val_r2: 0.6466 - val_root_mean_squared_error: 98133.8906\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3039864320.0000 - r2: 0.8708 - root_mean_squared_error: 55134.9648 - val_loss: 10241987584.0000 - val_r2: 0.6243 - val_root_mean_squared_error: 101202.7031\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3038368256.0000 - r2: 0.8708 - root_mean_squared_error: 55121.3945 - val_loss: 11497968640.0000 - val_r2: 0.5779 - val_root_mean_squared_error: 107228.5781\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3044492800.0000 - r2: 0.8701 - root_mean_squared_error: 55176.9219 - val_loss: 8882924544.0000 - val_r2: 0.6735 - val_root_mean_squared_error: 94249.2656\n",
      "session cleared!\n",
      "\n",
      "ix 3 i 1\n",
      "updated temp_vec [1, 1, 1, 0, 1, 0, 1, 1, 1]\n",
      "going through feature_mask [1, 1, 1, 0, 1, 0, 1, 1, 1]\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 12), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 17), dtype=tf.float32, name=None), name='flatten_2/Reshape:0', description=\"created by layer 'flatten_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 43), dtype=tf.float32, name=None), name='flatten_1/Reshape:0', description=\"created by layer 'flatten_1'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization/truediv:0', description=\"created by layer 'normalization'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_1/truediv:0', description=\"created by layer 'normalization_1'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_2/truediv:0', description=\"created by layer 'normalization_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_3/truediv:0', description=\"created by layer 'normalization_3'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_4/truediv:0', description=\"created by layer 'normalization_4'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_5/truediv:0', description=\"created by layer 'normalization_5'\")\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 36893114368.0000 - r2: -0.5578 - root_mean_squared_error: 192075.7969 - val_loss: 14291615744.0000 - val_r2: 0.4780 - val_root_mean_squared_error: 119547.5469\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7608476672.0000 - r2: 0.6765 - root_mean_squared_error: 87226.5859 - val_loss: 13534712832.0000 - val_r2: 0.5055 - val_root_mean_squared_error: 116338.7812\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6751668736.0000 - r2: 0.7138 - root_mean_squared_error: 82168.5391 - val_loss: 11796497408.0000 - val_r2: 0.5685 - val_root_mean_squared_error: 108611.6797\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5890581504.0000 - r2: 0.7504 - root_mean_squared_error: 76750.1250 - val_loss: 12569379840.0000 - val_r2: 0.5403 - val_root_mean_squared_error: 112113.2422\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5264443904.0000 - r2: 0.7766 - root_mean_squared_error: 72556.4844 - val_loss: 10893074432.0000 - val_r2: 0.6007 - val_root_mean_squared_error: 104369.8906\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4854150144.0000 - r2: 0.7940 - root_mean_squared_error: 69671.7344 - val_loss: 12299674624.0000 - val_r2: 0.5500 - val_root_mean_squared_error: 110903.8984\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4592230912.0000 - r2: 0.8050 - root_mean_squared_error: 67766.0000 - val_loss: 10570642432.0000 - val_r2: 0.6129 - val_root_mean_squared_error: 102813.6328\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4397775360.0000 - r2: 0.8131 - root_mean_squared_error: 66315.7266 - val_loss: 9713819648.0000 - val_r2: 0.6437 - val_root_mean_squared_error: 98558.7109\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4299895808.0000 - r2: 0.8171 - root_mean_squared_error: 65573.5938 - val_loss: 9589595136.0000 - val_r2: 0.6488 - val_root_mean_squared_error: 97926.4766\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4230183936.0000 - r2: 0.8203 - root_mean_squared_error: 65039.8633 - val_loss: 9110781952.0000 - val_r2: 0.6663 - val_root_mean_squared_error: 95450.4141\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4211834368.0000 - r2: 0.8213 - root_mean_squared_error: 64898.6484 - val_loss: 9314951168.0000 - val_r2: 0.6586 - val_root_mean_squared_error: 96513.9922\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4193618944.0000 - r2: 0.8216 - root_mean_squared_error: 64758.1562 - val_loss: 10024451072.0000 - val_r2: 0.6324 - val_root_mean_squared_error: 100122.1797\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4195853312.0000 - r2: 0.8217 - root_mean_squared_error: 64775.4062 - val_loss: 10879451136.0000 - val_r2: 0.6015 - val_root_mean_squared_error: 104304.6094\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4190738176.0000 - r2: 0.8219 - root_mean_squared_error: 64735.9102 - val_loss: 9768662016.0000 - val_r2: 0.6416 - val_root_mean_squared_error: 98836.5391\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4187417600.0000 - r2: 0.8221 - root_mean_squared_error: 64710.2578 - val_loss: 11043187712.0000 - val_r2: 0.5949 - val_root_mean_squared_error: 105086.5703\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4180529664.0000 - r2: 0.8226 - root_mean_squared_error: 64657.0156 - val_loss: 9305328640.0000 - val_r2: 0.6591 - val_root_mean_squared_error: 96464.1328\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4181704960.0000 - r2: 0.8222 - root_mean_squared_error: 64666.1055 - val_loss: 9292056576.0000 - val_r2: 0.6598 - val_root_mean_squared_error: 96395.3125\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4016864512.0000 - r2: 0.8292 - root_mean_squared_error: 63378.7383 - val_loss: 10785845248.0000 - val_r2: 0.6046 - val_root_mean_squared_error: 103854.9219\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3906922240.0000 - r2: 0.8339 - root_mean_squared_error: 62505.3789 - val_loss: 9965260800.0000 - val_r2: 0.6349 - val_root_mean_squared_error: 99826.1562\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3770572288.0000 - r2: 0.8396 - root_mean_squared_error: 61404.9844 - val_loss: 9973595136.0000 - val_r2: 0.6341 - val_root_mean_squared_error: 99867.8906\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3656749056.0000 - r2: 0.8446 - root_mean_squared_error: 60471.0586 - val_loss: 9523146752.0000 - val_r2: 0.6506 - val_root_mean_squared_error: 97586.6094\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3561505536.0000 - r2: 0.8486 - root_mean_squared_error: 59678.3516 - val_loss: 11219336192.0000 - val_r2: 0.5891 - val_root_mean_squared_error: 105921.3672\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3491353088.0000 - r2: 0.8511 - root_mean_squared_error: 59087.6719 - val_loss: 10095934464.0000 - val_r2: 0.6294 - val_root_mean_squared_error: 100478.5312\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3453367552.0000 - r2: 0.8533 - root_mean_squared_error: 58765.3594 - val_loss: 10683531264.0000 - val_r2: 0.6084 - val_root_mean_squared_error: 103361.1719\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3407425024.0000 - r2: 0.8553 - root_mean_squared_error: 58373.1523 - val_loss: 7877247488.0000 - val_r2: 0.7111 - val_root_mean_squared_error: 88753.8594\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3383174656.0000 - r2: 0.8561 - root_mean_squared_error: 58165.0625 - val_loss: 9193165824.0000 - val_r2: 0.6616 - val_root_mean_squared_error: 95881.0000\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3385302784.0000 - r2: 0.8562 - root_mean_squared_error: 58183.3555 - val_loss: 9444583424.0000 - val_r2: 0.6534 - val_root_mean_squared_error: 97183.2500\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3373481216.0000 - r2: 0.8567 - root_mean_squared_error: 58081.6758 - val_loss: 9746564096.0000 - val_r2: 0.6418 - val_root_mean_squared_error: 98724.6875\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3369315584.0000 - r2: 0.8568 - root_mean_squared_error: 58045.8047 - val_loss: 8038915072.0000 - val_r2: 0.7056 - val_root_mean_squared_error: 89660.0000\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3371997952.0000 - r2: 0.8566 - root_mean_squared_error: 58068.9062 - val_loss: 8663301120.0000 - val_r2: 0.6824 - val_root_mean_squared_error: 93076.8594\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3378932480.0000 - r2: 0.8560 - root_mean_squared_error: 58128.5859 - val_loss: 9028428800.0000 - val_r2: 0.6694 - val_root_mean_squared_error: 95018.0469\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3369973248.0000 - r2: 0.8567 - root_mean_squared_error: 58051.4688 - val_loss: 8466976256.0000 - val_r2: 0.6894 - val_root_mean_squared_error: 92016.1719\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3363882752.0000 - r2: 0.8566 - root_mean_squared_error: 57998.9883 - val_loss: 7640769536.0000 - val_r2: 0.7197 - val_root_mean_squared_error: 87411.4922\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3360492032.0000 - r2: 0.8571 - root_mean_squared_error: 57969.7500 - val_loss: 10663708672.0000 - val_r2: 0.6079 - val_root_mean_squared_error: 103265.2344\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3359721216.0000 - r2: 0.8571 - root_mean_squared_error: 57963.1016 - val_loss: 9228841984.0000 - val_r2: 0.6614 - val_root_mean_squared_error: 96066.8594\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3359197184.0000 - r2: 0.8571 - root_mean_squared_error: 57958.5820 - val_loss: 10421393408.0000 - val_r2: 0.6179 - val_root_mean_squared_error: 102085.2266\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3366573824.0000 - r2: 0.8570 - root_mean_squared_error: 58022.1836 - val_loss: 8901738496.0000 - val_r2: 0.6737 - val_root_mean_squared_error: 94349.0234\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3346209536.0000 - r2: 0.8578 - root_mean_squared_error: 57846.4297 - val_loss: 9198803968.0000 - val_r2: 0.6626 - val_root_mean_squared_error: 95910.3984\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3354278656.0000 - r2: 0.8571 - root_mean_squared_error: 57916.1328 - val_loss: 10501881856.0000 - val_r2: 0.6154 - val_root_mean_squared_error: 102478.6875\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3365302016.0000 - r2: 0.8568 - root_mean_squared_error: 58011.2227 - val_loss: 9595331584.0000 - val_r2: 0.6484 - val_root_mean_squared_error: 97955.7656\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3351254016.0000 - r2: 0.8572 - root_mean_squared_error: 57890.0156 - val_loss: 9854688256.0000 - val_r2: 0.6389 - val_root_mean_squared_error: 99270.7812\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3361967104.0000 - r2: 0.8570 - root_mean_squared_error: 57982.4727 - val_loss: 8338052608.0000 - val_r2: 0.6939 - val_root_mean_squared_error: 91312.9375\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3349037312.0000 - r2: 0.8573 - root_mean_squared_error: 57870.8672 - val_loss: 10418463744.0000 - val_r2: 0.6175 - val_root_mean_squared_error: 102070.8750\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3363582720.0000 - r2: 0.8570 - root_mean_squared_error: 57996.4023 - val_loss: 11144377344.0000 - val_r2: 0.5901 - val_root_mean_squared_error: 105566.9297\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3344904192.0000 - r2: 0.8575 - root_mean_squared_error: 57835.1484 - val_loss: 9432378368.0000 - val_r2: 0.6538 - val_root_mean_squared_error: 97120.4297\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3355304192.0000 - r2: 0.8574 - root_mean_squared_error: 57924.9883 - val_loss: 10461048832.0000 - val_r2: 0.6161 - val_root_mean_squared_error: 102279.2656\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3349996288.0000 - r2: 0.8574 - root_mean_squared_error: 57879.1523 - val_loss: 8355235840.0000 - val_r2: 0.6937 - val_root_mean_squared_error: 91406.9766\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3365749248.0000 - r2: 0.8569 - root_mean_squared_error: 58015.0781 - val_loss: 11144263680.0000 - val_r2: 0.5910 - val_root_mean_squared_error: 105566.3984\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3339234816.0000 - r2: 0.8581 - root_mean_squared_error: 57786.1133 - val_loss: 9368070144.0000 - val_r2: 0.6560 - val_root_mean_squared_error: 96788.7891\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3342286080.0000 - r2: 0.8575 - root_mean_squared_error: 57812.5078 - val_loss: 8975269888.0000 - val_r2: 0.6705 - val_root_mean_squared_error: 94737.8984\n",
      "new min loss: len 8, ix 3\n",
      "session cleared!\n",
      "\n",
      "ix 4 i 1\n",
      "updated temp_vec [1, 1, 1, 1, 0, 0, 1, 1, 1]\n",
      "going through feature_mask [1, 1, 1, 1, 0, 0, 1, 1, 1]\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 12), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 17), dtype=tf.float32, name=None), name='flatten_2/Reshape:0', description=\"created by layer 'flatten_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 43), dtype=tf.float32, name=None), name='flatten_1/Reshape:0', description=\"created by layer 'flatten_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization/truediv:0', description=\"created by layer 'normalization'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_1/truediv:0', description=\"created by layer 'normalization_1'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_2/truediv:0', description=\"created by layer 'normalization_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_3/truediv:0', description=\"created by layer 'normalization_3'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_4/truediv:0', description=\"created by layer 'normalization_4'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_5/truediv:0', description=\"created by layer 'normalization_5'\")\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 3s 6ms/step - loss: 38748221440.0000 - r2: -0.6585 - root_mean_squared_error: 196845.6719 - val_loss: 13888116736.0000 - val_r2: 0.4924 - val_root_mean_squared_error: 117847.8516\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7816590336.0000 - r2: 0.6689 - root_mean_squared_error: 88411.4844 - val_loss: 14289699840.0000 - val_r2: 0.4776 - val_root_mean_squared_error: 119539.5312\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7072208384.0000 - r2: 0.7003 - root_mean_squared_error: 84096.4219 - val_loss: 13393745920.0000 - val_r2: 0.5105 - val_root_mean_squared_error: 115731.3516\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6340756992.0000 - r2: 0.7312 - root_mean_squared_error: 79628.8672 - val_loss: 12140238848.0000 - val_r2: 0.5560 - val_root_mean_squared_error: 110182.7500\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5732031488.0000 - r2: 0.7572 - root_mean_squared_error: 75710.1797 - val_loss: 11939559424.0000 - val_r2: 0.5625 - val_root_mean_squared_error: 109268.2891\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5330143744.0000 - r2: 0.7736 - root_mean_squared_error: 73007.8359 - val_loss: 12050084864.0000 - val_r2: 0.5587 - val_root_mean_squared_error: 109772.8750\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5064986624.0000 - r2: 0.7850 - root_mean_squared_error: 71168.7188 - val_loss: 12191427584.0000 - val_r2: 0.5528 - val_root_mean_squared_error: 110414.7969\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4855435264.0000 - r2: 0.7938 - root_mean_squared_error: 69680.9531 - val_loss: 10074056704.0000 - val_r2: 0.6311 - val_root_mean_squared_error: 100369.6016\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4708334080.0000 - r2: 0.8000 - root_mean_squared_error: 68617.3047 - val_loss: 10463545344.0000 - val_r2: 0.6164 - val_root_mean_squared_error: 102291.4688\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4602419200.0000 - r2: 0.8040 - root_mean_squared_error: 67841.1328 - val_loss: 11021012992.0000 - val_r2: 0.5963 - val_root_mean_squared_error: 104981.0156\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4542895616.0000 - r2: 0.8071 - root_mean_squared_error: 67401.0078 - val_loss: 11309246464.0000 - val_r2: 0.5858 - val_root_mean_squared_error: 106344.9375\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4457777152.0000 - r2: 0.8108 - root_mean_squared_error: 66766.5859 - val_loss: 11644441600.0000 - val_r2: 0.5734 - val_root_mean_squared_error: 107909.4141\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4291720960.0000 - r2: 0.8177 - root_mean_squared_error: 65511.2266 - val_loss: 11133050880.0000 - val_r2: 0.5923 - val_root_mean_squared_error: 105513.2734\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4186650624.0000 - r2: 0.8218 - root_mean_squared_error: 64704.3320 - val_loss: 12366487552.0000 - val_r2: 0.5449 - val_root_mean_squared_error: 111204.7109\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4099529728.0000 - r2: 0.8256 - root_mean_squared_error: 64027.5703 - val_loss: 8963258368.0000 - val_r2: 0.6710 - val_root_mean_squared_error: 94674.4844\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3989792000.0000 - r2: 0.8304 - root_mean_squared_error: 63164.8008 - val_loss: 8337917952.0000 - val_r2: 0.6938 - val_root_mean_squared_error: 91312.2031\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3912008192.0000 - r2: 0.8336 - root_mean_squared_error: 62546.0469 - val_loss: 11743853568.0000 - val_r2: 0.5695 - val_root_mean_squared_error: 108369.0625\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3840992256.0000 - r2: 0.8362 - root_mean_squared_error: 61975.7383 - val_loss: 10119826432.0000 - val_r2: 0.6285 - val_root_mean_squared_error: 100597.3516\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3786347776.0000 - r2: 0.8390 - root_mean_squared_error: 61533.3047 - val_loss: 11444981760.0000 - val_r2: 0.5813 - val_root_mean_squared_error: 106981.2188\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3750569472.0000 - r2: 0.8401 - root_mean_squared_error: 61241.8945 - val_loss: 10680146944.0000 - val_r2: 0.6082 - val_root_mean_squared_error: 103344.7969\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3717918720.0000 - r2: 0.8420 - root_mean_squared_error: 60974.7383 - val_loss: 10270093312.0000 - val_r2: 0.6228 - val_root_mean_squared_error: 101341.4688\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3693759488.0000 - r2: 0.8429 - root_mean_squared_error: 60776.3086 - val_loss: 9286600704.0000 - val_r2: 0.6596 - val_root_mean_squared_error: 96367.0078\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3694650624.0000 - r2: 0.8432 - root_mean_squared_error: 60783.6367 - val_loss: 9043737600.0000 - val_r2: 0.6682 - val_root_mean_squared_error: 95098.5703\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3687013376.0000 - r2: 0.8432 - root_mean_squared_error: 60720.7812 - val_loss: 10264487936.0000 - val_r2: 0.6228 - val_root_mean_squared_error: 101313.8125\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3682525440.0000 - r2: 0.8432 - root_mean_squared_error: 60683.8164 - val_loss: 11259776000.0000 - val_r2: 0.5870 - val_root_mean_squared_error: 106112.0938\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3669489664.0000 - r2: 0.8441 - root_mean_squared_error: 60576.3125 - val_loss: 10056731648.0000 - val_r2: 0.6313 - val_root_mean_squared_error: 100283.2578\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3663954688.0000 - r2: 0.8439 - root_mean_squared_error: 60530.6094 - val_loss: 8953013248.0000 - val_r2: 0.6708 - val_root_mean_squared_error: 94620.3672\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3676897792.0000 - r2: 0.8434 - root_mean_squared_error: 60637.4297 - val_loss: 9406154752.0000 - val_r2: 0.6553 - val_root_mean_squared_error: 96985.3359\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3672090624.0000 - r2: 0.8436 - root_mean_squared_error: 60597.7773 - val_loss: 11732911104.0000 - val_r2: 0.5693 - val_root_mean_squared_error: 108318.5625\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3657455360.0000 - r2: 0.8444 - root_mean_squared_error: 60476.8984 - val_loss: 9908900864.0000 - val_r2: 0.6368 - val_root_mean_squared_error: 99543.4609\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3659418624.0000 - r2: 0.8446 - root_mean_squared_error: 60493.1289 - val_loss: 8408368640.0000 - val_r2: 0.6911 - val_root_mean_squared_error: 91697.1562\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3655336192.0000 - r2: 0.8446 - root_mean_squared_error: 60459.3750 - val_loss: 9453465600.0000 - val_r2: 0.6530 - val_root_mean_squared_error: 97228.9375\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3656210688.0000 - r2: 0.8444 - root_mean_squared_error: 60466.6094 - val_loss: 11098425344.0000 - val_r2: 0.5927 - val_root_mean_squared_error: 105349.0625\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3656048896.0000 - r2: 0.8445 - root_mean_squared_error: 60465.2695 - val_loss: 10525448192.0000 - val_r2: 0.6128 - val_root_mean_squared_error: 102593.6094\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3651645440.0000 - r2: 0.8448 - root_mean_squared_error: 60428.8477 - val_loss: 9764975616.0000 - val_r2: 0.6412 - val_root_mean_squared_error: 98817.8906\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3643134976.0000 - r2: 0.8450 - root_mean_squared_error: 60358.3867 - val_loss: 10043586560.0000 - val_r2: 0.6318 - val_root_mean_squared_error: 100217.6953\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3648317184.0000 - r2: 0.8446 - root_mean_squared_error: 60401.3008 - val_loss: 11625323520.0000 - val_r2: 0.5722 - val_root_mean_squared_error: 107820.7969\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3658489600.0000 - r2: 0.8444 - root_mean_squared_error: 60485.4492 - val_loss: 10716132352.0000 - val_r2: 0.6072 - val_root_mean_squared_error: 103518.7500\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3668658176.0000 - r2: 0.8440 - root_mean_squared_error: 60569.4492 - val_loss: 11034257408.0000 - val_r2: 0.5941 - val_root_mean_squared_error: 105044.0703\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3634821888.0000 - r2: 0.8454 - root_mean_squared_error: 60289.4844 - val_loss: 9626596352.0000 - val_r2: 0.6472 - val_root_mean_squared_error: 98115.2188\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3634780672.0000 - r2: 0.8453 - root_mean_squared_error: 60289.1406 - val_loss: 8976301056.0000 - val_r2: 0.6711 - val_root_mean_squared_error: 94743.3438\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3633814784.0000 - r2: 0.8452 - root_mean_squared_error: 60281.1328 - val_loss: 10465200128.0000 - val_r2: 0.6162 - val_root_mean_squared_error: 102299.5625\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3640123904.0000 - r2: 0.8449 - root_mean_squared_error: 60333.4375 - val_loss: 8078610432.0000 - val_r2: 0.7033 - val_root_mean_squared_error: 89881.0938\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3634611200.0000 - r2: 0.8454 - root_mean_squared_error: 60287.7383 - val_loss: 11051073536.0000 - val_r2: 0.5945 - val_root_mean_squared_error: 105124.0859\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3633411584.0000 - r2: 0.8457 - root_mean_squared_error: 60277.7852 - val_loss: 9906268160.0000 - val_r2: 0.6371 - val_root_mean_squared_error: 99530.2344\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3628622848.0000 - r2: 0.8455 - root_mean_squared_error: 60238.0508 - val_loss: 9299296256.0000 - val_r2: 0.6582 - val_root_mean_squared_error: 96432.8594\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3634796032.0000 - r2: 0.8453 - root_mean_squared_error: 60289.2695 - val_loss: 10892980224.0000 - val_r2: 0.5993 - val_root_mean_squared_error: 104369.4375\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3621646848.0000 - r2: 0.8461 - root_mean_squared_error: 60180.1211 - val_loss: 9771429888.0000 - val_r2: 0.6411 - val_root_mean_squared_error: 98850.5469\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3620515840.0000 - r2: 0.8456 - root_mean_squared_error: 60170.7227 - val_loss: 10375380992.0000 - val_r2: 0.6192 - val_root_mean_squared_error: 101859.6172\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3622737664.0000 - r2: 0.8456 - root_mean_squared_error: 60189.1836 - val_loss: 9553753088.0000 - val_r2: 0.6502 - val_root_mean_squared_error: 97743.3047\n",
      "session cleared!\n",
      "\n",
      "ix 5 i 0\n",
      "ix 6 i 1\n",
      "updated temp_vec [1, 1, 1, 1, 1, 0, 0, 1, 1]\n",
      "going through feature_mask [1, 1, 1, 1, 1, 0, 0, 1, 1]\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 12), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 17), dtype=tf.float32, name=None), name='flatten_2/Reshape:0', description=\"created by layer 'flatten_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 43), dtype=tf.float32, name=None), name='flatten_1/Reshape:0', description=\"created by layer 'flatten_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization/truediv:0', description=\"created by layer 'normalization'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_1/truediv:0', description=\"created by layer 'normalization_1'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_2/truediv:0', description=\"created by layer 'normalization_2'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_3/truediv:0', description=\"created by layer 'normalization_3'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_4/truediv:0', description=\"created by layer 'normalization_4'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_5/truediv:0', description=\"created by layer 'normalization_5'\")\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 3s 5ms/step - loss: 36010762240.0000 - r2: -0.5417 - root_mean_squared_error: 189765.0156 - val_loss: 14717200384.0000 - val_r2: 0.4614 - val_root_mean_squared_error: 121314.4688\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7813723136.0000 - r2: 0.6690 - root_mean_squared_error: 88395.2656 - val_loss: 13216802816.0000 - val_r2: 0.5158 - val_root_mean_squared_error: 114964.3516\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6996831232.0000 - r2: 0.7030 - root_mean_squared_error: 83647.0625 - val_loss: 12876720128.0000 - val_r2: 0.5292 - val_root_mean_squared_error: 113475.6328\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6061457920.0000 - r2: 0.7431 - root_mean_squared_error: 77855.3672 - val_loss: 12174189568.0000 - val_r2: 0.5549 - val_root_mean_squared_error: 110336.7109\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5169958912.0000 - r2: 0.7805 - root_mean_squared_error: 71902.4297 - val_loss: 11343140864.0000 - val_r2: 0.5840 - val_root_mean_squared_error: 106504.1797\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4536117760.0000 - r2: 0.8078 - root_mean_squared_error: 67350.7109 - val_loss: 10362605568.0000 - val_r2: 0.6202 - val_root_mean_squared_error: 101796.8828\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4196525312.0000 - r2: 0.8215 - root_mean_squared_error: 64780.5938 - val_loss: 10153302016.0000 - val_r2: 0.6287 - val_root_mean_squared_error: 100763.5938\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4056426240.0000 - r2: 0.8276 - root_mean_squared_error: 63690.0781 - val_loss: 10994499584.0000 - val_r2: 0.5973 - val_root_mean_squared_error: 104854.6562\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3981484288.0000 - r2: 0.8307 - root_mean_squared_error: 63099.0039 - val_loss: 8290860032.0000 - val_r2: 0.6964 - val_root_mean_squared_error: 91054.1562\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3958924032.0000 - r2: 0.8318 - root_mean_squared_error: 62919.9805 - val_loss: 10721060864.0000 - val_r2: 0.6073 - val_root_mean_squared_error: 103542.5547\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3911378432.0000 - r2: 0.8336 - root_mean_squared_error: 62541.0156 - val_loss: 8500963328.0000 - val_r2: 0.6880 - val_root_mean_squared_error: 92200.6719\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3896222976.0000 - r2: 0.8342 - root_mean_squared_error: 62419.7305 - val_loss: 10162228224.0000 - val_r2: 0.6271 - val_root_mean_squared_error: 100807.8750\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3879536128.0000 - r2: 0.8351 - root_mean_squared_error: 62285.9219 - val_loss: 8865728512.0000 - val_r2: 0.6746 - val_root_mean_squared_error: 94158.0000\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3866631424.0000 - r2: 0.8356 - root_mean_squared_error: 62182.2422 - val_loss: 11635378176.0000 - val_r2: 0.5731 - val_root_mean_squared_error: 107867.4141\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3859842048.0000 - r2: 0.8360 - root_mean_squared_error: 62127.6289 - val_loss: 9313551360.0000 - val_r2: 0.6592 - val_root_mean_squared_error: 96506.7422\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3739559168.0000 - r2: 0.8411 - root_mean_squared_error: 61151.9336 - val_loss: 9787463680.0000 - val_r2: 0.6403 - val_root_mean_squared_error: 98931.6094\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3610672640.0000 - r2: 0.8465 - root_mean_squared_error: 60088.8711 - val_loss: 9799272448.0000 - val_r2: 0.6406 - val_root_mean_squared_error: 98991.2734\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3472960512.0000 - r2: 0.8522 - root_mean_squared_error: 58931.8281 - val_loss: 9094981632.0000 - val_r2: 0.6660 - val_root_mean_squared_error: 95367.6094\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3293992448.0000 - r2: 0.8600 - root_mean_squared_error: 57393.3125 - val_loss: 9135305728.0000 - val_r2: 0.6653 - val_root_mean_squared_error: 95578.7969\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3149667328.0000 - r2: 0.8660 - root_mean_squared_error: 56121.8984 - val_loss: 9310943232.0000 - val_r2: 0.6583 - val_root_mean_squared_error: 96493.2266\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3060381696.0000 - r2: 0.8698 - root_mean_squared_error: 55320.7148 - val_loss: 9280581632.0000 - val_r2: 0.6592 - val_root_mean_squared_error: 96335.7734\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2994040320.0000 - r2: 0.8728 - root_mean_squared_error: 54717.8242 - val_loss: 10017981440.0000 - val_r2: 0.6335 - val_root_mean_squared_error: 100089.8672\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2965893632.0000 - r2: 0.8738 - root_mean_squared_error: 54460.0195 - val_loss: 8766466048.0000 - val_r2: 0.6788 - val_root_mean_squared_error: 93629.4062\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2942437120.0000 - r2: 0.8744 - root_mean_squared_error: 54244.2344 - val_loss: 9352810496.0000 - val_r2: 0.6566 - val_root_mean_squared_error: 96709.9297\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2913097984.0000 - r2: 0.8759 - root_mean_squared_error: 53973.1211 - val_loss: 9202010112.0000 - val_r2: 0.6616 - val_root_mean_squared_error: 95927.1094\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2893934080.0000 - r2: 0.8768 - root_mean_squared_error: 53795.2969 - val_loss: 8349425152.0000 - val_r2: 0.6940 - val_root_mean_squared_error: 91375.1875\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2879764224.0000 - r2: 0.8773 - root_mean_squared_error: 53663.4336 - val_loss: 8790466560.0000 - val_r2: 0.6767 - val_root_mean_squared_error: 93757.4844\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2873671424.0000 - r2: 0.8776 - root_mean_squared_error: 53606.6367 - val_loss: 10649532416.0000 - val_r2: 0.6089 - val_root_mean_squared_error: 103196.5703\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2880855296.0000 - r2: 0.8775 - root_mean_squared_error: 53673.6016 - val_loss: 8578830336.0000 - val_r2: 0.6852 - val_root_mean_squared_error: 92621.9766\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2869607168.0000 - r2: 0.8778 - root_mean_squared_error: 53568.7148 - val_loss: 9336081408.0000 - val_r2: 0.6570 - val_root_mean_squared_error: 96623.3984\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2856480000.0000 - r2: 0.8785 - root_mean_squared_error: 53446.0469 - val_loss: 8937309184.0000 - val_r2: 0.6723 - val_root_mean_squared_error: 94537.3438\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2864582912.0000 - r2: 0.8780 - root_mean_squared_error: 53521.7969 - val_loss: 9290254336.0000 - val_r2: 0.6584 - val_root_mean_squared_error: 96385.9688\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2856869120.0000 - r2: 0.8783 - root_mean_squared_error: 53449.6875 - val_loss: 9877630976.0000 - val_r2: 0.6369 - val_root_mean_squared_error: 99386.2734\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2847019008.0000 - r2: 0.8788 - root_mean_squared_error: 53357.4648 - val_loss: 9615836160.0000 - val_r2: 0.6475 - val_root_mean_squared_error: 98060.3672\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2855537152.0000 - r2: 0.8785 - root_mean_squared_error: 53437.2266 - val_loss: 8881140736.0000 - val_r2: 0.6741 - val_root_mean_squared_error: 94239.8047\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2859239424.0000 - r2: 0.8783 - root_mean_squared_error: 53471.8555 - val_loss: 8487586304.0000 - val_r2: 0.6879 - val_root_mean_squared_error: 92128.0938\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2848727296.0000 - r2: 0.8785 - root_mean_squared_error: 53373.4688 - val_loss: 9601024000.0000 - val_r2: 0.6479 - val_root_mean_squared_error: 97984.8125\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2856101888.0000 - r2: 0.8784 - root_mean_squared_error: 53442.5117 - val_loss: 9506305024.0000 - val_r2: 0.6512 - val_root_mean_squared_error: 97500.2812\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2842780928.0000 - r2: 0.8791 - root_mean_squared_error: 53317.7344 - val_loss: 10831305728.0000 - val_r2: 0.6015 - val_root_mean_squared_error: 104073.5625\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2845550848.0000 - r2: 0.8788 - root_mean_squared_error: 53343.7031 - val_loss: 8813623296.0000 - val_r2: 0.6764 - val_root_mean_squared_error: 93880.8984\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2835114240.0000 - r2: 0.8793 - root_mean_squared_error: 53245.7891 - val_loss: 10139172864.0000 - val_r2: 0.6277 - val_root_mean_squared_error: 100693.4609\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2849472768.0000 - r2: 0.8790 - root_mean_squared_error: 53380.4531 - val_loss: 8730590208.0000 - val_r2: 0.6790 - val_root_mean_squared_error: 93437.6250\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2845982464.0000 - r2: 0.8791 - root_mean_squared_error: 53347.7500 - val_loss: 10550749184.0000 - val_r2: 0.6125 - val_root_mean_squared_error: 102716.8359\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2843896576.0000 - r2: 0.8789 - root_mean_squared_error: 53328.1953 - val_loss: 9595165696.0000 - val_r2: 0.6482 - val_root_mean_squared_error: 97954.9141\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2832543232.0000 - r2: 0.8795 - root_mean_squared_error: 53221.6406 - val_loss: 9356480512.0000 - val_r2: 0.6560 - val_root_mean_squared_error: 96728.8984\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2828886784.0000 - r2: 0.8798 - root_mean_squared_error: 53187.2812 - val_loss: 9226366976.0000 - val_r2: 0.6613 - val_root_mean_squared_error: 96053.9766\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2844620288.0000 - r2: 0.8788 - root_mean_squared_error: 53334.9805 - val_loss: 9921994752.0000 - val_r2: 0.6355 - val_root_mean_squared_error: 99609.2109\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2845320704.0000 - r2: 0.8789 - root_mean_squared_error: 53341.5469 - val_loss: 11558751232.0000 - val_r2: 0.5759 - val_root_mean_squared_error: 107511.6328\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2840489216.0000 - r2: 0.8792 - root_mean_squared_error: 53296.2383 - val_loss: 9184439296.0000 - val_r2: 0.6629 - val_root_mean_squared_error: 95835.4766\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 2825875200.0000 - r2: 0.8797 - root_mean_squared_error: 53158.9609 - val_loss: 9084151808.0000 - val_r2: 0.6661 - val_root_mean_squared_error: 95310.8203\n",
      "session cleared!\n",
      "\n",
      "ix 7 i 1\n",
      "updated temp_vec [1, 1, 1, 1, 1, 0, 1, 0, 1]\n",
      "going through feature_mask [1, 1, 1, 1, 1, 0, 1, 0, 1]\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 12), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 17), dtype=tf.float32, name=None), name='flatten_2/Reshape:0', description=\"created by layer 'flatten_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 43), dtype=tf.float32, name=None), name='flatten_1/Reshape:0', description=\"created by layer 'flatten_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization/truediv:0', description=\"created by layer 'normalization'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_1/truediv:0', description=\"created by layer 'normalization_1'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_2/truediv:0', description=\"created by layer 'normalization_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_3/truediv:0', description=\"created by layer 'normalization_3'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_4/truediv:0', description=\"created by layer 'normalization_4'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_5/truediv:0', description=\"created by layer 'normalization_5'\")\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 3s 5ms/step - loss: 37486575616.0000 - r2: -0.6005 - root_mean_squared_error: 193614.5000 - val_loss: 14499556352.0000 - val_r2: 0.4699 - val_root_mean_squared_error: 120414.1016\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7969239552.0000 - r2: 0.6625 - root_mean_squared_error: 89270.5938 - val_loss: 14451447808.0000 - val_r2: 0.4712 - val_root_mean_squared_error: 120214.1719\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7315764224.0000 - r2: 0.6899 - root_mean_squared_error: 85532.2422 - val_loss: 13026844672.0000 - val_r2: 0.5233 - val_root_mean_squared_error: 114135.2031\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6627462144.0000 - r2: 0.7185 - root_mean_squared_error: 81409.2266 - val_loss: 11576595456.0000 - val_r2: 0.5761 - val_root_mean_squared_error: 107594.5859\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5977083904.0000 - r2: 0.7465 - root_mean_squared_error: 77311.6016 - val_loss: 12542936064.0000 - val_r2: 0.5408 - val_root_mean_squared_error: 111995.2500\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5487548928.0000 - r2: 0.7670 - root_mean_squared_error: 74077.9922 - val_loss: 11138335744.0000 - val_r2: 0.5919 - val_root_mean_squared_error: 105538.3125\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5066037760.0000 - r2: 0.7846 - root_mean_squared_error: 71176.1016 - val_loss: 10467946496.0000 - val_r2: 0.6169 - val_root_mean_squared_error: 102312.9844\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4742664192.0000 - r2: 0.7987 - root_mean_squared_error: 68867.0000 - val_loss: 9416443904.0000 - val_r2: 0.6550 - val_root_mean_squared_error: 97038.3594\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4506398208.0000 - r2: 0.8081 - root_mean_squared_error: 67129.7109 - val_loss: 11481314304.0000 - val_r2: 0.5793 - val_root_mean_squared_error: 107150.8984\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4340938240.0000 - r2: 0.8155 - root_mean_squared_error: 65885.7969 - val_loss: 11299371008.0000 - val_r2: 0.5861 - val_root_mean_squared_error: 106298.5000\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4218379264.0000 - r2: 0.8206 - root_mean_squared_error: 64949.0508 - val_loss: 9084996608.0000 - val_r2: 0.6673 - val_root_mean_squared_error: 95315.2500\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4119946496.0000 - r2: 0.8246 - root_mean_squared_error: 64186.8086 - val_loss: 9796740096.0000 - val_r2: 0.6414 - val_root_mean_squared_error: 98978.4844\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4021925120.0000 - r2: 0.8294 - root_mean_squared_error: 63418.6484 - val_loss: 10780660736.0000 - val_r2: 0.6046 - val_root_mean_squared_error: 103829.9609\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3961381888.0000 - r2: 0.8313 - root_mean_squared_error: 62939.5078 - val_loss: 9898187776.0000 - val_r2: 0.6366 - val_root_mean_squared_error: 99489.6328\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3888593152.0000 - r2: 0.8348 - root_mean_squared_error: 62358.5859 - val_loss: 9210470400.0000 - val_r2: 0.6628 - val_root_mean_squared_error: 95971.1953\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3833390592.0000 - r2: 0.8368 - root_mean_squared_error: 61914.3828 - val_loss: 8697372672.0000 - val_r2: 0.6807 - val_root_mean_squared_error: 93259.7031\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3783432192.0000 - r2: 0.8388 - root_mean_squared_error: 61509.6094 - val_loss: 9669564416.0000 - val_r2: 0.6449 - val_root_mean_squared_error: 98333.9453\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3758090240.0000 - r2: 0.8403 - root_mean_squared_error: 61303.2656 - val_loss: 12510780416.0000 - val_r2: 0.5403 - val_root_mean_squared_error: 111851.6016\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3714673920.0000 - r2: 0.8421 - root_mean_squared_error: 60948.1250 - val_loss: 9445255168.0000 - val_r2: 0.6540 - val_root_mean_squared_error: 97186.7031\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3698033408.0000 - r2: 0.8426 - root_mean_squared_error: 60811.4570 - val_loss: 9353533440.0000 - val_r2: 0.6567 - val_root_mean_squared_error: 96713.6641\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3691829760.0000 - r2: 0.8431 - root_mean_squared_error: 60760.4297 - val_loss: 11410224128.0000 - val_r2: 0.5819 - val_root_mean_squared_error: 106818.6484\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3671927040.0000 - r2: 0.8437 - root_mean_squared_error: 60596.4258 - val_loss: 11470688256.0000 - val_r2: 0.5779 - val_root_mean_squared_error: 107101.2969\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3661103360.0000 - r2: 0.8442 - root_mean_squared_error: 60507.0508 - val_loss: 8662194176.0000 - val_r2: 0.6822 - val_root_mean_squared_error: 93070.9062\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3659191296.0000 - r2: 0.8441 - root_mean_squared_error: 60491.2500 - val_loss: 8995827712.0000 - val_r2: 0.6698 - val_root_mean_squared_error: 94846.3359\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3661015040.0000 - r2: 0.8443 - root_mean_squared_error: 60506.3242 - val_loss: 8503116800.0000 - val_r2: 0.6879 - val_root_mean_squared_error: 92212.3438\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3669185280.0000 - r2: 0.8440 - root_mean_squared_error: 60573.8008 - val_loss: 9121793024.0000 - val_r2: 0.6652 - val_root_mean_squared_error: 95508.0781\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3637090304.0000 - r2: 0.8453 - root_mean_squared_error: 60308.2930 - val_loss: 7931965440.0000 - val_r2: 0.7089 - val_root_mean_squared_error: 89061.5859\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3660837632.0000 - r2: 0.8442 - root_mean_squared_error: 60504.8555 - val_loss: 9435266048.0000 - val_r2: 0.6538 - val_root_mean_squared_error: 97135.2969\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3637243904.0000 - r2: 0.8452 - root_mean_squared_error: 60309.5664 - val_loss: 11022364672.0000 - val_r2: 0.5962 - val_root_mean_squared_error: 104987.4531\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3646773760.0000 - r2: 0.8451 - root_mean_squared_error: 60388.5234 - val_loss: 11862598656.0000 - val_r2: 0.5648 - val_root_mean_squared_error: 108915.5547\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3640655872.0000 - r2: 0.8449 - root_mean_squared_error: 60337.8477 - val_loss: 8929777664.0000 - val_r2: 0.6724 - val_root_mean_squared_error: 94497.5000\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3639081216.0000 - r2: 0.8450 - root_mean_squared_error: 60324.7969 - val_loss: 8137955328.0000 - val_r2: 0.7017 - val_root_mean_squared_error: 90210.6172\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3649018880.0000 - r2: 0.8448 - root_mean_squared_error: 60407.1094 - val_loss: 11097302016.0000 - val_r2: 0.5925 - val_root_mean_squared_error: 105343.7344\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3646502656.0000 - r2: 0.8444 - root_mean_squared_error: 60386.2773 - val_loss: 9756366848.0000 - val_r2: 0.6419 - val_root_mean_squared_error: 98774.3203\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3634904832.0000 - r2: 0.8454 - root_mean_squared_error: 60290.1719 - val_loss: 8965774336.0000 - val_r2: 0.6718 - val_root_mean_squared_error: 94687.7734\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3631492864.0000 - r2: 0.8455 - root_mean_squared_error: 60261.8672 - val_loss: 9406251008.0000 - val_r2: 0.6548 - val_root_mean_squared_error: 96985.8281\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3636918784.0000 - r2: 0.8451 - root_mean_squared_error: 60306.8711 - val_loss: 9937474560.0000 - val_r2: 0.6356 - val_root_mean_squared_error: 99686.8828\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3630616320.0000 - r2: 0.8454 - root_mean_squared_error: 60254.5977 - val_loss: 11905362944.0000 - val_r2: 0.5627 - val_root_mean_squared_error: 109111.7031\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3633618432.0000 - r2: 0.8455 - root_mean_squared_error: 60279.5039 - val_loss: 9887808512.0000 - val_r2: 0.6373 - val_root_mean_squared_error: 99437.4609\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3641656064.0000 - r2: 0.8451 - root_mean_squared_error: 60346.1367 - val_loss: 11504769024.0000 - val_r2: 0.5777 - val_root_mean_squared_error: 107260.2891\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3628843776.0000 - r2: 0.8457 - root_mean_squared_error: 60239.8867 - val_loss: 10354780160.0000 - val_r2: 0.6200 - val_root_mean_squared_error: 101758.4375\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3634746880.0000 - r2: 0.8452 - root_mean_squared_error: 60288.8633 - val_loss: 9778186240.0000 - val_r2: 0.6410 - val_root_mean_squared_error: 98884.7109\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3630492672.0000 - r2: 0.8456 - root_mean_squared_error: 60253.5703 - val_loss: 9844509696.0000 - val_r2: 0.6380 - val_root_mean_squared_error: 99219.5000\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3623023360.0000 - r2: 0.8457 - root_mean_squared_error: 60191.5547 - val_loss: 10134656000.0000 - val_r2: 0.6284 - val_root_mean_squared_error: 100671.0312\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3623113728.0000 - r2: 0.8454 - root_mean_squared_error: 60192.3047 - val_loss: 9292472320.0000 - val_r2: 0.6582 - val_root_mean_squared_error: 96397.4688\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3629577472.0000 - r2: 0.8458 - root_mean_squared_error: 60245.9766 - val_loss: 9910823936.0000 - val_r2: 0.6361 - val_root_mean_squared_error: 99553.1250\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3629903616.0000 - r2: 0.8453 - root_mean_squared_error: 60248.6797 - val_loss: 9508986880.0000 - val_r2: 0.6508 - val_root_mean_squared_error: 97514.0312\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3625574656.0000 - r2: 0.8457 - root_mean_squared_error: 60212.7461 - val_loss: 10062189568.0000 - val_r2: 0.6307 - val_root_mean_squared_error: 100310.4688\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3624681984.0000 - r2: 0.8458 - root_mean_squared_error: 60205.3320 - val_loss: 10909597696.0000 - val_r2: 0.5998 - val_root_mean_squared_error: 104449.0234\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3621114624.0000 - r2: 0.8459 - root_mean_squared_error: 60175.6992 - val_loss: 10189796352.0000 - val_r2: 0.6260 - val_root_mean_squared_error: 100944.5234\n",
      "session cleared!\n",
      "\n",
      "ix 8 i 1\n",
      "updated temp_vec [1, 1, 1, 1, 1, 0, 1, 1, 0]\n",
      "going through feature_mask [1, 1, 1, 1, 1, 0, 1, 1, 0]\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 12), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 17), dtype=tf.float32, name=None), name='flatten_2/Reshape:0', description=\"created by layer 'flatten_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 43), dtype=tf.float32, name=None), name='flatten_1/Reshape:0', description=\"created by layer 'flatten_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization/truediv:0', description=\"created by layer 'normalization'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_1/truediv:0', description=\"created by layer 'normalization_1'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_2/truediv:0', description=\"created by layer 'normalization_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_3/truediv:0', description=\"created by layer 'normalization_3'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_4/truediv:0', description=\"created by layer 'normalization_4'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_5/truediv:0', description=\"created by layer 'normalization_5'\")\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 3s 5ms/step - loss: 39878258688.0000 - r2: -0.7209 - root_mean_squared_error: 199695.4219 - val_loss: 14632784896.0000 - val_r2: 0.4658 - val_root_mean_squared_error: 120966.0469\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 8397159936.0000 - r2: 0.6436 - root_mean_squared_error: 91636.0156 - val_loss: 13949112320.0000 - val_r2: 0.4901 - val_root_mean_squared_error: 118106.3594\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 8034791936.0000 - r2: 0.6591 - root_mean_squared_error: 89637.0000 - val_loss: 12883118080.0000 - val_r2: 0.5293 - val_root_mean_squared_error: 113503.8203\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7716236800.0000 - r2: 0.6726 - root_mean_squared_error: 87842.1094 - val_loss: 14032462848.0000 - val_r2: 0.4871 - val_root_mean_squared_error: 118458.6953\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7409026048.0000 - r2: 0.6859 - root_mean_squared_error: 86075.7031 - val_loss: 12144883712.0000 - val_r2: 0.5562 - val_root_mean_squared_error: 110203.8281\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7178107392.0000 - r2: 0.6955 - root_mean_squared_error: 84723.7109 - val_loss: 14121162752.0000 - val_r2: 0.4822 - val_root_mean_squared_error: 118832.5000\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7028230656.0000 - r2: 0.7018 - root_mean_squared_error: 83834.5469 - val_loss: 13148019712.0000 - val_r2: 0.5185 - val_root_mean_squared_error: 114664.8125\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6949989888.0000 - r2: 0.7048 - root_mean_squared_error: 83366.6016 - val_loss: 13608610816.0000 - val_r2: 0.5013 - val_root_mean_squared_error: 116655.9531\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6912796160.0000 - r2: 0.7062 - root_mean_squared_error: 83143.2266 - val_loss: 13745543168.0000 - val_r2: 0.4972 - val_root_mean_squared_error: 117241.3906\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6899064832.0000 - r2: 0.7064 - root_mean_squared_error: 83060.6094 - val_loss: 12714076160.0000 - val_r2: 0.5343 - val_root_mean_squared_error: 112756.7109\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6878046208.0000 - r2: 0.7081 - root_mean_squared_error: 82933.9844 - val_loss: 12589786112.0000 - val_r2: 0.5394 - val_root_mean_squared_error: 112204.2188\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6866644480.0000 - r2: 0.7087 - root_mean_squared_error: 82865.2188 - val_loss: 13926660096.0000 - val_r2: 0.4900 - val_root_mean_squared_error: 118011.2734\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6847120384.0000 - r2: 0.7093 - root_mean_squared_error: 82747.3281 - val_loss: 14248819712.0000 - val_r2: 0.4783 - val_root_mean_squared_error: 119368.4219\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6848235008.0000 - r2: 0.7093 - root_mean_squared_error: 82754.0625 - val_loss: 12566562816.0000 - val_r2: 0.5399 - val_root_mean_squared_error: 112100.6797\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6826832384.0000 - r2: 0.7101 - root_mean_squared_error: 82624.6484 - val_loss: 12595629056.0000 - val_r2: 0.5394 - val_root_mean_squared_error: 112230.2500\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6820494336.0000 - r2: 0.7103 - root_mean_squared_error: 82586.2812 - val_loss: 13168570368.0000 - val_r2: 0.5184 - val_root_mean_squared_error: 114754.3906\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6795781632.0000 - r2: 0.7116 - root_mean_squared_error: 82436.5312 - val_loss: 13055875072.0000 - val_r2: 0.5221 - val_root_mean_squared_error: 114262.3047\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6791591424.0000 - r2: 0.7115 - root_mean_squared_error: 82411.1094 - val_loss: 14105702400.0000 - val_r2: 0.4848 - val_root_mean_squared_error: 118767.4297\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6773302784.0000 - r2: 0.7124 - root_mean_squared_error: 82300.0781 - val_loss: 13852109824.0000 - val_r2: 0.4918 - val_root_mean_squared_error: 117694.9844\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6762170880.0000 - r2: 0.7128 - root_mean_squared_error: 82232.4219 - val_loss: 14405695488.0000 - val_r2: 0.4734 - val_root_mean_squared_error: 120023.7266\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6760581120.0000 - r2: 0.7129 - root_mean_squared_error: 82222.7500 - val_loss: 12954491904.0000 - val_r2: 0.5265 - val_root_mean_squared_error: 113817.8047\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6755661824.0000 - r2: 0.7131 - root_mean_squared_error: 82192.8359 - val_loss: 13991664640.0000 - val_r2: 0.4877 - val_root_mean_squared_error: 118286.3672\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6759855104.0000 - r2: 0.7133 - root_mean_squared_error: 82218.3359 - val_loss: 14116859904.0000 - val_r2: 0.4836 - val_root_mean_squared_error: 118814.3906\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6727947264.0000 - r2: 0.7149 - root_mean_squared_error: 82024.0625 - val_loss: 14122185728.0000 - val_r2: 0.4830 - val_root_mean_squared_error: 118836.8047\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6722469888.0000 - r2: 0.7142 - root_mean_squared_error: 81990.6719 - val_loss: 12280615936.0000 - val_r2: 0.5505 - val_root_mean_squared_error: 110817.9375\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6724070912.0000 - r2: 0.7144 - root_mean_squared_error: 82000.4297 - val_loss: 11682236416.0000 - val_r2: 0.5722 - val_root_mean_squared_error: 108084.3984\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6733787136.0000 - r2: 0.7144 - root_mean_squared_error: 82059.6562 - val_loss: 13539111936.0000 - val_r2: 0.5040 - val_root_mean_squared_error: 116357.6875\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6715471872.0000 - r2: 0.7152 - root_mean_squared_error: 81947.9844 - val_loss: 13129777152.0000 - val_r2: 0.5192 - val_root_mean_squared_error: 114585.2422\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6706181120.0000 - r2: 0.7151 - root_mean_squared_error: 81891.2734 - val_loss: 13272314880.0000 - val_r2: 0.5137 - val_root_mean_squared_error: 115205.5312\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6700383232.0000 - r2: 0.7154 - root_mean_squared_error: 81855.8672 - val_loss: 12204145664.0000 - val_r2: 0.5530 - val_root_mean_squared_error: 110472.3750\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6705482752.0000 - r2: 0.7155 - root_mean_squared_error: 81887.0156 - val_loss: 12743992320.0000 - val_r2: 0.5340 - val_root_mean_squared_error: 112889.2891\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6696114176.0000 - r2: 0.7153 - root_mean_squared_error: 81829.7891 - val_loss: 14215133184.0000 - val_r2: 0.4792 - val_root_mean_squared_error: 119227.2344\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6707262464.0000 - r2: 0.7149 - root_mean_squared_error: 81897.8750 - val_loss: 13405968384.0000 - val_r2: 0.5080 - val_root_mean_squared_error: 115784.1484\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6701709312.0000 - r2: 0.7153 - root_mean_squared_error: 81863.9688 - val_loss: 13135975424.0000 - val_r2: 0.5191 - val_root_mean_squared_error: 114612.2812\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6699433984.0000 - r2: 0.7155 - root_mean_squared_error: 81850.0703 - val_loss: 12232252416.0000 - val_r2: 0.5523 - val_root_mean_squared_error: 110599.5156\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6702454272.0000 - r2: 0.7152 - root_mean_squared_error: 81868.5156 - val_loss: 14207311872.0000 - val_r2: 0.4792 - val_root_mean_squared_error: 119194.4297\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6687456256.0000 - r2: 0.7165 - root_mean_squared_error: 81776.8672 - val_loss: 13423552512.0000 - val_r2: 0.5078 - val_root_mean_squared_error: 115860.0547\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6691080704.0000 - r2: 0.7156 - root_mean_squared_error: 81799.0234 - val_loss: 11520155648.0000 - val_r2: 0.5784 - val_root_mean_squared_error: 107331.9844\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6693340160.0000 - r2: 0.7155 - root_mean_squared_error: 81812.8359 - val_loss: 16269534208.0000 - val_r2: 0.4039 - val_root_mean_squared_error: 127552.0859\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6686550528.0000 - r2: 0.7159 - root_mean_squared_error: 81771.3281 - val_loss: 13106856960.0000 - val_r2: 0.5202 - val_root_mean_squared_error: 114485.1797\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6673175040.0000 - r2: 0.7169 - root_mean_squared_error: 81689.5000 - val_loss: 12425029632.0000 - val_r2: 0.5453 - val_root_mean_squared_error: 111467.6172\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6692667904.0000 - r2: 0.7157 - root_mean_squared_error: 81808.7266 - val_loss: 13038098432.0000 - val_r2: 0.5228 - val_root_mean_squared_error: 114184.4922\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6684374528.0000 - r2: 0.7164 - root_mean_squared_error: 81758.0234 - val_loss: 12126406656.0000 - val_r2: 0.5559 - val_root_mean_squared_error: 110119.9609\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6683424768.0000 - r2: 0.7164 - root_mean_squared_error: 81752.2188 - val_loss: 13090529280.0000 - val_r2: 0.5202 - val_root_mean_squared_error: 114413.8516\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6679090688.0000 - r2: 0.7167 - root_mean_squared_error: 81725.7031 - val_loss: 13059448832.0000 - val_r2: 0.5223 - val_root_mean_squared_error: 114277.9453\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6698503680.0000 - r2: 0.7157 - root_mean_squared_error: 81844.3906 - val_loss: 12596365312.0000 - val_r2: 0.5388 - val_root_mean_squared_error: 112233.5312\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6672952832.0000 - r2: 0.7166 - root_mean_squared_error: 81688.1406 - val_loss: 13483142144.0000 - val_r2: 0.5066 - val_root_mean_squared_error: 116116.9297\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6679108608.0000 - r2: 0.7161 - root_mean_squared_error: 81725.8125 - val_loss: 14135614464.0000 - val_r2: 0.4826 - val_root_mean_squared_error: 118893.2891\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6683461632.0000 - r2: 0.7167 - root_mean_squared_error: 81752.4375 - val_loss: 13087270912.0000 - val_r2: 0.5212 - val_root_mean_squared_error: 114399.6094\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6692942848.0000 - r2: 0.7159 - root_mean_squared_error: 81810.4062 - val_loss: 13455244288.0000 - val_r2: 0.5076 - val_root_mean_squared_error: 115996.7422\n",
      "session cleared!\n",
      "\n",
      "2162.980932712555 seconds elapsed\n",
      "\n",
      "vec [1, 1, 1, 0, 1, 0, 1, 1, 1]\n",
      "ix 0 i 1\n",
      "updated temp_vec [0, 1, 1, 0, 1, 0, 1, 1, 1]\n",
      "going through feature_mask [0, 1, 1, 0, 1, 0, 1, 1, 1]\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 12), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 17), dtype=tf.float32, name=None), name='flatten_2/Reshape:0', description=\"created by layer 'flatten_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 43), dtype=tf.float32, name=None), name='flatten_1/Reshape:0', description=\"created by layer 'flatten_1'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization/truediv:0', description=\"created by layer 'normalization'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_1/truediv:0', description=\"created by layer 'normalization_1'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_2/truediv:0', description=\"created by layer 'normalization_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_3/truediv:0', description=\"created by layer 'normalization_3'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_4/truediv:0', description=\"created by layer 'normalization_4'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_5/truediv:0', description=\"created by layer 'normalization_5'\")\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 3s 5ms/step - loss: 37923950592.0000 - r2: -0.6118 - root_mean_squared_error: 194740.7344 - val_loss: 14478670848.0000 - val_r2: 0.4711 - val_root_mean_squared_error: 120327.3516\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7537909248.0000 - r2: 0.6805 - root_mean_squared_error: 86821.1328 - val_loss: 12667966464.0000 - val_r2: 0.5365 - val_root_mean_squared_error: 112552.0625\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6641052160.0000 - r2: 0.7182 - root_mean_squared_error: 81492.6484 - val_loss: 12427852800.0000 - val_r2: 0.5455 - val_root_mean_squared_error: 111480.2812\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5811041792.0000 - r2: 0.7536 - root_mean_squared_error: 76230.1875 - val_loss: 12499830784.0000 - val_r2: 0.5423 - val_root_mean_squared_error: 111802.6406\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5207493632.0000 - r2: 0.7788 - root_mean_squared_error: 72162.9688 - val_loss: 11475651584.0000 - val_r2: 0.5801 - val_root_mean_squared_error: 107124.4688\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4828333056.0000 - r2: 0.7949 - root_mean_squared_error: 69486.2109 - val_loss: 10831969280.0000 - val_r2: 0.6035 - val_root_mean_squared_error: 104076.7500\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4577516032.0000 - r2: 0.8057 - root_mean_squared_error: 67657.3438 - val_loss: 10055694336.0000 - val_r2: 0.6310 - val_root_mean_squared_error: 100278.0859\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4382647808.0000 - r2: 0.8140 - root_mean_squared_error: 66201.5703 - val_loss: 10394233856.0000 - val_r2: 0.6188 - val_root_mean_squared_error: 101952.1172\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4284198656.0000 - r2: 0.8182 - root_mean_squared_error: 65453.7891 - val_loss: 10715967488.0000 - val_r2: 0.6077 - val_root_mean_squared_error: 103517.9609\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4219365888.0000 - r2: 0.8207 - root_mean_squared_error: 64956.6445 - val_loss: 11434413056.0000 - val_r2: 0.5815 - val_root_mean_squared_error: 106931.8125\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4198255104.0000 - r2: 0.8215 - root_mean_squared_error: 64793.9453 - val_loss: 12269838336.0000 - val_r2: 0.5504 - val_root_mean_squared_error: 110769.3047\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4204672256.0000 - r2: 0.8212 - root_mean_squared_error: 64843.4453 - val_loss: 9907259392.0000 - val_r2: 0.6373 - val_root_mean_squared_error: 99535.2188\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4204602368.0000 - r2: 0.8212 - root_mean_squared_error: 64842.9062 - val_loss: 10922997760.0000 - val_r2: 0.6003 - val_root_mean_squared_error: 104513.1484\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4194158848.0000 - r2: 0.8217 - root_mean_squared_error: 64762.3242 - val_loss: 9766974464.0000 - val_r2: 0.6420 - val_root_mean_squared_error: 98828.0078\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4197236224.0000 - r2: 0.8220 - root_mean_squared_error: 64786.0820 - val_loss: 9572264960.0000 - val_r2: 0.6488 - val_root_mean_squared_error: 97837.9531\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4203490560.0000 - r2: 0.8215 - root_mean_squared_error: 64834.3320 - val_loss: 10309139456.0000 - val_r2: 0.6223 - val_root_mean_squared_error: 101533.9297\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4196094464.0000 - r2: 0.8216 - root_mean_squared_error: 64777.2695 - val_loss: 10409964544.0000 - val_r2: 0.6191 - val_root_mean_squared_error: 102029.2344\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4196899072.0000 - r2: 0.8215 - root_mean_squared_error: 64783.4766 - val_loss: 8673740800.0000 - val_r2: 0.6821 - val_root_mean_squared_error: 93132.9219\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4188360448.0000 - r2: 0.8219 - root_mean_squared_error: 64717.5430 - val_loss: 9935226880.0000 - val_r2: 0.6359 - val_root_mean_squared_error: 99675.6094\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4188676864.0000 - r2: 0.8223 - root_mean_squared_error: 64719.9883 - val_loss: 10418250752.0000 - val_r2: 0.6187 - val_root_mean_squared_error: 102069.8359\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4196314112.0000 - r2: 0.8215 - root_mean_squared_error: 64778.9648 - val_loss: 8701533184.0000 - val_r2: 0.6810 - val_root_mean_squared_error: 93282.0078\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4194098944.0000 - r2: 0.8218 - root_mean_squared_error: 64761.8633 - val_loss: 10284419072.0000 - val_r2: 0.6242 - val_root_mean_squared_error: 101412.1250\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4191058688.0000 - r2: 0.8217 - root_mean_squared_error: 64738.3867 - val_loss: 12170214400.0000 - val_r2: 0.5540 - val_root_mean_squared_error: 110318.6953\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4185700864.0000 - r2: 0.8221 - root_mean_squared_error: 64696.9922 - val_loss: 10189815808.0000 - val_r2: 0.6267 - val_root_mean_squared_error: 100944.6172\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4193393920.0000 - r2: 0.8217 - root_mean_squared_error: 64756.4180 - val_loss: 10813764608.0000 - val_r2: 0.6041 - val_root_mean_squared_error: 103989.2500\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4181440256.0000 - r2: 0.8220 - root_mean_squared_error: 64664.0586 - val_loss: 10625551360.0000 - val_r2: 0.6111 - val_root_mean_squared_error: 103080.3125\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4183627776.0000 - r2: 0.8221 - root_mean_squared_error: 64680.9688 - val_loss: 10509075456.0000 - val_r2: 0.6157 - val_root_mean_squared_error: 102513.7812\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4196496640.0000 - r2: 0.8212 - root_mean_squared_error: 64780.3711 - val_loss: 9839032320.0000 - val_r2: 0.6385 - val_root_mean_squared_error: 99191.8984\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4194041344.0000 - r2: 0.8219 - root_mean_squared_error: 64761.4180 - val_loss: 10541356032.0000 - val_r2: 0.6136 - val_root_mean_squared_error: 102671.1094\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4186136832.0000 - r2: 0.8220 - root_mean_squared_error: 64700.3633 - val_loss: 11696209920.0000 - val_r2: 0.5706 - val_root_mean_squared_error: 108149.0156\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4182127616.0000 - r2: 0.8223 - root_mean_squared_error: 64669.3711 - val_loss: 10055631872.0000 - val_r2: 0.6309 - val_root_mean_squared_error: 100277.7734\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4195297536.0000 - r2: 0.8220 - root_mean_squared_error: 64771.1172 - val_loss: 9585042432.0000 - val_r2: 0.6487 - val_root_mean_squared_error: 97903.2266\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4186539008.0000 - r2: 0.8223 - root_mean_squared_error: 64703.4688 - val_loss: 11785833472.0000 - val_r2: 0.5685 - val_root_mean_squared_error: 108562.5781\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4187115008.0000 - r2: 0.8220 - root_mean_squared_error: 64707.9219 - val_loss: 9881483264.0000 - val_r2: 0.6381 - val_root_mean_squared_error: 99405.6484\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4185011200.0000 - r2: 0.8224 - root_mean_squared_error: 64691.6641 - val_loss: 9553956864.0000 - val_r2: 0.6493 - val_root_mean_squared_error: 97744.3438\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4180125952.0000 - r2: 0.8224 - root_mean_squared_error: 64653.8945 - val_loss: 10239616000.0000 - val_r2: 0.6248 - val_root_mean_squared_error: 101190.9844\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4197091072.0000 - r2: 0.8221 - root_mean_squared_error: 64784.9609 - val_loss: 10631149568.0000 - val_r2: 0.6105 - val_root_mean_squared_error: 103107.4688\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4178832128.0000 - r2: 0.8225 - root_mean_squared_error: 64643.8867 - val_loss: 9080313856.0000 - val_r2: 0.6673 - val_root_mean_squared_error: 95290.6797\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4184771584.0000 - r2: 0.8224 - root_mean_squared_error: 64689.8086 - val_loss: 10097382400.0000 - val_r2: 0.6303 - val_root_mean_squared_error: 100485.7344\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4183925504.0000 - r2: 0.8223 - root_mean_squared_error: 64683.2695 - val_loss: 11640282112.0000 - val_r2: 0.5729 - val_root_mean_squared_error: 107890.1406\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4181230080.0000 - r2: 0.8224 - root_mean_squared_error: 64662.4336 - val_loss: 11789097984.0000 - val_r2: 0.5670 - val_root_mean_squared_error: 108577.6094\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4187173376.0000 - r2: 0.8220 - root_mean_squared_error: 64708.3711 - val_loss: 9981382656.0000 - val_r2: 0.6342 - val_root_mean_squared_error: 99906.8672\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4176177152.0000 - r2: 0.8228 - root_mean_squared_error: 64623.3477 - val_loss: 8903311360.0000 - val_r2: 0.6731 - val_root_mean_squared_error: 94357.3594\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4178153472.0000 - r2: 0.8227 - root_mean_squared_error: 64638.6367 - val_loss: 10575571968.0000 - val_r2: 0.6129 - val_root_mean_squared_error: 102837.6016\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4197303040.0000 - r2: 0.8215 - root_mean_squared_error: 64786.5977 - val_loss: 9607943168.0000 - val_r2: 0.6483 - val_root_mean_squared_error: 98020.1172\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4185720832.0000 - r2: 0.8221 - root_mean_squared_error: 64697.1484 - val_loss: 8918615040.0000 - val_r2: 0.6736 - val_root_mean_squared_error: 94438.4219\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4181532928.0000 - r2: 0.8223 - root_mean_squared_error: 64664.7734 - val_loss: 9779257344.0000 - val_r2: 0.6424 - val_root_mean_squared_error: 98890.1250\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4172930816.0000 - r2: 0.8225 - root_mean_squared_error: 64598.2266 - val_loss: 9256770560.0000 - val_r2: 0.6608 - val_root_mean_squared_error: 96212.1094\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4181514752.0000 - r2: 0.8223 - root_mean_squared_error: 64664.6328 - val_loss: 11049448448.0000 - val_r2: 0.5950 - val_root_mean_squared_error: 105116.3594\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4180943616.0000 - r2: 0.8222 - root_mean_squared_error: 64660.2148 - val_loss: 12001681408.0000 - val_r2: 0.5599 - val_root_mean_squared_error: 109552.1875\n",
      "session cleared!\n",
      "\n",
      "ix 1 i 1\n",
      "updated temp_vec [1, 0, 1, 0, 1, 0, 1, 1, 1]\n",
      "going through feature_mask [1, 0, 1, 0, 1, 0, 1, 1, 1]\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 12), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 17), dtype=tf.float32, name=None), name='flatten_2/Reshape:0', description=\"created by layer 'flatten_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 43), dtype=tf.float32, name=None), name='flatten_1/Reshape:0', description=\"created by layer 'flatten_1'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization/truediv:0', description=\"created by layer 'normalization'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_1/truediv:0', description=\"created by layer 'normalization_1'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_2/truediv:0', description=\"created by layer 'normalization_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_3/truediv:0', description=\"created by layer 'normalization_3'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_4/truediv:0', description=\"created by layer 'normalization_4'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_5/truediv:0', description=\"created by layer 'normalization_5'\")\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 3s 5ms/step - loss: 39905492992.0000 - r2: -0.6589 - root_mean_squared_error: 199763.5938 - val_loss: 16880791552.0000 - val_r2: 0.3844 - val_root_mean_squared_error: 129926.1016\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 9159948288.0000 - r2: 0.6126 - root_mean_squared_error: 95707.6172 - val_loss: 15769012224.0000 - val_r2: 0.4243 - val_root_mean_squared_error: 125574.7266\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7972505600.0000 - r2: 0.6627 - root_mean_squared_error: 89288.8906 - val_loss: 13180702720.0000 - val_r2: 0.5190 - val_root_mean_squared_error: 114807.2422\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6817610752.0000 - r2: 0.7115 - root_mean_squared_error: 82568.8281 - val_loss: 12655694848.0000 - val_r2: 0.5376 - val_root_mean_squared_error: 112497.5312\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5989571584.0000 - r2: 0.7462 - root_mean_squared_error: 77392.3203 - val_loss: 12614491136.0000 - val_r2: 0.5383 - val_root_mean_squared_error: 112314.2500\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5515327488.0000 - r2: 0.7657 - root_mean_squared_error: 74265.2500 - val_loss: 11849535488.0000 - val_r2: 0.5662 - val_root_mean_squared_error: 108855.5703\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5209009152.0000 - r2: 0.7789 - root_mean_squared_error: 72173.4688 - val_loss: 13051197440.0000 - val_r2: 0.5228 - val_root_mean_squared_error: 114241.8359\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5005206528.0000 - r2: 0.7880 - root_mean_squared_error: 70747.4844 - val_loss: 11493211136.0000 - val_r2: 0.5793 - val_root_mean_squared_error: 107206.3984\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4901872128.0000 - r2: 0.7918 - root_mean_squared_error: 70013.3672 - val_loss: 10576229376.0000 - val_r2: 0.6129 - val_root_mean_squared_error: 102840.7969\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4834280960.0000 - r2: 0.7949 - root_mean_squared_error: 69528.9922 - val_loss: 10335271936.0000 - val_r2: 0.6221 - val_root_mean_squared_error: 101662.5391\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4819252736.0000 - r2: 0.7955 - root_mean_squared_error: 69420.8359 - val_loss: 12964903936.0000 - val_r2: 0.5252 - val_root_mean_squared_error: 113863.5312\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4798341632.0000 - r2: 0.7962 - root_mean_squared_error: 69270.0625 - val_loss: 10346457088.0000 - val_r2: 0.6209 - val_root_mean_squared_error: 101717.5391\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4787416064.0000 - r2: 0.7969 - root_mean_squared_error: 69191.1562 - val_loss: 12594247680.0000 - val_r2: 0.5393 - val_root_mean_squared_error: 112224.0938\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4794754560.0000 - r2: 0.7963 - root_mean_squared_error: 69244.1641 - val_loss: 11561724928.0000 - val_r2: 0.5773 - val_root_mean_squared_error: 107525.4609\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4799074816.0000 - r2: 0.7960 - root_mean_squared_error: 69275.3516 - val_loss: 12818552832.0000 - val_r2: 0.5304 - val_root_mean_squared_error: 113219.0469\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4803040768.0000 - r2: 0.7964 - root_mean_squared_error: 69303.9766 - val_loss: 12475776000.0000 - val_r2: 0.5434 - val_root_mean_squared_error: 111695.0156\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4792970752.0000 - r2: 0.7965 - root_mean_squared_error: 69231.2812 - val_loss: 9949881344.0000 - val_r2: 0.6361 - val_root_mean_squared_error: 99749.0938\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4781049344.0000 - r2: 0.7968 - root_mean_squared_error: 69145.1328 - val_loss: 11695732736.0000 - val_r2: 0.5715 - val_root_mean_squared_error: 108146.8125\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4785457152.0000 - r2: 0.7970 - root_mean_squared_error: 69177.0000 - val_loss: 13033259008.0000 - val_r2: 0.5231 - val_root_mean_squared_error: 114163.2969\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4795817472.0000 - r2: 0.7960 - root_mean_squared_error: 69251.8438 - val_loss: 11516878848.0000 - val_r2: 0.5783 - val_root_mean_squared_error: 107316.7188\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4812805120.0000 - r2: 0.7954 - root_mean_squared_error: 69374.3828 - val_loss: 12789113856.0000 - val_r2: 0.5316 - val_root_mean_squared_error: 113088.9609\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4790563840.0000 - r2: 0.7964 - root_mean_squared_error: 69213.8984 - val_loss: 12932158464.0000 - val_r2: 0.5269 - val_root_mean_squared_error: 113719.6484\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4799633920.0000 - r2: 0.7963 - root_mean_squared_error: 69279.3906 - val_loss: 11781846016.0000 - val_r2: 0.5689 - val_root_mean_squared_error: 108544.2109\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4791870464.0000 - r2: 0.7968 - root_mean_squared_error: 69223.3359 - val_loss: 11888723968.0000 - val_r2: 0.5652 - val_root_mean_squared_error: 109035.4219\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4782037504.0000 - r2: 0.7969 - root_mean_squared_error: 69152.2812 - val_loss: 12880030720.0000 - val_r2: 0.5291 - val_root_mean_squared_error: 113490.2266\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4783438336.0000 - r2: 0.7969 - root_mean_squared_error: 69162.4062 - val_loss: 10995037184.0000 - val_r2: 0.5972 - val_root_mean_squared_error: 104857.2266\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4782440448.0000 - r2: 0.7970 - root_mean_squared_error: 69155.1875 - val_loss: 11110886400.0000 - val_r2: 0.5938 - val_root_mean_squared_error: 105408.1875\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4793623552.0000 - r2: 0.7966 - root_mean_squared_error: 69236.0000 - val_loss: 11384865792.0000 - val_r2: 0.5836 - val_root_mean_squared_error: 106699.8828\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4782069248.0000 - r2: 0.7967 - root_mean_squared_error: 69152.5078 - val_loss: 12110642176.0000 - val_r2: 0.5562 - val_root_mean_squared_error: 110048.3594\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4784280576.0000 - r2: 0.7965 - root_mean_squared_error: 69168.4922 - val_loss: 12683784192.0000 - val_r2: 0.5355 - val_root_mean_squared_error: 112622.3047\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4788334080.0000 - r2: 0.7967 - root_mean_squared_error: 69197.7891 - val_loss: 9781756928.0000 - val_r2: 0.6424 - val_root_mean_squared_error: 98902.7656\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4785225216.0000 - r2: 0.7968 - root_mean_squared_error: 69175.3203 - val_loss: 12311943168.0000 - val_r2: 0.5498 - val_root_mean_squared_error: 110959.1953\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4778911744.0000 - r2: 0.7972 - root_mean_squared_error: 69129.6719 - val_loss: 10871335936.0000 - val_r2: 0.6017 - val_root_mean_squared_error: 104265.6953\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4777017856.0000 - r2: 0.7973 - root_mean_squared_error: 69115.9766 - val_loss: 12289617920.0000 - val_r2: 0.5499 - val_root_mean_squared_error: 110858.5469\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4737356288.0000 - r2: 0.7993 - root_mean_squared_error: 68828.4531 - val_loss: 10833533952.0000 - val_r2: 0.6034 - val_root_mean_squared_error: 104084.2656\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4407123968.0000 - r2: 0.8131 - root_mean_squared_error: 66386.1719 - val_loss: 11215970304.0000 - val_r2: 0.5885 - val_root_mean_squared_error: 105905.4766\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4041549824.0000 - r2: 0.8284 - root_mean_squared_error: 63573.1836 - val_loss: 10963403776.0000 - val_r2: 0.5984 - val_root_mean_squared_error: 104706.2734\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3909955328.0000 - r2: 0.8341 - root_mean_squared_error: 62529.6367 - val_loss: 10223458304.0000 - val_r2: 0.6256 - val_root_mean_squared_error: 101111.1172\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3841911808.0000 - r2: 0.8369 - root_mean_squared_error: 61983.1562 - val_loss: 10115681280.0000 - val_r2: 0.6291 - val_root_mean_squared_error: 100576.7422\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3798791424.0000 - r2: 0.8384 - root_mean_squared_error: 61634.3359 - val_loss: 10401507328.0000 - val_r2: 0.6188 - val_root_mean_squared_error: 101987.7812\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3741597696.0000 - r2: 0.8411 - root_mean_squared_error: 61168.6016 - val_loss: 9958910976.0000 - val_r2: 0.6343 - val_root_mean_squared_error: 99794.3438\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3720782592.0000 - r2: 0.8420 - root_mean_squared_error: 60998.2188 - val_loss: 11221607424.0000 - val_r2: 0.5882 - val_root_mean_squared_error: 105932.0859\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3695304704.0000 - r2: 0.8431 - root_mean_squared_error: 60789.0195 - val_loss: 9311982592.0000 - val_r2: 0.6589 - val_root_mean_squared_error: 96498.6172\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3688088832.0000 - r2: 0.8434 - root_mean_squared_error: 60729.6367 - val_loss: 9472292864.0000 - val_r2: 0.6522 - val_root_mean_squared_error: 97325.7031\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3662745344.0000 - r2: 0.8444 - root_mean_squared_error: 60520.6211 - val_loss: 9423126528.0000 - val_r2: 0.6545 - val_root_mean_squared_error: 97072.7891\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3654260480.0000 - r2: 0.8446 - root_mean_squared_error: 60450.4805 - val_loss: 10159754240.0000 - val_r2: 0.6274 - val_root_mean_squared_error: 100795.6094\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3638512384.0000 - r2: 0.8453 - root_mean_squared_error: 60320.0820 - val_loss: 9517927424.0000 - val_r2: 0.6510 - val_root_mean_squared_error: 97559.8672\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3622805248.0000 - r2: 0.8459 - root_mean_squared_error: 60189.7422 - val_loss: 10140097536.0000 - val_r2: 0.6283 - val_root_mean_squared_error: 100698.0547\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3616434688.0000 - r2: 0.8460 - root_mean_squared_error: 60136.8008 - val_loss: 10741794816.0000 - val_r2: 0.6062 - val_root_mean_squared_error: 103642.6328\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3594360320.0000 - r2: 0.8472 - root_mean_squared_error: 59952.9844 - val_loss: 10055863296.0000 - val_r2: 0.6316 - val_root_mean_squared_error: 100278.9297\n",
      "session cleared!\n",
      "\n",
      "ix 2 i 1\n",
      "updated temp_vec [1, 1, 0, 0, 1, 0, 1, 1, 1]\n",
      "going through feature_mask [1, 1, 0, 0, 1, 0, 1, 1, 1]\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 12), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 17), dtype=tf.float32, name=None), name='flatten_2/Reshape:0', description=\"created by layer 'flatten_2'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 43), dtype=tf.float32, name=None), name='flatten_1/Reshape:0', description=\"created by layer 'flatten_1'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization/truediv:0', description=\"created by layer 'normalization'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_1/truediv:0', description=\"created by layer 'normalization_1'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_2/truediv:0', description=\"created by layer 'normalization_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_3/truediv:0', description=\"created by layer 'normalization_3'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_4/truediv:0', description=\"created by layer 'normalization_4'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_5/truediv:0', description=\"created by layer 'normalization_5'\")\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 3s 5ms/step - loss: 52341915648.0000 - r2: -1.2292 - root_mean_squared_error: 228783.5625 - val_loss: 28504238080.0000 - val_r2: -0.0402 - val_root_mean_squared_error: 168831.9844\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 18849282048.0000 - r2: 0.2015 - root_mean_squared_error: 137292.6875 - val_loss: 27874230272.0000 - val_r2: -0.0184 - val_root_mean_squared_error: 166955.7656\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 17977587712.0000 - r2: 0.2394 - root_mean_squared_error: 134080.5312 - val_loss: 27788687360.0000 - val_r2: -0.0159 - val_root_mean_squared_error: 166699.3906\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 17160185856.0000 - r2: 0.2732 - root_mean_squared_error: 130996.8906 - val_loss: 25963311104.0000 - val_r2: 0.0495 - val_root_mean_squared_error: 161131.3438\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 16443056128.0000 - r2: 0.3028 - root_mean_squared_error: 128230.4844 - val_loss: 24883630080.0000 - val_r2: 0.0896 - val_root_mean_squared_error: 157745.4531\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15916720128.0000 - r2: 0.3251 - root_mean_squared_error: 126161.4844 - val_loss: 25283567616.0000 - val_r2: 0.0751 - val_root_mean_squared_error: 159008.0781\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15608193024.0000 - r2: 0.3371 - root_mean_squared_error: 124932.7578 - val_loss: 26799650816.0000 - val_r2: 0.0198 - val_root_mean_squared_error: 163705.9844\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15469448192.0000 - r2: 0.3436 - root_mean_squared_error: 124376.2344 - val_loss: 25847128064.0000 - val_r2: 0.0538 - val_root_mean_squared_error: 160770.4219\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15410549760.0000 - r2: 0.3470 - root_mean_squared_error: 124139.2344 - val_loss: 24889438208.0000 - val_r2: 0.0889 - val_root_mean_squared_error: 157763.8750\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15413426176.0000 - r2: 0.3470 - root_mean_squared_error: 124150.8203 - val_loss: 23108702208.0000 - val_r2: 0.1542 - val_root_mean_squared_error: 152015.4688\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15420205056.0000 - r2: 0.3459 - root_mean_squared_error: 124178.1172 - val_loss: 24511244288.0000 - val_r2: 0.1028 - val_root_mean_squared_error: 156560.6719\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15388884992.0000 - r2: 0.3473 - root_mean_squared_error: 124051.9453 - val_loss: 26293964800.0000 - val_r2: 0.0381 - val_root_mean_squared_error: 162154.1406\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15409811456.0000 - r2: 0.3452 - root_mean_squared_error: 124136.2578 - val_loss: 24790697984.0000 - val_r2: 0.0925 - val_root_mean_squared_error: 157450.6250\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15380128768.0000 - r2: 0.3478 - root_mean_squared_error: 124016.6484 - val_loss: 24794155008.0000 - val_r2: 0.0920 - val_root_mean_squared_error: 157461.5938\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15383710720.0000 - r2: 0.3477 - root_mean_squared_error: 124031.0859 - val_loss: 24294940672.0000 - val_r2: 0.1118 - val_root_mean_squared_error: 155868.3438\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15391841280.0000 - r2: 0.3470 - root_mean_squared_error: 124063.8594 - val_loss: 24972333056.0000 - val_r2: 0.0852 - val_root_mean_squared_error: 158026.3750\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15392569344.0000 - r2: 0.3474 - root_mean_squared_error: 124066.7969 - val_loss: 24989904896.0000 - val_r2: 0.0859 - val_root_mean_squared_error: 158081.9531\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15405146112.0000 - r2: 0.3471 - root_mean_squared_error: 124117.4688 - val_loss: 25412112384.0000 - val_r2: 0.0713 - val_root_mean_squared_error: 159411.7656\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15395659776.0000 - r2: 0.3478 - root_mean_squared_error: 124079.2500 - val_loss: 24463671296.0000 - val_r2: 0.1033 - val_root_mean_squared_error: 156408.6719\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15400853504.0000 - r2: 0.3472 - root_mean_squared_error: 124100.1719 - val_loss: 26609707008.0000 - val_r2: 0.0250 - val_root_mean_squared_error: 163124.8281\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15389283328.0000 - r2: 0.3473 - root_mean_squared_error: 124053.5469 - val_loss: 25493645312.0000 - val_r2: 0.0673 - val_root_mean_squared_error: 159667.2969\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15394355200.0000 - r2: 0.3455 - root_mean_squared_error: 124073.9922 - val_loss: 25756200960.0000 - val_r2: 0.0583 - val_root_mean_squared_error: 160487.3906\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15396377600.0000 - r2: 0.3471 - root_mean_squared_error: 124082.1406 - val_loss: 25076758528.0000 - val_r2: 0.0834 - val_root_mean_squared_error: 158356.4219\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15387729920.0000 - r2: 0.3477 - root_mean_squared_error: 124047.2891 - val_loss: 25262964736.0000 - val_r2: 0.0756 - val_root_mean_squared_error: 158943.2812\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15382782976.0000 - r2: 0.3473 - root_mean_squared_error: 124027.3516 - val_loss: 24995155968.0000 - val_r2: 0.0851 - val_root_mean_squared_error: 158098.5625\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15409124352.0000 - r2: 0.3465 - root_mean_squared_error: 124133.4922 - val_loss: 24402593792.0000 - val_r2: 0.1072 - val_root_mean_squared_error: 156213.2969\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15386341376.0000 - r2: 0.3476 - root_mean_squared_error: 124041.6953 - val_loss: 26274205696.0000 - val_r2: 0.0397 - val_root_mean_squared_error: 162093.2031\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15387943936.0000 - r2: 0.3471 - root_mean_squared_error: 124048.1484 - val_loss: 22914461696.0000 - val_r2: 0.1613 - val_root_mean_squared_error: 151375.2344\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15409311744.0000 - r2: 0.3467 - root_mean_squared_error: 124134.2500 - val_loss: 25664526336.0000 - val_r2: 0.0615 - val_root_mean_squared_error: 160201.5156\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15393848320.0000 - r2: 0.3476 - root_mean_squared_error: 124071.9453 - val_loss: 25326637056.0000 - val_r2: 0.0738 - val_root_mean_squared_error: 159143.4531\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15391514624.0000 - r2: 0.3477 - root_mean_squared_error: 124062.5469 - val_loss: 24330776576.0000 - val_r2: 0.1101 - val_root_mean_squared_error: 155983.2500\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15402121216.0000 - r2: 0.3471 - root_mean_squared_error: 124105.2812 - val_loss: 25735862272.0000 - val_r2: 0.0581 - val_root_mean_squared_error: 160424.0000\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15382855680.0000 - r2: 0.3472 - root_mean_squared_error: 124027.6406 - val_loss: 26934484992.0000 - val_r2: 0.0141 - val_root_mean_squared_error: 164117.2969\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15389863936.0000 - r2: 0.3469 - root_mean_squared_error: 124055.8906 - val_loss: 27297521664.0000 - val_r2: 6.4234e-04 - val_root_mean_squared_error: 165219.6094\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15383378944.0000 - r2: 0.3466 - root_mean_squared_error: 124029.7500 - val_loss: 25269776384.0000 - val_r2: 0.0760 - val_root_mean_squared_error: 158964.7031\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15392351232.0000 - r2: 0.3471 - root_mean_squared_error: 124065.9141 - val_loss: 26382217216.0000 - val_r2: 0.0356 - val_root_mean_squared_error: 162426.0312\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15384572928.0000 - r2: 0.3470 - root_mean_squared_error: 124034.5625 - val_loss: 24308183040.0000 - val_r2: 0.1101 - val_root_mean_squared_error: 155910.8125\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15386107904.0000 - r2: 0.3472 - root_mean_squared_error: 124040.7500 - val_loss: 25812649984.0000 - val_r2: 0.0565 - val_root_mean_squared_error: 160663.1562\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15400899584.0000 - r2: 0.3469 - root_mean_squared_error: 124100.3594 - val_loss: 25185437696.0000 - val_r2: 0.0785 - val_root_mean_squared_error: 158699.2031\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15373328384.0000 - r2: 0.3485 - root_mean_squared_error: 123989.2266 - val_loss: 25988868096.0000 - val_r2: 0.0503 - val_root_mean_squared_error: 161210.6250\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15391241216.0000 - r2: 0.3477 - root_mean_squared_error: 124061.4375 - val_loss: 24894937088.0000 - val_r2: 0.0868 - val_root_mean_squared_error: 157781.2969\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15377262592.0000 - r2: 0.3484 - root_mean_squared_error: 124005.0938 - val_loss: 25043179520.0000 - val_r2: 0.0831 - val_root_mean_squared_error: 158250.3750\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15380343808.0000 - r2: 0.3483 - root_mean_squared_error: 124017.5156 - val_loss: 25288607744.0000 - val_r2: 0.0751 - val_root_mean_squared_error: 159023.9219\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15404734464.0000 - r2: 0.3468 - root_mean_squared_error: 124115.8125 - val_loss: 24605159424.0000 - val_r2: 0.1002 - val_root_mean_squared_error: 156860.3125\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15383283712.0000 - r2: 0.3470 - root_mean_squared_error: 124029.3672 - val_loss: 25365086208.0000 - val_r2: 0.0715 - val_root_mean_squared_error: 159264.2031\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15372509184.0000 - r2: 0.3483 - root_mean_squared_error: 123985.9219 - val_loss: 25268054016.0000 - val_r2: 0.0753 - val_root_mean_squared_error: 158959.2812\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15392437248.0000 - r2: 0.3473 - root_mean_squared_error: 124066.2578 - val_loss: 26838036480.0000 - val_r2: 0.0169 - val_root_mean_squared_error: 163823.1875\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15391863808.0000 - r2: 0.3471 - root_mean_squared_error: 124063.9531 - val_loss: 24965744640.0000 - val_r2: 0.0872 - val_root_mean_squared_error: 158005.5156\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15396252672.0000 - r2: 0.3462 - root_mean_squared_error: 124081.6406 - val_loss: 25276219392.0000 - val_r2: 0.0754 - val_root_mean_squared_error: 158984.9688\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 15379830784.0000 - r2: 0.3470 - root_mean_squared_error: 124015.4453 - val_loss: 24660043776.0000 - val_r2: 0.0963 - val_root_mean_squared_error: 157035.1719\n",
      "session cleared!\n",
      "\n",
      "ix 3 i 0\n",
      "ix 4 i 1\n",
      "updated temp_vec [1, 1, 1, 0, 0, 0, 1, 1, 1]\n",
      "going through feature_mask [1, 1, 1, 0, 0, 0, 1, 1, 1]\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 12), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 17), dtype=tf.float32, name=None), name='flatten_2/Reshape:0', description=\"created by layer 'flatten_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 43), dtype=tf.float32, name=None), name='flatten_1/Reshape:0', description=\"created by layer 'flatten_1'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization/truediv:0', description=\"created by layer 'normalization'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_1/truediv:0', description=\"created by layer 'normalization_1'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_2/truediv:0', description=\"created by layer 'normalization_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_3/truediv:0', description=\"created by layer 'normalization_3'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_4/truediv:0', description=\"created by layer 'normalization_4'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_5/truediv:0', description=\"created by layer 'normalization_5'\")\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 3s 5ms/step - loss: 35755855872.0000 - r2: -0.5099 - root_mean_squared_error: 189092.1875 - val_loss: 14553617408.0000 - val_r2: 0.4684 - val_root_mean_squared_error: 120638.3750\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7526410752.0000 - r2: 0.6804 - root_mean_squared_error: 86754.8906 - val_loss: 12727144448.0000 - val_r2: 0.5347 - val_root_mean_squared_error: 112814.6484\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6631666688.0000 - r2: 0.7187 - root_mean_squared_error: 81435.0469 - val_loss: 13661348864.0000 - val_r2: 0.4994 - val_root_mean_squared_error: 116881.7734\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5859145728.0000 - r2: 0.7511 - root_mean_squared_error: 76545.0547 - val_loss: 11661277184.0000 - val_r2: 0.5742 - val_root_mean_squared_error: 107987.3906\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5364159488.0000 - r2: 0.7722 - root_mean_squared_error: 73240.4219 - val_loss: 11522960384.0000 - val_r2: 0.5771 - val_root_mean_squared_error: 107345.0547\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5054222848.0000 - r2: 0.7854 - root_mean_squared_error: 71093.0547 - val_loss: 10664029184.0000 - val_r2: 0.6092 - val_root_mean_squared_error: 103266.7891\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4833200640.0000 - r2: 0.7945 - root_mean_squared_error: 69521.2266 - val_loss: 11493793792.0000 - val_r2: 0.5794 - val_root_mean_squared_error: 107209.1094\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4690108416.0000 - r2: 0.8009 - root_mean_squared_error: 68484.3672 - val_loss: 12035271680.0000 - val_r2: 0.5593 - val_root_mean_squared_error: 109705.3828\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4613064192.0000 - r2: 0.8041 - root_mean_squared_error: 67919.5391 - val_loss: 11092170752.0000 - val_r2: 0.5935 - val_root_mean_squared_error: 105319.3750\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4572387840.0000 - r2: 0.8057 - root_mean_squared_error: 67619.4375 - val_loss: 10411534336.0000 - val_r2: 0.6184 - val_root_mean_squared_error: 102036.9297\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4566226944.0000 - r2: 0.8061 - root_mean_squared_error: 67573.8594 - val_loss: 10379275264.0000 - val_r2: 0.6191 - val_root_mean_squared_error: 101878.7266\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4561613312.0000 - r2: 0.8061 - root_mean_squared_error: 67539.7188 - val_loss: 11337247744.0000 - val_r2: 0.5842 - val_root_mean_squared_error: 106476.5156\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4559706112.0000 - r2: 0.8062 - root_mean_squared_error: 67525.5938 - val_loss: 10483414016.0000 - val_r2: 0.6163 - val_root_mean_squared_error: 102388.5469\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4551155200.0000 - r2: 0.8067 - root_mean_squared_error: 67462.2500 - val_loss: 11641522176.0000 - val_r2: 0.5731 - val_root_mean_squared_error: 107895.8828\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4554041856.0000 - r2: 0.8066 - root_mean_squared_error: 67483.6406 - val_loss: 10244015104.0000 - val_r2: 0.6244 - val_root_mean_squared_error: 101212.7188\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4547843072.0000 - r2: 0.8068 - root_mean_squared_error: 67437.6953 - val_loss: 10539290624.0000 - val_r2: 0.6138 - val_root_mean_squared_error: 102661.0469\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4544091136.0000 - r2: 0.8069 - root_mean_squared_error: 67409.8750 - val_loss: 9609924608.0000 - val_r2: 0.6481 - val_root_mean_squared_error: 98030.2266\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4555908096.0000 - r2: 0.8062 - root_mean_squared_error: 67497.4688 - val_loss: 11754841088.0000 - val_r2: 0.5696 - val_root_mean_squared_error: 108419.7422\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4553867776.0000 - r2: 0.8064 - root_mean_squared_error: 67482.3516 - val_loss: 11120589824.0000 - val_r2: 0.5924 - val_root_mean_squared_error: 105454.2109\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4549229568.0000 - r2: 0.8066 - root_mean_squared_error: 67447.9766 - val_loss: 9793904640.0000 - val_r2: 0.6414 - val_root_mean_squared_error: 98964.1562\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4536725504.0000 - r2: 0.8075 - root_mean_squared_error: 67355.2188 - val_loss: 10292306944.0000 - val_r2: 0.6226 - val_root_mean_squared_error: 101451.0078\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4539517440.0000 - r2: 0.8075 - root_mean_squared_error: 67375.9375 - val_loss: 10559481856.0000 - val_r2: 0.6128 - val_root_mean_squared_error: 102759.3359\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4539263488.0000 - r2: 0.8069 - root_mean_squared_error: 67374.0547 - val_loss: 11128070144.0000 - val_r2: 0.5923 - val_root_mean_squared_error: 105489.6719\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4551033856.0000 - r2: 0.8066 - root_mean_squared_error: 67461.3516 - val_loss: 11431324672.0000 - val_r2: 0.5811 - val_root_mean_squared_error: 106917.3750\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4552539648.0000 - r2: 0.8069 - root_mean_squared_error: 67472.5078 - val_loss: 10675371008.0000 - val_r2: 0.6089 - val_root_mean_squared_error: 103321.6875\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4550282752.0000 - r2: 0.8066 - root_mean_squared_error: 67455.7812 - val_loss: 10528003072.0000 - val_r2: 0.6143 - val_root_mean_squared_error: 102606.0547\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4555522048.0000 - r2: 0.8062 - root_mean_squared_error: 67494.6094 - val_loss: 8914270208.0000 - val_r2: 0.6735 - val_root_mean_squared_error: 94415.4141\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4549321728.0000 - r2: 0.8067 - root_mean_squared_error: 67448.6562 - val_loss: 10862212096.0000 - val_r2: 0.6018 - val_root_mean_squared_error: 104221.9375\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4546884608.0000 - r2: 0.8068 - root_mean_squared_error: 67430.5938 - val_loss: 11376766976.0000 - val_r2: 0.5829 - val_root_mean_squared_error: 106661.9297\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4532225536.0000 - r2: 0.8073 - root_mean_squared_error: 67321.8047 - val_loss: 10823845888.0000 - val_r2: 0.6030 - val_root_mean_squared_error: 104037.7109\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4429165056.0000 - r2: 0.8116 - root_mean_squared_error: 66551.9688 - val_loss: 10357946368.0000 - val_r2: 0.6202 - val_root_mean_squared_error: 101774.0000\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4315539968.0000 - r2: 0.8168 - root_mean_squared_error: 65692.7656 - val_loss: 10979233792.0000 - val_r2: 0.5982 - val_root_mean_squared_error: 104781.8359\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4175172864.0000 - r2: 0.8226 - root_mean_squared_error: 64615.5781 - val_loss: 10506881024.0000 - val_r2: 0.6142 - val_root_mean_squared_error: 102503.0781\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4032703232.0000 - r2: 0.8286 - root_mean_squared_error: 63503.5703 - val_loss: 10567501824.0000 - val_r2: 0.6118 - val_root_mean_squared_error: 102798.3516\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3958121728.0000 - r2: 0.8317 - root_mean_squared_error: 62913.6055 - val_loss: 10437008384.0000 - val_r2: 0.6176 - val_root_mean_squared_error: 102161.6797\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3884101888.0000 - r2: 0.8347 - root_mean_squared_error: 62322.5625 - val_loss: 10435139584.0000 - val_r2: 0.6176 - val_root_mean_squared_error: 102152.5312\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3842992128.0000 - r2: 0.8366 - root_mean_squared_error: 61991.8711 - val_loss: 11323351040.0000 - val_r2: 0.5845 - val_root_mean_squared_error: 106411.2344\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3804839424.0000 - r2: 0.8382 - root_mean_squared_error: 61683.3789 - val_loss: 10817809408.0000 - val_r2: 0.6025 - val_root_mean_squared_error: 104008.6953\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3759506176.0000 - r2: 0.8399 - root_mean_squared_error: 61314.8125 - val_loss: 9277562880.0000 - val_r2: 0.6599 - val_root_mean_squared_error: 96320.1094\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3751917824.0000 - r2: 0.8406 - root_mean_squared_error: 61252.9023 - val_loss: 9799012352.0000 - val_r2: 0.6402 - val_root_mean_squared_error: 98989.9609\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3740100864.0000 - r2: 0.8408 - root_mean_squared_error: 61156.3633 - val_loss: 10465190912.0000 - val_r2: 0.6153 - val_root_mean_squared_error: 102299.5156\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3724010752.0000 - r2: 0.8416 - root_mean_squared_error: 61024.6719 - val_loss: 9874577408.0000 - val_r2: 0.6375 - val_root_mean_squared_error: 99370.9062\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3711021056.0000 - r2: 0.8420 - root_mean_squared_error: 60918.1523 - val_loss: 9236468736.0000 - val_r2: 0.6611 - val_root_mean_squared_error: 96106.5469\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3708353024.0000 - r2: 0.8419 - root_mean_squared_error: 60896.2461 - val_loss: 10716794880.0000 - val_r2: 0.6061 - val_root_mean_squared_error: 103521.9531\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3707619072.0000 - r2: 0.8424 - root_mean_squared_error: 60890.2227 - val_loss: 10075578368.0000 - val_r2: 0.6295 - val_root_mean_squared_error: 100377.1797\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3705041152.0000 - r2: 0.8424 - root_mean_squared_error: 60869.0508 - val_loss: 9624286208.0000 - val_r2: 0.6474 - val_root_mean_squared_error: 98103.4453\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3714008576.0000 - r2: 0.8420 - root_mean_squared_error: 60942.6680 - val_loss: 10509562880.0000 - val_r2: 0.6142 - val_root_mean_squared_error: 102516.1562\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3706132224.0000 - r2: 0.8423 - root_mean_squared_error: 60878.0117 - val_loss: 9531246592.0000 - val_r2: 0.6501 - val_root_mean_squared_error: 97628.1016\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3718531584.0000 - r2: 0.8417 - root_mean_squared_error: 60979.7656 - val_loss: 10857764864.0000 - val_r2: 0.6018 - val_root_mean_squared_error: 104200.6016\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3699855104.0000 - r2: 0.8428 - root_mean_squared_error: 60826.4336 - val_loss: 9472589824.0000 - val_r2: 0.6528 - val_root_mean_squared_error: 97327.2344\n",
      "session cleared!\n",
      "\n",
      "ix 5 i 0\n",
      "ix 6 i 1\n",
      "updated temp_vec [1, 1, 1, 0, 1, 0, 0, 1, 1]\n",
      "going through feature_mask [1, 1, 1, 0, 1, 0, 0, 1, 1]\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 12), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 17), dtype=tf.float32, name=None), name='flatten_2/Reshape:0', description=\"created by layer 'flatten_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 43), dtype=tf.float32, name=None), name='flatten_1/Reshape:0', description=\"created by layer 'flatten_1'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization/truediv:0', description=\"created by layer 'normalization'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_1/truediv:0', description=\"created by layer 'normalization_1'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_2/truediv:0', description=\"created by layer 'normalization_2'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_3/truediv:0', description=\"created by layer 'normalization_3'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_4/truediv:0', description=\"created by layer 'normalization_4'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_5/truediv:0', description=\"created by layer 'normalization_5'\")\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 3s 5ms/step - loss: 35957301248.0000 - r2: -0.5148 - root_mean_squared_error: 189624.1094 - val_loss: 15000008704.0000 - val_r2: 0.4515 - val_root_mean_squared_error: 122474.5234\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7745583616.0000 - r2: 0.6715 - root_mean_squared_error: 88009.0000 - val_loss: 13519507456.0000 - val_r2: 0.5056 - val_root_mean_squared_error: 116273.4141\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6900636160.0000 - r2: 0.7076 - root_mean_squared_error: 83070.0703 - val_loss: 12210816000.0000 - val_r2: 0.5530 - val_root_mean_squared_error: 110502.5625\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5934255616.0000 - r2: 0.7485 - root_mean_squared_error: 77034.1172 - val_loss: 12878432256.0000 - val_r2: 0.5281 - val_root_mean_squared_error: 113483.1797\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5100584960.0000 - r2: 0.7840 - root_mean_squared_error: 71418.3828 - val_loss: 9621642240.0000 - val_r2: 0.6475 - val_root_mean_squared_error: 98089.9688\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4556661760.0000 - r2: 0.8067 - root_mean_squared_error: 67503.0469 - val_loss: 9246370816.0000 - val_r2: 0.6615 - val_root_mean_squared_error: 96158.0547\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4309266432.0000 - r2: 0.8169 - root_mean_squared_error: 65645.0000 - val_loss: 11347761152.0000 - val_r2: 0.5842 - val_root_mean_squared_error: 106525.8672\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4231440128.0000 - r2: 0.8201 - root_mean_squared_error: 65049.5195 - val_loss: 10679017472.0000 - val_r2: 0.6088 - val_root_mean_squared_error: 103339.3281\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4207124736.0000 - r2: 0.8214 - root_mean_squared_error: 64862.3516 - val_loss: 11363118080.0000 - val_r2: 0.5829 - val_root_mean_squared_error: 106597.9297\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4207186688.0000 - r2: 0.8215 - root_mean_squared_error: 64862.8281 - val_loss: 9708342272.0000 - val_r2: 0.6436 - val_root_mean_squared_error: 98530.9219\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4202299136.0000 - r2: 0.8216 - root_mean_squared_error: 64825.1445 - val_loss: 11891427328.0000 - val_r2: 0.5645 - val_root_mean_squared_error: 109047.8203\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4209999616.0000 - r2: 0.8210 - root_mean_squared_error: 64884.5117 - val_loss: 9372815360.0000 - val_r2: 0.6565 - val_root_mean_squared_error: 96813.3047\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4204026880.0000 - r2: 0.8213 - root_mean_squared_error: 64838.4688 - val_loss: 9907816448.0000 - val_r2: 0.6370 - val_root_mean_squared_error: 99538.0156\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4197012224.0000 - r2: 0.8221 - root_mean_squared_error: 64784.3516 - val_loss: 10596930560.0000 - val_r2: 0.6117 - val_root_mean_squared_error: 102941.3906\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4208485376.0000 - r2: 0.8211 - root_mean_squared_error: 64872.8398 - val_loss: 8783547392.0000 - val_r2: 0.6781 - val_root_mean_squared_error: 93720.5781\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4205071616.0000 - r2: 0.8211 - root_mean_squared_error: 64846.5234 - val_loss: 11314883584.0000 - val_r2: 0.5852 - val_root_mean_squared_error: 106371.4453\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4200595968.0000 - r2: 0.8214 - root_mean_squared_error: 64812.0039 - val_loss: 9849987072.0000 - val_r2: 0.6388 - val_root_mean_squared_error: 99247.1016\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4205224960.0000 - r2: 0.8215 - root_mean_squared_error: 64847.7070 - val_loss: 9471106048.0000 - val_r2: 0.6529 - val_root_mean_squared_error: 97319.6094\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4218408192.0000 - r2: 0.8206 - root_mean_squared_error: 64949.2734 - val_loss: 12332170240.0000 - val_r2: 0.5464 - val_root_mean_squared_error: 111050.3047\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4199751424.0000 - r2: 0.8217 - root_mean_squared_error: 64805.4883 - val_loss: 11414401024.0000 - val_r2: 0.5819 - val_root_mean_squared_error: 106838.2031\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4186297344.0000 - r2: 0.8219 - root_mean_squared_error: 64701.6016 - val_loss: 10331953152.0000 - val_r2: 0.6214 - val_root_mean_squared_error: 101646.2188\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4191192064.0000 - r2: 0.8219 - root_mean_squared_error: 64739.4180 - val_loss: 10987259904.0000 - val_r2: 0.5972 - val_root_mean_squared_error: 104820.1328\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4200401664.0000 - r2: 0.8217 - root_mean_squared_error: 64810.5039 - val_loss: 9684114432.0000 - val_r2: 0.6455 - val_root_mean_squared_error: 98407.8984\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4221132288.0000 - r2: 0.8204 - root_mean_squared_error: 64970.2422 - val_loss: 12821133312.0000 - val_r2: 0.5301 - val_root_mean_squared_error: 113230.4453\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4195466496.0000 - r2: 0.8218 - root_mean_squared_error: 64772.4219 - val_loss: 10747359232.0000 - val_r2: 0.6058 - val_root_mean_squared_error: 103669.4688\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4204318976.0000 - r2: 0.8217 - root_mean_squared_error: 64840.7188 - val_loss: 10231742464.0000 - val_r2: 0.6250 - val_root_mean_squared_error: 101152.0781\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4195577600.0000 - r2: 0.8216 - root_mean_squared_error: 64773.2773 - val_loss: 11459679232.0000 - val_r2: 0.5797 - val_root_mean_squared_error: 107049.8906\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4195233280.0000 - r2: 0.8217 - root_mean_squared_error: 64770.6211 - val_loss: 9164641280.0000 - val_r2: 0.6646 - val_root_mean_squared_error: 95732.1328\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4197619200.0000 - r2: 0.8217 - root_mean_squared_error: 64789.0352 - val_loss: 10704253952.0000 - val_r2: 0.6080 - val_root_mean_squared_error: 103461.3672\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4197234176.0000 - r2: 0.8218 - root_mean_squared_error: 64786.0664 - val_loss: 8516498432.0000 - val_r2: 0.6880 - val_root_mean_squared_error: 92284.8750\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4201379328.0000 - r2: 0.8214 - root_mean_squared_error: 64818.0469 - val_loss: 9937879040.0000 - val_r2: 0.6355 - val_root_mean_squared_error: 99688.9141\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4198869248.0000 - r2: 0.8213 - root_mean_squared_error: 64798.6836 - val_loss: 9798524928.0000 - val_r2: 0.6406 - val_root_mean_squared_error: 98987.5000\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4187888384.0000 - r2: 0.8222 - root_mean_squared_error: 64713.8945 - val_loss: 9977640960.0000 - val_r2: 0.6344 - val_root_mean_squared_error: 99888.1406\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4175222016.0000 - r2: 0.8224 - root_mean_squared_error: 64615.9570 - val_loss: 11760030720.0000 - val_r2: 0.5690 - val_root_mean_squared_error: 108443.6719\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4051455488.0000 - r2: 0.8277 - root_mean_squared_error: 63651.0430 - val_loss: 10519389184.0000 - val_r2: 0.6144 - val_root_mean_squared_error: 102564.0703\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3917876736.0000 - r2: 0.8334 - root_mean_squared_error: 62592.9453 - val_loss: 10217633792.0000 - val_r2: 0.6256 - val_root_mean_squared_error: 101082.3125\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3778168832.0000 - r2: 0.8391 - root_mean_squared_error: 61466.8125 - val_loss: 9085762560.0000 - val_r2: 0.6666 - val_root_mean_squared_error: 95319.2656\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3645918464.0000 - r2: 0.8452 - root_mean_squared_error: 60381.4414 - val_loss: 9397808128.0000 - val_r2: 0.6548 - val_root_mean_squared_error: 96942.2891\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3563315456.0000 - r2: 0.8486 - root_mean_squared_error: 59693.5117 - val_loss: 9296952320.0000 - val_r2: 0.6585 - val_root_mean_squared_error: 96420.7031\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3528701184.0000 - r2: 0.8502 - root_mean_squared_error: 59402.8711 - val_loss: 10351106048.0000 - val_r2: 0.6208 - val_root_mean_squared_error: 101740.3828\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3484140288.0000 - r2: 0.8516 - root_mean_squared_error: 59026.6055 - val_loss: 9850827776.0000 - val_r2: 0.6397 - val_root_mean_squared_error: 99251.3359\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3456522496.0000 - r2: 0.8528 - root_mean_squared_error: 58792.1992 - val_loss: 10374660096.0000 - val_r2: 0.6196 - val_root_mean_squared_error: 101856.0781\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3447759872.0000 - r2: 0.8532 - root_mean_squared_error: 58717.6289 - val_loss: 8326688768.0000 - val_r2: 0.6942 - val_root_mean_squared_error: 91250.6953\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3419266560.0000 - r2: 0.8547 - root_mean_squared_error: 58474.4961 - val_loss: 9235657728.0000 - val_r2: 0.6607 - val_root_mean_squared_error: 96102.3281\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3419667456.0000 - r2: 0.8545 - root_mean_squared_error: 58477.9219 - val_loss: 7835756544.0000 - val_r2: 0.7123 - val_root_mean_squared_error: 88519.8125\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3421319680.0000 - r2: 0.8546 - root_mean_squared_error: 58492.0469 - val_loss: 8451051008.0000 - val_r2: 0.6904 - val_root_mean_squared_error: 91929.6016\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3413025280.0000 - r2: 0.8546 - root_mean_squared_error: 58421.1016 - val_loss: 9987183616.0000 - val_r2: 0.6334 - val_root_mean_squared_error: 99935.8984\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3410290944.0000 - r2: 0.8550 - root_mean_squared_error: 58397.6953 - val_loss: 8894531584.0000 - val_r2: 0.6743 - val_root_mean_squared_error: 94310.8281\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3397571840.0000 - r2: 0.8554 - root_mean_squared_error: 58288.6953 - val_loss: 9756511232.0000 - val_r2: 0.6423 - val_root_mean_squared_error: 98775.0547\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3399162624.0000 - r2: 0.8553 - root_mean_squared_error: 58302.3398 - val_loss: 8928010240.0000 - val_r2: 0.6719 - val_root_mean_squared_error: 94488.1484\n",
      "session cleared!\n",
      "\n",
      "ix 7 i 1\n",
      "updated temp_vec [1, 1, 1, 0, 1, 0, 1, 0, 1]\n",
      "going through feature_mask [1, 1, 1, 0, 1, 0, 1, 0, 1]\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 12), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 17), dtype=tf.float32, name=None), name='flatten_2/Reshape:0', description=\"created by layer 'flatten_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 43), dtype=tf.float32, name=None), name='flatten_1/Reshape:0', description=\"created by layer 'flatten_1'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization/truediv:0', description=\"created by layer 'normalization'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_1/truediv:0', description=\"created by layer 'normalization_1'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_2/truediv:0', description=\"created by layer 'normalization_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_3/truediv:0', description=\"created by layer 'normalization_3'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_4/truediv:0', description=\"created by layer 'normalization_4'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_5/truediv:0', description=\"created by layer 'normalization_5'\")\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 3s 5ms/step - loss: 36404043776.0000 - r2: -0.5146 - root_mean_squared_error: 190798.4375 - val_loss: 14889553920.0000 - val_r2: 0.4558 - val_root_mean_squared_error: 122022.7578\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7870237696.0000 - r2: 0.6663 - root_mean_squared_error: 88714.3594 - val_loss: 13876775936.0000 - val_r2: 0.4926 - val_root_mean_squared_error: 117799.7266\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7160358400.0000 - r2: 0.6963 - root_mean_squared_error: 84618.8984 - val_loss: 13040094208.0000 - val_r2: 0.5231 - val_root_mean_squared_error: 114193.2344\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6452091392.0000 - r2: 0.7261 - root_mean_squared_error: 80324.9141 - val_loss: 11204347904.0000 - val_r2: 0.5896 - val_root_mean_squared_error: 105850.5938\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5844557312.0000 - r2: 0.7519 - root_mean_squared_error: 76449.7031 - val_loss: 11351425024.0000 - val_r2: 0.5844 - val_root_mean_squared_error: 106543.0703\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5431844352.0000 - r2: 0.7691 - root_mean_squared_error: 73701.0469 - val_loss: 12080580608.0000 - val_r2: 0.5574 - val_root_mean_squared_error: 109911.6953\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 5161093120.0000 - r2: 0.7807 - root_mean_squared_error: 71840.7500 - val_loss: 12092939264.0000 - val_r2: 0.5569 - val_root_mean_squared_error: 109967.8984\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4981693440.0000 - r2: 0.7886 - root_mean_squared_error: 70581.1094 - val_loss: 10370762752.0000 - val_r2: 0.6205 - val_root_mean_squared_error: 101836.9453\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4881351680.0000 - r2: 0.7923 - root_mean_squared_error: 69866.6719 - val_loss: 11426746368.0000 - val_r2: 0.5812 - val_root_mean_squared_error: 106895.9609\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4789337088.0000 - r2: 0.7961 - root_mean_squared_error: 69205.0391 - val_loss: 9560885248.0000 - val_r2: 0.6500 - val_root_mean_squared_error: 97779.7812\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4689844224.0000 - r2: 0.8008 - root_mean_squared_error: 68482.4375 - val_loss: 9973417984.0000 - val_r2: 0.6350 - val_root_mean_squared_error: 99867.0000\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4625057280.0000 - r2: 0.8035 - root_mean_squared_error: 68007.7734 - val_loss: 11009716224.0000 - val_r2: 0.5960 - val_root_mean_squared_error: 104927.1953\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4542874112.0000 - r2: 0.8069 - root_mean_squared_error: 67400.8438 - val_loss: 11028721664.0000 - val_r2: 0.5950 - val_root_mean_squared_error: 105017.7188\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4443684352.0000 - r2: 0.8114 - root_mean_squared_error: 66660.9688 - val_loss: 9894424576.0000 - val_r2: 0.6364 - val_root_mean_squared_error: 99470.7188\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4361604096.0000 - r2: 0.8149 - root_mean_squared_error: 66042.4453 - val_loss: 10286391296.0000 - val_r2: 0.6234 - val_root_mean_squared_error: 101421.8516\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4289183488.0000 - r2: 0.8173 - root_mean_squared_error: 65491.8594 - val_loss: 11159873536.0000 - val_r2: 0.5904 - val_root_mean_squared_error: 105640.3047\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4220967168.0000 - r2: 0.8202 - root_mean_squared_error: 64968.9727 - val_loss: 11248411648.0000 - val_r2: 0.5877 - val_root_mean_squared_error: 106058.5312\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4163776256.0000 - r2: 0.8230 - root_mean_squared_error: 64527.3281 - val_loss: 9699689472.0000 - val_r2: 0.6444 - val_root_mean_squared_error: 98487.0000\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4126877952.0000 - r2: 0.8241 - root_mean_squared_error: 64240.7812 - val_loss: 10989201408.0000 - val_r2: 0.5971 - val_root_mean_squared_error: 104829.3906\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4074094080.0000 - r2: 0.8265 - root_mean_squared_error: 63828.6289 - val_loss: 10940182528.0000 - val_r2: 0.5986 - val_root_mean_squared_error: 104595.3281\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4058850048.0000 - r2: 0.8271 - root_mean_squared_error: 63709.1055 - val_loss: 9143197696.0000 - val_r2: 0.6640 - val_root_mean_squared_error: 95620.0703\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4042200576.0000 - r2: 0.8278 - root_mean_squared_error: 63578.3008 - val_loss: 9136173056.0000 - val_r2: 0.6650 - val_root_mean_squared_error: 95583.3281\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4034502400.0000 - r2: 0.8284 - root_mean_squared_error: 63517.7344 - val_loss: 8886332416.0000 - val_r2: 0.6740 - val_root_mean_squared_error: 94267.3438\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4035760128.0000 - r2: 0.8283 - root_mean_squared_error: 63527.6328 - val_loss: 10249477120.0000 - val_r2: 0.6244 - val_root_mean_squared_error: 101239.7031\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4008449536.0000 - r2: 0.8294 - root_mean_squared_error: 63312.3164 - val_loss: 9111239680.0000 - val_r2: 0.6652 - val_root_mean_squared_error: 95452.8125\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4001008640.0000 - r2: 0.8296 - root_mean_squared_error: 63253.5273 - val_loss: 10492499968.0000 - val_r2: 0.6153 - val_root_mean_squared_error: 102432.9062\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4001135104.0000 - r2: 0.8296 - root_mean_squared_error: 63254.5273 - val_loss: 9002971136.0000 - val_r2: 0.6690 - val_root_mean_squared_error: 94883.9844\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4008015616.0000 - r2: 0.8295 - root_mean_squared_error: 63308.8906 - val_loss: 10237942784.0000 - val_r2: 0.6233 - val_root_mean_squared_error: 101182.7188\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3996101376.0000 - r2: 0.8299 - root_mean_squared_error: 63214.7227 - val_loss: 9556159488.0000 - val_r2: 0.6488 - val_root_mean_squared_error: 97755.6094\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3989835008.0000 - r2: 0.8300 - root_mean_squared_error: 63165.1406 - val_loss: 9318070272.0000 - val_r2: 0.6576 - val_root_mean_squared_error: 96530.1484\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3994880000.0000 - r2: 0.8293 - root_mean_squared_error: 63205.0625 - val_loss: 7891600384.0000 - val_r2: 0.7103 - val_root_mean_squared_error: 88834.6797\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3996790528.0000 - r2: 0.8299 - root_mean_squared_error: 63220.1758 - val_loss: 10857687040.0000 - val_r2: 0.6023 - val_root_mean_squared_error: 104200.2266\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3991913216.0000 - r2: 0.8304 - root_mean_squared_error: 63181.5898 - val_loss: 11403809792.0000 - val_r2: 0.5811 - val_root_mean_squared_error: 106788.6250\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4000291584.0000 - r2: 0.8298 - root_mean_squared_error: 63247.8594 - val_loss: 9310153728.0000 - val_r2: 0.6584 - val_root_mean_squared_error: 96489.1406\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3996626688.0000 - r2: 0.8302 - root_mean_squared_error: 63218.8789 - val_loss: 10450738176.0000 - val_r2: 0.6174 - val_root_mean_squared_error: 102228.8516\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3991772928.0000 - r2: 0.8302 - root_mean_squared_error: 63180.4805 - val_loss: 9246402560.0000 - val_r2: 0.6609 - val_root_mean_squared_error: 96158.2188\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3986384384.0000 - r2: 0.8304 - root_mean_squared_error: 63137.8203 - val_loss: 11966819328.0000 - val_r2: 0.5608 - val_root_mean_squared_error: 109392.9609\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3993596160.0000 - r2: 0.8301 - root_mean_squared_error: 63194.9062 - val_loss: 9598774272.0000 - val_r2: 0.6477 - val_root_mean_squared_error: 97973.3359\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3993780736.0000 - r2: 0.8297 - root_mean_squared_error: 63196.3672 - val_loss: 9534005248.0000 - val_r2: 0.6506 - val_root_mean_squared_error: 97642.2344\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3987094528.0000 - r2: 0.8300 - root_mean_squared_error: 63143.4453 - val_loss: 8214803968.0000 - val_r2: 0.6985 - val_root_mean_squared_error: 90635.5547\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3982985216.0000 - r2: 0.8304 - root_mean_squared_error: 63110.8945 - val_loss: 8681200640.0000 - val_r2: 0.6817 - val_root_mean_squared_error: 93172.9609\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3993691648.0000 - r2: 0.8300 - root_mean_squared_error: 63195.6602 - val_loss: 10828140544.0000 - val_r2: 0.6033 - val_root_mean_squared_error: 104058.3516\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 4001165312.0000 - r2: 0.8296 - root_mean_squared_error: 63254.7656 - val_loss: 8727863296.0000 - val_r2: 0.6798 - val_root_mean_squared_error: 93423.0312\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3982717440.0000 - r2: 0.8305 - root_mean_squared_error: 63108.7734 - val_loss: 9197611008.0000 - val_r2: 0.6626 - val_root_mean_squared_error: 95904.1797\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3982854656.0000 - r2: 0.8312 - root_mean_squared_error: 63109.8633 - val_loss: 10380967936.0000 - val_r2: 0.6184 - val_root_mean_squared_error: 101887.0391\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3998765824.0000 - r2: 0.8297 - root_mean_squared_error: 63235.7969 - val_loss: 10139815936.0000 - val_r2: 0.6282 - val_root_mean_squared_error: 100696.6562\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3989997056.0000 - r2: 0.8301 - root_mean_squared_error: 63166.4219 - val_loss: 9945388032.0000 - val_r2: 0.6343 - val_root_mean_squared_error: 99726.5625\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3972910848.0000 - r2: 0.8310 - root_mean_squared_error: 63031.0312 - val_loss: 10786736128.0000 - val_r2: 0.6043 - val_root_mean_squared_error: 103859.2109\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3988678400.0000 - r2: 0.8301 - root_mean_squared_error: 63155.9844 - val_loss: 10860600320.0000 - val_r2: 0.6020 - val_root_mean_squared_error: 104214.2031\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 3995961856.0000 - r2: 0.8301 - root_mean_squared_error: 63213.6211 - val_loss: 10242767872.0000 - val_r2: 0.6243 - val_root_mean_squared_error: 101206.5625\n",
      "session cleared!\n",
      "\n",
      "ix 8 i 1\n",
      "updated temp_vec [1, 1, 1, 0, 1, 0, 1, 1, 0]\n",
      "going through feature_mask [1, 1, 1, 0, 1, 0, 1, 1, 0]\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 12), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 17), dtype=tf.float32, name=None), name='flatten_2/Reshape:0', description=\"created by layer 'flatten_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 43), dtype=tf.float32, name=None), name='flatten_1/Reshape:0', description=\"created by layer 'flatten_1'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization/truediv:0', description=\"created by layer 'normalization'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_1/truediv:0', description=\"created by layer 'normalization_1'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_2/truediv:0', description=\"created by layer 'normalization_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_3/truediv:0', description=\"created by layer 'normalization_3'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_4/truediv:0', description=\"created by layer 'normalization_4'\")\n",
      "Skipping KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='normalization_5/truediv:0', description=\"created by layer 'normalization_5'\")\n",
      "Epoch 1/50\n",
      "342/342 [==============================] - 3s 5ms/step - loss: 37972086784.0000 - r2: -0.5799 - root_mean_squared_error: 194864.2812 - val_loss: 15602453504.0000 - val_r2: 0.4302 - val_root_mean_squared_error: 124909.7812\n",
      "Epoch 2/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 8301826048.0000 - r2: 0.6477 - root_mean_squared_error: 91114.3594 - val_loss: 13314154496.0000 - val_r2: 0.5138 - val_root_mean_squared_error: 115386.9766\n",
      "Epoch 3/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7909094400.0000 - r2: 0.6644 - root_mean_squared_error: 88933.0859 - val_loss: 14107587584.0000 - val_r2: 0.4837 - val_root_mean_squared_error: 118775.3672\n",
      "Epoch 4/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7580603392.0000 - r2: 0.6784 - root_mean_squared_error: 87066.6641 - val_loss: 12217945088.0000 - val_r2: 0.5532 - val_root_mean_squared_error: 110534.8125\n",
      "Epoch 5/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7285774336.0000 - r2: 0.6910 - root_mean_squared_error: 85356.7500 - val_loss: 13132705792.0000 - val_r2: 0.5192 - val_root_mean_squared_error: 114598.0156\n",
      "Epoch 6/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7110230016.0000 - r2: 0.6975 - root_mean_squared_error: 84322.1797 - val_loss: 13715639296.0000 - val_r2: 0.4987 - val_root_mean_squared_error: 117113.7891\n",
      "Epoch 7/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7042605056.0000 - r2: 0.7010 - root_mean_squared_error: 83920.2266 - val_loss: 12569232384.0000 - val_r2: 0.5405 - val_root_mean_squared_error: 112112.5859\n",
      "Epoch 8/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7011994624.0000 - r2: 0.7021 - root_mean_squared_error: 83737.6562 - val_loss: 12918037504.0000 - val_r2: 0.5276 - val_root_mean_squared_error: 113657.5469\n",
      "Epoch 9/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7009697280.0000 - r2: 0.7027 - root_mean_squared_error: 83723.9375 - val_loss: 14346339328.0000 - val_r2: 0.4746 - val_root_mean_squared_error: 119776.2031\n",
      "Epoch 10/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7006151680.0000 - r2: 0.7024 - root_mean_squared_error: 83702.7578 - val_loss: 13043172352.0000 - val_r2: 0.5221 - val_root_mean_squared_error: 114206.7109\n",
      "Epoch 11/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6990817280.0000 - r2: 0.7032 - root_mean_squared_error: 83611.1094 - val_loss: 12052242432.0000 - val_r2: 0.5589 - val_root_mean_squared_error: 109782.7031\n",
      "Epoch 12/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6993368064.0000 - r2: 0.7035 - root_mean_squared_error: 83626.3594 - val_loss: 11895350272.0000 - val_r2: 0.5646 - val_root_mean_squared_error: 109065.8047\n",
      "Epoch 13/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7017869824.0000 - r2: 0.7023 - root_mean_squared_error: 83772.7266 - val_loss: 12551341056.0000 - val_r2: 0.5413 - val_root_mean_squared_error: 112032.7656\n",
      "Epoch 14/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6993726976.0000 - r2: 0.7033 - root_mean_squared_error: 83628.5078 - val_loss: 15059692544.0000 - val_r2: 0.4486 - val_root_mean_squared_error: 122717.9375\n",
      "Epoch 15/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7006250496.0000 - r2: 0.7023 - root_mean_squared_error: 83703.3516 - val_loss: 13988328448.0000 - val_r2: 0.4881 - val_root_mean_squared_error: 118272.2656\n",
      "Epoch 16/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7020902912.0000 - r2: 0.7021 - root_mean_squared_error: 83790.8281 - val_loss: 12305533952.0000 - val_r2: 0.5494 - val_root_mean_squared_error: 110930.3125\n",
      "Epoch 17/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7016024576.0000 - r2: 0.7021 - root_mean_squared_error: 83761.7109 - val_loss: 12297428992.0000 - val_r2: 0.5507 - val_root_mean_squared_error: 110893.7734\n",
      "Epoch 18/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7001692160.0000 - r2: 0.7022 - root_mean_squared_error: 83676.1172 - val_loss: 12049098752.0000 - val_r2: 0.5583 - val_root_mean_squared_error: 109768.3906\n",
      "Epoch 19/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7001483264.0000 - r2: 0.7032 - root_mean_squared_error: 83674.8672 - val_loss: 12347948032.0000 - val_r2: 0.5481 - val_root_mean_squared_error: 111121.3203\n",
      "Epoch 20/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6997332480.0000 - r2: 0.7032 - root_mean_squared_error: 83650.0625 - val_loss: 10769275904.0000 - val_r2: 0.6066 - val_root_mean_squared_error: 103775.1250\n",
      "Epoch 21/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7014953984.0000 - r2: 0.7024 - root_mean_squared_error: 83755.3203 - val_loss: 13183527936.0000 - val_r2: 0.5179 - val_root_mean_squared_error: 114819.5469\n",
      "Epoch 22/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6997026304.0000 - r2: 0.7032 - root_mean_squared_error: 83648.2266 - val_loss: 13984666624.0000 - val_r2: 0.4871 - val_root_mean_squared_error: 118256.7812\n",
      "Epoch 23/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6994918912.0000 - r2: 0.7029 - root_mean_squared_error: 83635.6328 - val_loss: 12944370688.0000 - val_r2: 0.5265 - val_root_mean_squared_error: 113773.3281\n",
      "Epoch 24/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6985801728.0000 - r2: 0.7033 - root_mean_squared_error: 83581.1094 - val_loss: 12322438144.0000 - val_r2: 0.5489 - val_root_mean_squared_error: 111006.4766\n",
      "Epoch 25/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6988295680.0000 - r2: 0.7034 - root_mean_squared_error: 83596.0234 - val_loss: 12234408960.0000 - val_r2: 0.5525 - val_root_mean_squared_error: 110609.2656\n",
      "Epoch 26/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6996967424.0000 - r2: 0.7025 - root_mean_squared_error: 83647.8750 - val_loss: 13347301376.0000 - val_r2: 0.5108 - val_root_mean_squared_error: 115530.5234\n",
      "Epoch 27/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6998469120.0000 - r2: 0.7029 - root_mean_squared_error: 83656.8516 - val_loss: 13667827712.0000 - val_r2: 0.4995 - val_root_mean_squared_error: 116909.4844\n",
      "Epoch 28/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7000345600.0000 - r2: 0.7027 - root_mean_squared_error: 83668.0703 - val_loss: 12617670656.0000 - val_r2: 0.5383 - val_root_mean_squared_error: 112328.4062\n",
      "Epoch 29/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7001220608.0000 - r2: 0.7026 - root_mean_squared_error: 83673.2969 - val_loss: 12552008704.0000 - val_r2: 0.5409 - val_root_mean_squared_error: 112035.7500\n",
      "Epoch 30/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6980341760.0000 - r2: 0.7034 - root_mean_squared_error: 83548.4375 - val_loss: 13562189824.0000 - val_r2: 0.5029 - val_root_mean_squared_error: 116456.8125\n",
      "Epoch 31/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7010548736.0000 - r2: 0.7025 - root_mean_squared_error: 83729.0234 - val_loss: 13075576832.0000 - val_r2: 0.5216 - val_root_mean_squared_error: 114348.4922\n",
      "Epoch 32/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6989103616.0000 - r2: 0.7031 - root_mean_squared_error: 83600.8594 - val_loss: 12668986368.0000 - val_r2: 0.5359 - val_root_mean_squared_error: 112556.5938\n",
      "Epoch 33/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6990161408.0000 - r2: 0.7030 - root_mean_squared_error: 83607.1875 - val_loss: 13124078592.0000 - val_r2: 0.5194 - val_root_mean_squared_error: 114560.3672\n",
      "Epoch 34/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6994364928.0000 - r2: 0.7027 - root_mean_squared_error: 83632.3203 - val_loss: 13400845312.0000 - val_r2: 0.5098 - val_root_mean_squared_error: 115762.0234\n",
      "Epoch 35/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6995937280.0000 - r2: 0.7027 - root_mean_squared_error: 83641.7188 - val_loss: 12898620416.0000 - val_r2: 0.5281 - val_root_mean_squared_error: 113572.0938\n",
      "Epoch 36/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6999706624.0000 - r2: 0.7024 - root_mean_squared_error: 83664.2500 - val_loss: 12972882944.0000 - val_r2: 0.5241 - val_root_mean_squared_error: 113898.5625\n",
      "Epoch 37/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6989917696.0000 - r2: 0.7038 - root_mean_squared_error: 83605.7266 - val_loss: 12537151488.0000 - val_r2: 0.5416 - val_root_mean_squared_error: 111969.4219\n",
      "Epoch 38/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6984901120.0000 - r2: 0.7038 - root_mean_squared_error: 83575.7188 - val_loss: 15286103040.0000 - val_r2: 0.4403 - val_root_mean_squared_error: 123636.9844\n",
      "Epoch 39/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6983535104.0000 - r2: 0.7036 - root_mean_squared_error: 83567.5469 - val_loss: 13847474176.0000 - val_r2: 0.4926 - val_root_mean_squared_error: 117675.2891\n",
      "Epoch 40/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6979145216.0000 - r2: 0.7042 - root_mean_squared_error: 83541.2812 - val_loss: 13510501376.0000 - val_r2: 0.5057 - val_root_mean_squared_error: 116234.6797\n",
      "Epoch 41/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6996887552.0000 - r2: 0.7030 - root_mean_squared_error: 83647.3984 - val_loss: 16626772992.0000 - val_r2: 0.3914 - val_root_mean_squared_error: 128944.8438\n",
      "Epoch 42/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7006372864.0000 - r2: 0.7028 - root_mean_squared_error: 83704.0781 - val_loss: 14316233728.0000 - val_r2: 0.4754 - val_root_mean_squared_error: 119650.4609\n",
      "Epoch 43/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6983605760.0000 - r2: 0.7038 - root_mean_squared_error: 83567.9688 - val_loss: 13518373888.0000 - val_r2: 0.5054 - val_root_mean_squared_error: 116268.5391\n",
      "Epoch 44/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6992087040.0000 - r2: 0.7031 - root_mean_squared_error: 83618.7031 - val_loss: 11467454464.0000 - val_r2: 0.5806 - val_root_mean_squared_error: 107086.2031\n",
      "Epoch 45/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6985857536.0000 - r2: 0.7034 - root_mean_squared_error: 83581.4453 - val_loss: 13701447680.0000 - val_r2: 0.4981 - val_root_mean_squared_error: 117053.1797\n",
      "Epoch 46/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6989892608.0000 - r2: 0.7028 - root_mean_squared_error: 83605.5781 - val_loss: 13574632448.0000 - val_r2: 0.5029 - val_root_mean_squared_error: 116510.2266\n",
      "Epoch 47/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6988528128.0000 - r2: 0.7031 - root_mean_squared_error: 83597.4141 - val_loss: 12753444864.0000 - val_r2: 0.5333 - val_root_mean_squared_error: 112931.1484\n",
      "Epoch 48/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6997237760.0000 - r2: 0.7032 - root_mean_squared_error: 83649.4922 - val_loss: 12852362240.0000 - val_r2: 0.5290 - val_root_mean_squared_error: 113368.2578\n",
      "Epoch 49/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 7000704000.0000 - r2: 0.7027 - root_mean_squared_error: 83670.2109 - val_loss: 15420194816.0000 - val_r2: 0.4357 - val_root_mean_squared_error: 124178.0781\n",
      "Epoch 50/50\n",
      "342/342 [==============================] - 2s 5ms/step - loss: 6991939584.0000 - r2: 0.7027 - root_mean_squared_error: 83617.8203 - val_loss: 13368087552.0000 - val_r2: 0.5108 - val_root_mean_squared_error: 115620.4453\n",
      "session cleared!\n",
      "\n",
      "3037.0585465431213 seconds elapsed\n",
      "\n",
      "[[8450651648.0, 8207024128.0, 7777756672.0, 8319836672.0, 8290722304.0, 7753868800.0, 7790351872.0, 8386395648.0, 11615621120.0], [7971602432.0, 8430142464.0, 8738764800.0, 7640769536.0, 8078610432.0, 8290860032.0, 7931965440.0, 11520155648.0], [8673740800.0, 9311982592.0, 22914461696.0, 8914270208.0, 7835756544.0, 7891600384.0, 10769275904.0]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Implementation of recursive feature elimination algorithm for neural networks.\n",
    "\n",
    "Recursive feature elimination (RFE) is a feature selection method that removes unnecessary features from the inputs. \n",
    "It can also shed some insights on how much each feature contributes to the prediction task.\n",
    "\n",
    "The algorithm starts by removing one input feature whose removal leads to the minimum drop (or maximum improvement) in performance. \n",
    "- Given k features, to determine which of the k features will cause the minimum drop / maximum increase when that feature is removed, you will have to perform k experiments. After removing that feature, k-1 features will be left and you will have to perform k-1 experiments to determine the next feature to remove.\n",
    "    - In the case removing a feature leads to an improvement from the baseline (all features used), that feature is likely not useful since removing it actually helped the model to perform better.\n",
    "    - There will also be cases when all subsets with k-1 features do not do better than the baseline model. In that case, it is likely that all features are useful. You can get a sense of which are more useful than others by looking at the increase in error that occurs when the feature is removed.\n",
    "\n",
    "This procedure is repeated recursively on the reduced input set until the optimal number of input features is reached. \n",
    "- The feature removal goes on until either 1 feature is left, or the model performance does not improve from the previous best (e.g. when there are 7 features left, if none of the 7 experiments performed does better than the best performance of the model with 8 features, the RFE algorithm terminates).\n",
    "- The condition to stop the recursive process once all (k-1)-features models do worse than the best k-features model was added to make the algorithm terminate earlier so that you don't have to run too many iterations. Also, if the condition happens, then subsequent search is likely to be fruitless (it's always possible for the contrary to happen, but the chances are low and it's usually not worth the additional time).\n",
    "\n",
    "Each model should use a different subset of features and they are trained independently. There is no loading of weights from any previous models.\n",
    "\n",
    "\n",
    "In the code below, a boolean mask `vec` is used to keep track of which features to select during the iteration. \n",
    "\n",
    "You need to place your model training code into the 'train_model' function and have it return the validation loss.\n",
    "\n",
    "Look out for the comments labelled 'TODO'.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "import os\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "\n",
    "import random \n",
    "random.seed(SEED)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "num_features = 9\n",
    "\n",
    "vec = [1 for i in range(num_features)]\n",
    "best_loss = 1e15\n",
    "new_best_loss = 1e14\n",
    "which_iter = ''\n",
    "\n",
    "all_losses = [] # should be len 9,8,7,...\n",
    "\n",
    "\n",
    "def train_model(feature_mask):\n",
    "    \"\"\"\n",
    "    Given a boolean mask (feature_mask), select the features accordingly, train the model and return the validation loss.\n",
    "    \"\"\"\n",
    "    \n",
    "    feature_mask_string = ''.join([str(i) for i in feature_mask])\n",
    "    \n",
    "    # TODO: define the input layer here (your code from Q2)\n",
    "    \n",
    "    # Categorcial Features encoded as Integers\n",
    "    month = keras.Input(shape=(1,), name=\"month\", dtype=\"int64\")\n",
    "\n",
    "    # Categorcial Features encoded as String\n",
    "    flat_model_type = keras.Input(shape=(1,), name=\"flat_model_type\", dtype=\"string\")\n",
    "    storey_range = keras.Input(shape=(1,), name=\"storey_range\", dtype=\"string\")\n",
    "\n",
    "    # Numerical Features\n",
    "    floor_area_sqm = keras.Input(shape=(1,), name=\"floor_area_sqm\")\n",
    "    remaining_lease_years = keras.Input(shape=(1,), name=\"remaining_lease_years\")\n",
    "    degree_centrality = keras.Input(shape=(1,), name=\"degree_centrality\")\n",
    "    eigenvector_centrality = keras.Input(shape=(1,), name=\"eigenvector_centrality\")\n",
    "    dist_to_nearest_stn = keras.Input(shape=(1,), name=\"dist_to_nearest_stn\")\n",
    "    dist_to_dhoby = keras.Input(shape=(1,), name=\"dist_to_dhoby\")\n",
    "\n",
    "    all_inputs = [\n",
    "        month,\n",
    "        storey_range,\n",
    "        flat_model_type,\n",
    "        floor_area_sqm,\n",
    "        remaining_lease_years,\n",
    "        degree_centrality,\n",
    "        eigenvector_centrality,\n",
    "        dist_to_nearest_stn,\n",
    "        dist_to_dhoby\n",
    "    ]\n",
    "\n",
    "    # Embedding implemented for all the categorical features after using \n",
    "    # lookup to get the input integer encoded -> embedded -> flattened\n",
    "\n",
    "    # Integer Categorical Features\n",
    "    month_encoded = encode_categorical_feature(month, \"month\", train_ds, False)\n",
    "    month_embedded = embedding('month', divisor)(month_encoded)\n",
    "    month_flattened = keras.layers.Flatten()(month_embedded)\n",
    "\n",
    "    # String Categorical Features\n",
    "    flat_model_type_encoded = encode_categorical_feature(flat_model_type, \"flat_model_type\", train_ds, True)\n",
    "    flat_model_type_embedded = embedding('flat_model_type', divisor)(flat_model_type_encoded)\n",
    "    flat_model_type_flattened = keras.layers.Flatten()(flat_model_type_embedded)\n",
    "\n",
    "    storey_range_encoded = encode_categorical_feature(storey_range, \"storey_range\", train_ds, True)\n",
    "    storey_range_embedded = embedding('storey_range', divisor)(storey_range_encoded)\n",
    "    storey_range_flattened = keras.layers.Flatten()(storey_range_embedded)\n",
    "\n",
    "    # Numerical Features\n",
    "    floor_area_sqm_encoded = encode_numerical_feature(floor_area_sqm, \"floor_area_sqm\", train_ds)\n",
    "    remaining_lease_years_encoded = encode_numerical_feature(remaining_lease_years, \"remaining_lease_years\", train_ds)\n",
    "    degree_centrality_encoded = encode_numerical_feature(degree_centrality, \"degree_centrality\", train_ds)\n",
    "    eigenvector_centrality_encoded = encode_numerical_feature(eigenvector_centrality, \"eigenvector_centrality\", train_ds)\n",
    "    dist_to_nearest_stn_encoded = encode_numerical_feature(dist_to_nearest_stn, \"dist_to_nearest_stn\", train_ds)\n",
    "    dist_to_dhoby_encoded = encode_numerical_feature(dist_to_dhoby, \"dist_to_dhoby\", train_ds)\n",
    "\n",
    "    all_features_input = [\n",
    "            month_flattened,\n",
    "            storey_range_flattened,\n",
    "            flat_model_type_flattened,\n",
    "            floor_area_sqm_encoded,\n",
    "            remaining_lease_years_encoded,\n",
    "            degree_centrality_encoded,\n",
    "            eigenvector_centrality_encoded,\n",
    "            dist_to_nearest_stn_encoded,\n",
    "            dist_to_dhoby_encoded\n",
    "        ]\n",
    "    \n",
    "    selected_inputs = []\n",
    "    print('going through feature_mask', feature_mask)\n",
    "    for i,j in zip(all_features_input, feature_mask):\n",
    "        if j == 1:\n",
    "            selected_inputs.append(i)\n",
    "            print(i)\n",
    "        else:\n",
    "            print('Skipping', i)\n",
    "\n",
    "    all_features = layers.concatenate(selected_inputs)\n",
    "    \n",
    "    # TODO: Complete the rest of the architecture + training code and retrieve the training history\n",
    "    \n",
    "    x = layers.Dense(units=units, activation='relu')(all_features)\n",
    "    output = layers.Dense(1, activation='linear')(x)\n",
    "    model = keras.Model(all_inputs, output)\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss=tf.keras.losses.mean_squared_error, \n",
    "                  metrics=[r2, tf.keras.metrics.RootMeanSquaredError()])\n",
    "    \n",
    "    history = model.fit(train_ds, epochs=50, validation_data=test_ds)    \n",
    "    \n",
    "    \n",
    "    val_loss_hx = history.history['val_loss'] # NOTE: You can use RMSE if you find it easier to interpret.\n",
    "    val_loss_min = min(val_loss_hx)\n",
    "    \n",
    "    return val_loss_min\n",
    "\n",
    "\n",
    "## RFE starts here \n",
    "\n",
    "while sum(vec) > 0 and best_loss > new_best_loss:\n",
    "    \n",
    "    print('vec', vec)\n",
    "\n",
    "    best_loss = new_best_loss\n",
    "    new_min_loss_flag = False\n",
    "    \n",
    "    losses_from_same_vec = []\n",
    "    \n",
    "    for ix, i in enumerate(vec):\n",
    "        \n",
    "        print('ix', ix, 'i', i)\n",
    "        \n",
    "        if i == 0:\n",
    "            continue # if the feature is off, no need to do anything, go to next position\n",
    "        else:\n",
    "            temp_vec = vec[:]\n",
    "            temp_vec[ix] = 0 # turn off the feature\n",
    "            print('updated temp_vec', temp_vec)\n",
    "            \n",
    "            loss = train_model(temp_vec)\n",
    "            losses_from_same_vec.append(loss)\n",
    "            \n",
    "            if loss < new_best_loss:\n",
    "                new_best_loss = loss\n",
    "                which_iter = 'len ' + str(sum(vec)) + ', ix ' + str(ix)\n",
    "                print('new min loss:', which_iter)\n",
    "                new_min_loss_flag = True\n",
    "                min_loss_vec = temp_vec[:]\n",
    "\n",
    "            tf.keras.backend.clear_session()\n",
    "            print('session cleared!\\n')\n",
    "                \n",
    "    \n",
    "    all_losses.append(losses_from_same_vec)\n",
    "    \n",
    "    # After going through the vec once, update vec if new min loss    \n",
    "    if new_min_loss_flag:\n",
    "        vec = min_loss_vec\n",
    "    \n",
    "    # else case means no new min loss, the latter while loop condition will cause it to terminate \n",
    "    print(time.time() - start, 'seconds elapsed')\n",
    "    print()\n",
    "\n",
    "print(all_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_losses\n",
    "\n",
    "all_inputs = [\n",
    "        'month',\n",
    "        'storey_range',\n",
    "        'flat_model_type',\n",
    "        'floor_area_sqm',\n",
    "        'remaining_lease_years',\n",
    "        'degree_centrality',\n",
    "        'eigenvector_centrality',\n",
    "        'dist_to_nearest_stn',\n",
    "        'dist_to_dhoby'\n",
    "    ]\n",
    "\n",
    "removed_inputs = []\n",
    "for loss in all_losses:\n",
    "    removed_inputs.append(all_inputs[loss.index(min(loss))])\n",
    "    all_inputs.pop(loss.index(min(loss)))  \n",
    "    \n",
    "all_inputs = [\n",
    "        'month',\n",
    "        'storey_range',\n",
    "        'flat_model_type',\n",
    "        'floor_area_sqm',\n",
    "        'remaining_lease_years',\n",
    "        'degree_centrality',\n",
    "        'eigenvector_centrality',\n",
    "        'dist_to_nearest_stn',\n",
    "        'dist_to_dhoby'\n",
    "    ]\n",
    "\n",
    "crucial_inputs = []\n",
    "for losses in all_losses:\n",
    "    crucial = all_inputs[losses.index(max(losses))]\n",
    "    if crucial not in crucial_inputs:\n",
    "        crucial_inputs.append(crucial)\n",
    "    else:\n",
    "        while crucial in crucial_inputs:\n",
    "            losses.pop(losses.index(max(losses)))\n",
    "            crucial = all_inputs[losses.index(max(losses))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Removed inputs are  ['degree_centrality', 'floor_area_sqm', 'eigenvector_centrality']\n"
     ]
    }
   ],
   "source": [
    "print('The Removed inputs are ', removed_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Crucial inputs are  ['dist_to_dhoby', 'dist_to_nearest_stn', 'flat_model_type']\n"
     ]
    }
   ],
   "source": [
    "print('The Crucial inputs are ', crucial_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Compare the RFE on 'old test set' to RFE on train set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the RFE's removed degree_centrality, but the RFE on the new test set removed floor_area_sqm, eigenvector_centrality instead of month.\n",
    "\n",
    "Both the RFE's have dist_to_dhoby and dist_to_nearest_stn with fla_model_type as an addition on the new test set.\n",
    "\n",
    "Concept drift has occured. When we include data from 2022 as well in the new test set the featuresw being removed are different from the features being removed in RFE on the old test set. Therefore we conclude that due to the change in the data there has been a shift/concept drift in the new data which would lead to our model predicting worse on the new test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In Q1, we compared a linear regression model to an equivalent neural network architecture and also saw how adding a hidden layer changes model performance.In Q2, we saw how adding an Embedding layer introduces more learnable parameters to the neural network. What other benefits do neural networks have over other machine learning approaches? In cases where neural networks perform better, is it possible to modify â€˜traditionalâ€™ machine learning algorithms to close up the gap?\n",
    "Machine learning is a set of algorithms that take in data as an input, learn from them and then apply what has been learned to make intelligent decisions.\n",
    "\n",
    "Neural Networks mimic the working of a human brain through a set of algorithms.\n",
    "\n",
    "Neural Networks can be used to perform nonlinear statistcial modelling ans provide a new alternative to logistic regression. It requires less statistical training and has the abiliity to detect complex nonlinear relationships between both dependent and independent variables.\n",
    "\n",
    "Machine learning models can be improved by - \n",
    "1. Collecting a larger amount of training samples.\n",
    "2. Feature processing and engineering - add more variables/features and create variables based on domain knowledge which would have an impact on the final prediction.\n",
    "3. Parameter Tuning - consider multiple parameter values during tuning and choose the parameter which has the best accuracy/lowest loss while validating the model.\n",
    "\n",
    "- In Q2, we tried out another approach of model tuning. KerasTuner offers many other algorithms â€“ how do Bayesian optimisation or HyperBand work? Are they necessarily better than random search? Also, is random search better than grid search?\n",
    "\n",
    "Bayesian Optimisation, HyperBand and Random Search are all a subset of hyperparameter tuning algorithms.\n",
    "\n",
    "**Bayesian Optimisation** tunes hyperparameters by using a probabilistic approach. It takes into account the already tested combinations and uses this information to test the next hyperparameter combination for a test. It learns the objective function by learning based on previous data\n",
    "\n",
    "**Hyperband** is an optimized version of RandomSearch. It takes less time to search and also takes less resources when compared to random search. Initially it only runs for 1-2 iterations to observe the performance. Then it takes the best performers and runs them for a longer number of iterations.\n",
    "\n",
    "**Hyperband** is better than **RandomSearch** since it is more optimised but may miss out on the best hyperparameter based on the learning rates of hyperparameters. In the case of **Bayesian Optimisation** it works best when obtaining hyperparameters with less trials and long run time per iteration.\n",
    "\n",
    "**GridSearch** is an exhaustive searching technique which will select the absolute best model from the list of hyperparameters that need to be tuned. Since RandomSearch searches through a random list it is more optimised and faster than GridSearch."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMAsMzJzLPS+MWXs83UC1RG",
   "collapsed_sections": [],
   "name": "start_1b.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
